{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPrm/81Y+RBNiDBCRKBxFUo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jess-Lau/Real-Life-B-W-Video-Colorization-Project/blob/main/ImageColorizerGANV4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow scikit-image matplotlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bgs2oPT8Cb-u",
        "outputId": "c841c3dd-f79a-4115-d160-8d1ea002adf0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.14.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.1.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.2.18)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spDGJkC8CN6-",
        "outputId": "bc8f2180-5f05-42fa-92d4-c2ae2b885693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored from /content/colorization/checkpoints/ckpt-1\n",
            "Final Test MAE: 0.0786\n"
          ]
        }
      ],
      "source": [
        "# ----------------------\n",
        "# Image Colorization GAN\n",
        "# ----------------------\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "from datetime import datetime\n",
        "\n",
        "# ------------------\n",
        "# Configuration\n",
        "# ------------------\n",
        "IMAGE_SIZE = 32\n",
        "CHANNELS = 1  # L channel input\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 128\n",
        "LAMBDA = 100  # L1 loss weight\n",
        "WORKDIR = \"/content/colorization\"\n",
        "CHECKPOINT_DIR = os.path.join(WORKDIR, \"checkpoints\")\n",
        "RESULTS_DIR = os.path.join(WORKDIR, \"results\")\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# ------------------\n",
        "# Data Pipeline\n",
        "# ------------------\n",
        "def load_cifar10():\n",
        "    (train_images, _), (test_images, _) = tf.keras.datasets.cifar10.load_data()\n",
        "    return train_images / 255.0, test_images / 255.0\n",
        "\n",
        "def rgb_to_lab(images, debug=False):\n",
        "    lab_images = []\n",
        "    for rgb in images:\n",
        "        lab = rgb2lab(rgb)\n",
        "        L = lab[:, :, 0:1]          # (32, 32, 1) [0-100]\n",
        "        AB = lab[:, :, 1:] / 128.0  # (32, 32, 2) [-1, 1]\n",
        "        lab_images.append((L, AB))\n",
        "    return zip(*lab_images)\n",
        "\n",
        "def create_dataset(images, batch_size=32):\n",
        "    L, AB = rgb_to_lab(images)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (  # Wrap both arrays in a single tuple\n",
        "            np.array(L, dtype=np.float32),\n",
        "            np.array(AB, dtype=np.float32)\n",
        "        )\n",
        "    )\n",
        "    return dataset.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "# Load and prepare data\n",
        "train_images, test_images = load_cifar10()\n",
        "train_dataset = create_dataset(train_images, BATCH_SIZE)\n",
        "test_dataset = create_dataset(test_images, BATCH_SIZE)\n",
        "\n",
        "# ------------------\n",
        "# Generator (U-Net)\n",
        "# ------------------\n",
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    result = Sequential()\n",
        "    result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                             kernel_initializer=initializer, use_bias=False))\n",
        "    if apply_batchnorm:\n",
        "        result.add(layers.BatchNormalization())\n",
        "    result.add(layers.LeakyReLU())\n",
        "    return result\n",
        "\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    result = Sequential()\n",
        "    result.add(layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                      padding='same',\n",
        "                                      kernel_initializer=initializer,\n",
        "                                      use_bias=False))\n",
        "    result.add(layers.BatchNormalization())\n",
        "    if apply_dropout:\n",
        "        result.add(layers.Dropout(0.5))\n",
        "    result.add(layers.ReLU())\n",
        "    return result\n",
        "\n",
        "def build_generator():\n",
        "    inputs = layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, CHANNELS])\n",
        "\n",
        "    # Encoder (3 downsampling steps)\n",
        "    down_stack = [\n",
        "        downsample(64, 4, apply_batchnorm=False),  # 16x16\n",
        "        downsample(128, 4),                        # 8x8\n",
        "        downsample(256, 4),                        # 4x4\n",
        "    ]\n",
        "\n",
        "    # Decoder (3 upsampling steps)\n",
        "    up_stack = [\n",
        "        upsample(256, 4, apply_dropout=True),      # 8x8\n",
        "        upsample(128, 4),                          # 16x16\n",
        "        upsample(64, 4),                           # 32x32 (critical!)\n",
        "    ]\n",
        "\n",
        "    # Final output layer\n",
        "    last = layers.Conv2D(2, 3, padding='same', activation='tanh')\n",
        "\n",
        "    x = inputs\n",
        "    skips = []\n",
        "\n",
        "    # Downsampling\n",
        "    for down in down_stack:\n",
        "        x = down(x)\n",
        "        skips.append(x)\n",
        "\n",
        "    skips = reversed(skips[:-1])  # Use first two skip connections\n",
        "\n",
        "    # Upsampling with skip connections\n",
        "    for up, skip in zip(up_stack[:-1], skips):  # First two up layers use skips\n",
        "        x = up(x)\n",
        "        x = layers.Concatenate()([x, skip])\n",
        "\n",
        "    # Final upsampling without skip\n",
        "    x = up_stack[-1](x)  # Third up layer (32x32)\n",
        "    x = last(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=x)\n",
        "\n",
        "# ------------------\n",
        "# Discriminator\n",
        "# ------------------\n",
        "def build_discriminator():\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    inp = layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, 3], name='input_image')\n",
        "\n",
        "    x = layers.Conv2D(64, 4, strides=2, padding='same',\n",
        "                      kernel_initializer=initializer)(inp)  # (16, 16, 64)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 4, strides=2, padding='same',\n",
        "                      kernel_initializer=initializer)(x)    # (8, 8, 128)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Conv2D(256, 4, strides=2, padding='same',\n",
        "                      kernel_initializer=initializer)(x)    # (4, 4, 256)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU()(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    return Model(inputs=inp, outputs=x)\n",
        "\n",
        "# ------------------\n",
        "# Loss & Optimizers\n",
        "# ------------------\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(fake_output, generated_images, real_images):\n",
        "    gan_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "    l1_loss = tf.reduce_mean(tf.abs(real_images - generated_images))\n",
        "    return gan_loss + LAMBDA * l1_loss, gan_loss, l1_loss\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "\n",
        "# ------------------\n",
        "# Training Setup\n",
        "# ------------------\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    generator_optimizer=generator_optimizer,\n",
        "    discriminator_optimizer=discriminator_optimizer,\n",
        "    generator=generator,\n",
        "    discriminator=discriminator,\n",
        "    epoch=tf.Variable(0)\n",
        ")\n",
        "\n",
        "manager = tf.train.CheckpointManager(\n",
        "    checkpoint, CHECKPOINT_DIR, max_to_keep=3\n",
        ")\n",
        "\n",
        "# ------------------\n",
        "# Training Loop\n",
        "# ------------------\n",
        "\n",
        "def generate_images(model, test_input, epoch):\n",
        "    # Get predictions\n",
        "    prediction = model(test_input, training=False)\n",
        "\n",
        "    # Convert to LAB and then to RGB\n",
        "    grayscale_rgb = lab2rgb(np.dstack((\n",
        "        test_input[0].numpy()[..., 0],\n",
        "        np.zeros_like(prediction[0]),\n",
        "        np.zeros_like(prediction[0])\n",
        "    )))  # Grayscale (L + zero AB)\n",
        "\n",
        "    original_rgb = lab2rgb(np.dstack((\n",
        "        test_input[0].numpy()[..., 0],\n",
        "        (test_input[0].numpy()[..., 1:] * 128).astype(np.float64)\n",
        "    )))  # Ground truth\n",
        "\n",
        "    predicted_rgb = lab2rgb(np.dstack((\n",
        "        test_input[0].numpy()[..., 0],\n",
        "        (prediction[0].numpy() * 128).astype(np.float64)\n",
        "    )))  # Colorized prediction\n",
        "\n",
        "    # Plotting\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.title(\"Input\")\n",
        "    plt.imshow(grayscale_rgb)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.title(\"Ground Truth\")\n",
        "    plt.imshow(original_rgb)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.title(\"Predicted\")\n",
        "    plt.imshow(predicted_rgb)\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, f'epoch_{epoch}.png'))\n",
        "    plt.close()\n",
        "\n",
        "@tf.function\n",
        "def train_step(input_l, target_ab):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_ab = generator(input_l, training=True)\n",
        "        real_images = tf.concat([input_l, target_ab], axis=-1)\n",
        "        fake_images = tf.concat([input_l, generated_ab], axis=-1)\n",
        "\n",
        "        real_output = discriminator(real_images, training=True)\n",
        "        fake_output = discriminator(fake_images, training=True)\n",
        "\n",
        "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(\n",
        "            fake_output, generated_ab, target_ab\n",
        "        )\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # Gradient clipping\n",
        "    generator_gradients = gen_tape.gradient(\n",
        "        gen_total_loss, generator.trainable_variables\n",
        "    )\n",
        "    generator_gradients = [tf.clip_by_norm(g, 1.0) for g in generator_gradients]\n",
        "\n",
        "    discriminator_gradients = disc_tape.gradient(\n",
        "        disc_loss, discriminator.trainable_variables\n",
        "    )\n",
        "    discriminator_gradients = [\n",
        "        tf.clip_by_norm(g, 1.0) for g in discriminator_gradients\n",
        "    ]\n",
        "\n",
        "    generator_optimizer.apply_gradients(\n",
        "        zip(generator_gradients, generator.trainable_variables)\n",
        "    )\n",
        "    discriminator_optimizer.apply_gradients(\n",
        "        zip(discriminator_gradients, discriminator.trainable_variables)\n",
        "    )\n",
        "\n",
        "    return gen_total_loss, disc_loss, gen_gan_loss, gen_l1_loss\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    for epoch in range(checkpoint.epoch.numpy(), epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        # Training\n",
        "        gen_loss = []\n",
        "        disc_loss = []\n",
        "        for input_l, target_ab in dataset:\n",
        "            losses = train_step(input_l, target_ab)\n",
        "            gen_loss.append(losses[0])\n",
        "            disc_loss.append(losses[1])\n",
        "\n",
        "        # Save checkpoint\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            manager.save()\n",
        "            generate_images(generator, next(iter(test_dataset))[0], epoch+1)\n",
        "\n",
        "        # Logging\n",
        "        print(f'Epoch {epoch+1} | '\n",
        "              f'Gen Loss: {np.mean(gen_loss):.4f} | '\n",
        "              f'Disc Loss: {np.mean(disc_loss):.4f} | '\n",
        "              f'Time: {time.time()-start:.2f}s')\n",
        "\n",
        "        checkpoint.epoch.assign_add(1)\n",
        "\n",
        "# ------------------\n",
        "# Execution\n",
        "# ------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Restore checkpoints if available\n",
        "    if manager.latest_checkpoint:\n",
        "        checkpoint.restore(manager.latest_checkpoint)\n",
        "        print(f\"Restored from {manager.latest_checkpoint}\")\n",
        "\n",
        "    # Start training\n",
        "    train(train_dataset, EPOCHS)\n",
        "\n",
        "    # Final evaluation\n",
        "    test_loss = []\n",
        "    for test_input, test_target in test_dataset:\n",
        "        gen_output = generator(test_input, training=False)\n",
        "        test_loss.append(tf.reduce_mean(tf.abs(test_target - gen_output)))\n",
        "    print(f\"Final Test MAE: {np.mean(test_loss):.4f}\")"
      ]
    }
  ]
}