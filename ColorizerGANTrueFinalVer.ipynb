{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "https://github.com/Jess-Lau/Real-Life-B-W-Video-Colorization-Project/blob/main/ColorizerGANV2.ipynb",
      "authorship_tag": "ABX9TyOON15XftAFgxLzBgAyfGo7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jess-Lau/Real-Life-B-W-Video-Colorization-Project/blob/main/ColorizerGANTrueFinalVer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ads3J-VraLRG"
      },
      "outputs": [],
      "source": [
        "# ----------------------\n",
        "# Colorization GAN\n",
        "# ----------------------\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Configuration\n",
        "# ------------------\n",
        "IMAGE_SIZE = 64\n",
        "CHANNELS = 1\n",
        "EPOCHS = 70\n",
        "BATCH_SIZE = 512\n",
        "LAMBDA = 100\n",
        "DATA_DIR = \"/content/drive/MyDrive/ImageNet\"  # Update with your path\n",
        "WORKDIR = \"/content/drive/MyDrive/Colorization\"\n",
        "CHECKPOINT_DIR = os.path.join(WORKDIR, \"checkpoints2\")\n",
        "RESULTS_DIR = os.path.join(WORKDIR, \"results2\")\n",
        "\n",
        "# Enable mixed precision with proper policy\n",
        "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.set_global_policy(policy)\n",
        "\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "1jffqiuUahQR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "id": "IwZJqTfo4Ge7",
        "outputId": "0d961e9e-e9dd-48cf-f66f-60bebdb4e09c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Apr  6 20:52:37 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P0             53W /  400W |    6593MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Data Pipeline\n",
        "# ------------------\n",
        "def load_mean(data_dir):\n",
        "    \"\"\"Load mean image from first training batch\"\"\"\n",
        "    with open(os.path.join(data_dir, 'train_data_batch_1'), 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "        mean = data['mean'].astype(np.float32) / 255.0\n",
        "        return mean.reshape(3, IMAGE_SIZE, IMAGE_SIZE).transpose(1, 2, 0)\n",
        "\n",
        "def data_generator(data_dir, split='train'):\n",
        "    mean = load_mean(data_dir) if split == 'train' else None\n",
        "    files = [f'train_data_batch_{i}' for i in range(1, 11)] if split == 'train' else ['val_data']\n",
        "\n",
        "    for file in files:\n",
        "        path = os.path.join(data_dir, file)\n",
        "        try:\n",
        "            with open(path, 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "                x = data['data'].astype(np.float32) / 255.0\n",
        "                x = x.reshape(-1, 3, IMAGE_SIZE, IMAGE_SIZE).transpose(0, 2, 3, 1)\n",
        "\n",
        "                if mean is not None:\n",
        "                    x -= mean\n",
        "\n",
        "                for i in range(0, x.shape[0], BATCH_SIZE):\n",
        "                    batch_rgb = x[i:i+BATCH_SIZE]\n",
        "                    batch_lab = np.array([rgb2lab(img) for img in batch_rgb])\n",
        "                    L = batch_lab[..., 0:1].astype(np.float32)\n",
        "                    AB = (batch_lab[..., 1:] / 128.0).astype(np.float32)\n",
        "                    yield L, AB\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load {path}: {str(e)}\")\n",
        "            continue  # Skip problematic files\n",
        "\n",
        "def create_dataset(data_dir, split='train'):\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        lambda: data_generator(data_dir, split),\n",
        "        output_signature=(  # ✅ Proper parentheses\n",
        "            tf.TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(None, 64, 64, 2), dtype=tf.float32)\n",
        "        )\n",
        "    ).prefetch(tf.data.AUTOTUNE)  # ✅ .prefetch() called on dataset"
      ],
      "metadata": {
        "id": "oXsq8r77afW4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Model Architectures\n",
        "# ------------------\n",
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                          kernel_initializer=initializer, use_bias=False))\n",
        "    if apply_batchnorm:\n",
        "        model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "    return model\n",
        "\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
        "                                    kernel_initializer=initializer, use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    if apply_dropout:\n",
        "        model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.ReLU())\n",
        "    return model\n",
        "\n",
        "def build_generator():\n",
        "    inputs = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
        "\n",
        "    # Encoder\n",
        "    d1 = downsample(64, 4, False)(inputs)    # 32x32\n",
        "    d2 = downsample(128, 4)(d1)              # 16x16\n",
        "    d3 = downsample(256, 4)(d2)              # 8x8\n",
        "    d4 = downsample(512, 4)(d3)              # 4x4\n",
        "\n",
        "    # Decoder\n",
        "    u1 = upsample(512, 4, True)(d4)          # 8x8\n",
        "    u1 = layers.Concatenate()([u1, d3])\n",
        "    u2 = upsample(256, 4)(u1)                # 16x16\n",
        "    u2 = layers.Concatenate()([u2, d2])\n",
        "    u3 = upsample(128, 4)(u2)                # 32x32\n",
        "    u3 = layers.Concatenate()([u3, d1])\n",
        "    u4 = upsample(64, 4)(u3)                 # 64x64\n",
        "\n",
        "    output = layers.Conv2D(2, 3, padding='same', activation='tanh')(u4)\n",
        "    return Model(inputs, output)\n",
        "\n",
        "def build_discriminator():\n",
        "    inputs = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "\n",
        "    x = layers.Conv2D(64, 4, strides=2, padding='same')(inputs)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(256, 4, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)\n",
        "    return Model(inputs, x)"
      ],
      "metadata": {
        "id": "6YOSJkmZadOh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Training Setup\n",
        "# ------------------\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    generator_optimizer=generator_optimizer,\n",
        "    discriminator_optimizer=discriminator_optimizer,\n",
        "    generator=generator,\n",
        "    discriminator=discriminator,\n",
        "    epoch=tf.Variable(0)\n",
        ")\n",
        "manager = tf.train.CheckpointManager(checkpoint, CHECKPOINT_DIR, max_to_keep=3)"
      ],
      "metadata": {
        "id": "ENkU2C05abcZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Training Utilities\n",
        "# ------------------\n",
        "def generate_images(model, test_input, epoch):\n",
        "    input_L = test_input[0]  # ✅ Extract L channel\n",
        "    target_AB = test_input[1]  # Ground truth AB\n",
        "\n",
        "    # Predict using only L\n",
        "    prediction = model(input_L, training=False)[0].numpy()\n",
        "    L = input_L[0].numpy()[..., 0]  # Use first sample in batch\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Input (grayscale)\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(L, cmap='gray')\n",
        "    plt.title(\"Input\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Ground truth (colorized)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    true_rgb = lab2rgb(np.dstack((L, target_AB[0].numpy() * 128)))  # ✅ Use target_AB\n",
        "    plt.imshow(true_rgb)\n",
        "    plt.title(\"Ground Truth\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Predicted (colorized)\n",
        "    plt.subplot(1, 3, 3)\n",
        "    pred_rgb = lab2rgb(np.dstack((L, prediction * 128)))\n",
        "    plt.imshow(pred_rgb)\n",
        "    plt.title(\"Predicted\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, f'epoch_{epoch+1}.png'))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# --- Add PSNR/SSIM Calculations ---\n",
        "# Convert LAB to RGB for metrics\n",
        "def lab_to_rgb(lab):\n",
        "    \"\"\"Convert LAB tensor to RGB tensor (0-255 range) with mixed precision support\"\"\"\n",
        "    # Ensure LAB tensor is float32 for stable calculations\n",
        "    lab = tf.cast(lab, tf.float32)\n",
        "\n",
        "    # Denormalize LAB\n",
        "    L = lab[..., 0] * 100.0          # L: [0,100]\n",
        "    ab = lab[..., 1:] * 128.0        # ab: [-128, 127]\n",
        "\n",
        "    # Convert LAB to XYZ\n",
        "    y = (L + 16.0) / 116.0\n",
        "    x = ab[..., 0] / 500.0 + y\n",
        "    z = y - ab[..., 1] / 200.0\n",
        "\n",
        "    xyz = tf.stack([x, y, z], axis=-1)\n",
        "    xyz = tf.where(xyz > 0.2068966, xyz**3, (xyz - 16.0/116.0)/7.787)\n",
        "\n",
        "    # D65 reference white (cast to float32)\n",
        "    xyz = xyz * tf.constant([95.047, 100.0, 108.883], dtype=tf.float32)\n",
        "\n",
        "    # XYZ to RGB matrix\n",
        "    rgb = tf.tensordot(xyz, tf.constant([\n",
        "        [3.2406, -1.5372, -0.4986],\n",
        "        [-0.9689, 1.8758, 0.0415],\n",
        "        [0.0557, -0.2040, 1.0570]\n",
        "    ], dtype=tf.float32), axes=1)\n",
        "\n",
        "    # Gamma correction\n",
        "    rgb = tf.where(rgb > 0.0031308,\n",
        "                    1.055 * (rgb ** (1/2.4)) - 0.055,\n",
        "                    12.92 * rgb)\n",
        "\n",
        "    # Final conversion to float16 if needed\n",
        "    return tf.cast(tf.clip_by_value(rgb * 255.0, 0.0, 255.0), tf.float16)\n",
        "\n",
        "def safe_psnr(real, fake, max_val, eps=1e-10):\n",
        "    # Cast both tensors to float32 to ensure dtype consistency\n",
        "    real = tf.cast(real, tf.float32)\n",
        "    fake = tf.cast(fake, tf.float32)\n",
        "    mse = tf.reduce_mean(tf.square(real - fake))\n",
        "    return 20 * tf.math.log(max_val) / tf.math.log(10.0) - 10 * tf.math.log(mse + eps) / tf.math.log(10.0)\n",
        "\n",
        "@tf.function\n",
        "def train_step(input_L, input_AB):\n",
        "    # Cast to mixed precision\n",
        "    input_L = tf.cast(input_L, tf.float16)\n",
        "    input_AB = tf.cast(input_AB, tf.float16)\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        generated_AB = generator(input_L, training=True)\n",
        "\n",
        "        # Create concatenated images\n",
        "        real_images = tf.concat([input_L, input_AB], axis=-1)\n",
        "        fake_images = tf.concat([input_L, generated_AB], axis=-1)\n",
        "\n",
        "        # Discriminator outputs\n",
        "        disc_real = discriminator(real_images, training=True)\n",
        "        disc_fake = discriminator(fake_images, training=True)\n",
        "\n",
        "        # Loss calculations\n",
        "        gen_loss = tf.keras.losses.binary_crossentropy(\n",
        "            tf.ones_like(disc_fake), disc_fake) + LAMBDA * tf.reduce_mean(tf.abs(input_AB - generated_AB))\n",
        "        disc_loss = tf.keras.losses.binary_crossentropy(\n",
        "            tf.ones_like(disc_real), disc_real) + tf.keras.losses.binary_crossentropy(\n",
        "            tf.zeros_like(disc_fake), disc_fake)\n",
        "\n",
        "\n",
        "\n",
        "    # Ground truth RGB (from original LAB)\n",
        "    lab_real = tf.concat([input_L, input_AB], axis=-1)\n",
        "    rgb_real = lab_to_rgb(lab_real)\n",
        "\n",
        "    # Generated RGB\n",
        "    lab_fake = tf.concat([input_L, generated_AB], axis=-1)\n",
        "    rgb_fake = lab_to_rgb(lab_fake)\n",
        "\n",
        "    # Calculate metrics\n",
        "    psnr = safe_psnr(rgb_real, rgb_fake, max_val=255.0)\n",
        "    ssim = tf.image.ssim(rgb_real, rgb_fake, max_val=255.0)\n",
        "\n",
        "    # Apply gradient clipping\n",
        "    gen_grads = tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gen_grads = [tf.clip_by_norm(g, 1.0) for g in gen_grads]\n",
        "    generator_optimizer.apply_gradients(zip(gen_grads, generator.trainable_variables))\n",
        "\n",
        "    disc_grads = tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    disc_grads = [tf.clip_by_norm(g, 1.0) for g in disc_grads]\n",
        "    discriminator_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_variables))\n",
        "\n",
        "    return tf.reduce_mean(gen_loss), tf.reduce_mean(disc_loss), psnr, ssim\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zs6PxIdJaVn0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def calculate_frame_psnr(original, colorized):\n",
        "    \"\"\"\n",
        "    Calculate PSNR for a single frame pair.\n",
        "    Args:\n",
        "        original: Ground truth frame (BGR)\n",
        "        colorized: Colorized frame (BGR)\n",
        "    Returns:\n",
        "        PSNR value in dB\n",
        "    \"\"\"\n",
        "    # Convert to YCrCb for luminance comparison (optional)\n",
        "    original_yuv = cv2.cvtColor(original, cv2.COLOR_BGR2YCrCb)\n",
        "    colorized_yuv = cv2.cvtColor(colorized, cv2.COLOR_BGR2YCrCb)\n",
        "\n",
        "    # Calculate PSNR for each channel\n",
        "    psnr_y = peak_signal_noise_ratio(original_yuv[...,0], colorized_yuv[...,0], data_range=255)\n",
        "    psnr_cr = peak_signal_noise_ratio(original_yuv[...,1], colorized_yuv[...,1], data_range=255)\n",
        "    psnr_cb = peak_signal_noise_ratio(original_yuv[...,2], colorized_yuv[...,2], data_range=255)\n",
        "\n",
        "    return np.mean([psnr_y, psnr_cr, psnr_cb])\n",
        "\n",
        "def calculate_video_psnr(original_video_path, colorized_video_path):\n",
        "    \"\"\"\n",
        "    Calculate average PSNR between two videos.\n",
        "    Returns:\n",
        "        Mean PSNR (dB), Frame-wise PSNR array\n",
        "    \"\"\"\n",
        "    cap_orig = cv2.VideoCapture(original_video_path)\n",
        "    cap_color = cv2.VideoCapture(colorized_video_path)\n",
        "\n",
        "    psnr_values = []\n",
        "\n",
        "    while True:\n",
        "        ret_orig, frame_orig = cap_orig.read()\n",
        "        ret_color, frame_color = cap_color.read()\n",
        "\n",
        "        if not ret_orig or not ret_color:\n",
        "            break\n",
        "\n",
        "        # Resize if necessary (match dimensions)\n",
        "        if frame_orig.shape != frame_color.shape:\n",
        "            frame_color = cv2.resize(frame_color, (frame_orig.shape[1], frame_orig.shape[0]))\n",
        "\n",
        "        psnr = calculate_frame_psnr(frame_orig, frame_color)\n",
        "        psnr_values.append(psnr)\n",
        "\n",
        "    cap_orig.release()\n",
        "    cap_color.release()\n",
        "\n",
        "    return np.mean(psnr_values), psnr_values"
      ],
      "metadata": {
        "id": "8xpOqmc-3Gko"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Training Loop\n",
        "# ------------------\n",
        "def train():\n",
        "    train_dataset = create_dataset(DATA_DIR, 'train')\n",
        "    val_dataset = create_dataset(DATA_DIR, 'val')\n",
        "\n",
        "    if manager.latest_checkpoint:\n",
        "        checkpoint.restore(manager.latest_checkpoint)\n",
        "        print(f\"Resumed from epoch {checkpoint.epoch.numpy()}\")\n",
        "\n",
        "    # Initialize metrics\n",
        "    psnr_metric = tf.keras.metrics.Mean(name='psnr')\n",
        "    ssim_metric = tf.keras.metrics.Mean(name='ssim')\n",
        "\n",
        "    for epoch in range(checkpoint.epoch.numpy(), EPOCHS):\n",
        "        start = time.time()\n",
        "        gen_losses, disc_losses = [], []\n",
        "        # Reset metrics each epoch (CORRECTED METHOD NAME)\n",
        "        psnr_metric.reset_state()\n",
        "        ssim_metric.reset_state()\n",
        "\n",
        "        # Training phase\n",
        "        for batch, (L, AB) in enumerate(train_dataset):\n",
        "            gen_loss, disc_loss, psnr, ssim = train_step(L, AB)\n",
        "            gen_losses.append(gen_loss)\n",
        "            disc_losses.append(disc_loss)\n",
        "\n",
        "            # Update metrics\n",
        "            psnr_metric.update_state(psnr)\n",
        "            ssim_metric.update_state(ssim)\n",
        "\n",
        "\n",
        "            # Existing logging\n",
        "            if batch % 100 == 0:\n",
        "                gen_loss_val = gen_loss.numpy().item()\n",
        "                disc_loss_val = disc_loss.numpy().item()\n",
        "                print(f\"Batch {batch} | PSNR: {psnr_metric.result():.2f} | SSIM: {ssim_metric.result():.3f}\")\n",
        "                print(f\"Gen: {gen_loss_val:.2f} Disc: {disc_loss_val:.2f}\")\n",
        "\n",
        "\n",
        "        # In your training loop after the epoch's training phase:\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            manager.save()\n",
        "            test_batch = next(iter(val_dataset))\n",
        "            generate_images(generator, test_batch, epoch)\n",
        "\n",
        "        # Validation phase\n",
        "        val_psnr = []\n",
        "        val_ssim = []\n",
        "        for val_L, val_AB in val_dataset.take(10):\n",
        "           val_gen_AB = generator(val_L, training=False)\n",
        "\n",
        "        # Convert to float32 before concatenation\n",
        "           val_real_lab = tf.concat([\n",
        "               tf.cast(val_L, tf.float32),\n",
        "               tf.cast(val_AB, tf.float32)\n",
        "           ], axis=-1)\n",
        "           val_real_rgb = lab_to_rgb(val_real_lab)\n",
        "\n",
        "           val_fake_lab = tf.concat([\n",
        "               tf.cast(val_L, tf.float32),\n",
        "               tf.cast(val_gen_AB, tf.float32)\n",
        "           ], axis=-1)\n",
        "           val_fake_rgb = lab_to_rgb(val_fake_lab)\n",
        "\n",
        "        # Calculate metrics\n",
        "        batch_psnr = tf.reduce_mean(tf.image.psnr(val_real_rgb, val_fake_rgb, max_val=255))\n",
        "        batch_ssim = tf.reduce_mean(tf.image.ssim(val_real_rgb, val_fake_rgb, max_val=255))\n",
        "\n",
        "        val_psnr.append(batch_psnr.numpy())\n",
        "        val_ssim.append(batch_ssim.numpy())\n",
        "\n",
        "        # Epoch summary\n",
        "        print(f\"\\nEpoch {epoch+1}\")\n",
        "        print(f\"Time: {time.time()-start:.2f}s\")\n",
        "        print(f\"Gen Loss: {np.mean(gen_losses):.4f}\")\n",
        "        print(f\"Disc Loss: {np.mean(disc_losses):.4f}\\n\")\n",
        "        print(f\"Train PSNR: {psnr_metric.result():.2f} dB\")\n",
        "        print(f\"Train SSIM: {ssim_metric.result():.4f}\")\n",
        "        print(f\"Val PSNR: {np.mean(val_psnr):.2f} dB\")\n",
        "        print(f\"Val SSIM: {np.mean(val_ssim):.4f}\")\n",
        "\n",
        "        checkpoint.epoch.assign_add(1)\n"
      ],
      "metadata": {
        "id": "BOasui2daTd5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train()"
      ],
      "metadata": {
        "id": "LvKNoJXlaRZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "610d4541-8106-4c72-f9d1-a9cd03f79908"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumed from epoch 59\n",
            "Batch 0 | PSNR: 24.42 | SSIM: 0.980\n",
            "Gen: 9.77 Disc: 1.40\n",
            "Batch 100 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 9.94 Disc: 1.33\n",
            "Batch 200 | PSNR: 24.89 | SSIM: 0.981\n",
            "Gen: 10.27 Disc: 1.36\n",
            "Batch 300 | PSNR: 24.92 | SSIM: 0.981\n",
            "Gen: 9.96 Disc: 1.36\n",
            "Batch 400 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.21 Disc: 1.38\n",
            "Batch 500 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.34 Disc: 1.38\n",
            "Batch 600 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.09 Disc: 1.39\n",
            "Batch 700 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.32 Disc: 1.35\n",
            "Batch 800 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.57 Disc: 1.30\n",
            "Batch 900 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.14 Disc: 1.38\n",
            "Batch 1000 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.67 Disc: 1.33\n",
            "Batch 1100 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.02 Disc: 1.34\n",
            "Batch 1200 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.52 Disc: 1.42\n",
            "Batch 1300 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.12 Disc: 1.35\n",
            "Batch 1400 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.63 Disc: 1.33\n",
            "Batch 1500 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 9.86 Disc: 1.33\n",
            "Batch 1600 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.40 Disc: 1.34\n",
            "Batch 1700 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.46 Disc: 1.35\n",
            "Batch 1800 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.11 Disc: 1.31\n",
            "Batch 1900 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.23 Disc: 1.38\n",
            "Batch 2000 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.41 Disc: 1.34\n",
            "Batch 2100 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.30 Disc: 1.34\n",
            "Batch 2200 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.76 Disc: 1.27\n",
            "Batch 2300 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.30 Disc: 1.33\n",
            "Batch 2400 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.73 Disc: 1.40\n",
            "Batch 2500 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.49 Disc: 1.38\n",
            "\n",
            "Epoch 60\n",
            "Time: 805.04s\n",
            "Gen Loss: 10.2344\n",
            "Disc Loss: 1.3516\n",
            "\n",
            "Train PSNR: 24.95 dB\n",
            "Train SSIM: 0.9810\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9768\n",
            "Batch 0 | PSNR: 24.86 | SSIM: 0.981\n",
            "Gen: 10.16 Disc: 1.36\n",
            "Batch 100 | PSNR: 24.89 | SSIM: 0.981\n",
            "Gen: 10.37 Disc: 1.37\n",
            "Batch 200 | PSNR: 24.92 | SSIM: 0.981\n",
            "Gen: 10.10 Disc: 1.36\n",
            "Batch 300 | PSNR: 24.92 | SSIM: 0.981\n",
            "Gen: 10.16 Disc: 1.37\n",
            "Batch 400 | PSNR: 24.91 | SSIM: 0.981\n",
            "Gen: 10.23 Disc: 1.39\n",
            "Batch 500 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.75 Disc: 1.34\n",
            "Batch 600 | PSNR: 24.92 | SSIM: 0.981\n",
            "Gen: 10.29 Disc: 1.39\n",
            "Batch 700 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.44 Disc: 1.37\n",
            "Batch 800 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.44 Disc: 1.36\n",
            "Batch 900 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.77 Disc: 1.36\n",
            "Batch 1000 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.14 Disc: 1.41\n",
            "Batch 1100 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.90 Disc: 1.37\n",
            "Batch 1200 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.05 Disc: 1.35\n",
            "Batch 1300 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.18 Disc: 1.35\n",
            "Batch 1400 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.09 Disc: 1.45\n",
            "Batch 1500 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.14 Disc: 1.37\n",
            "Batch 1600 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.68 Disc: 1.37\n",
            "Batch 1700 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.24 Disc: 1.37\n",
            "Batch 1800 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.54 Disc: 1.38\n",
            "Batch 1900 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.84 Disc: 1.33\n",
            "Batch 2000 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.89 Disc: 1.35\n",
            "Batch 2100 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.98 Disc: 1.34\n",
            "Batch 2200 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.97 Disc: 1.29\n",
            "Batch 2300 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.23 Disc: 1.39\n",
            "Batch 2400 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.01 Disc: 1.39\n",
            "Batch 2500 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.57 Disc: 1.39\n",
            "\n",
            "Epoch 61\n",
            "Time: 799.54s\n",
            "Gen Loss: 10.2188\n",
            "Disc Loss: 1.3496\n",
            "\n",
            "Train PSNR: 24.95 dB\n",
            "Train SSIM: 0.9810\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9852\n",
            "Batch 0 | PSNR: 25.16 | SSIM: 0.981\n",
            "Gen: 9.81 Disc: 1.34\n",
            "Batch 100 | PSNR: 24.82 | SSIM: 0.980\n",
            "Gen: 10.45 Disc: 1.34\n",
            "Batch 200 | PSNR: 24.93 | SSIM: 0.981\n",
            "Gen: 9.98 Disc: 1.38\n",
            "Batch 300 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.70 Disc: 1.34\n",
            "Batch 400 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.21 Disc: 1.33\n",
            "Batch 500 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.07 Disc: 1.38\n",
            "Batch 600 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.09 Disc: 1.32\n",
            "Batch 700 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.23 Disc: 1.32\n",
            "Batch 800 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.20 Disc: 1.33\n",
            "Batch 900 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.24 Disc: 1.41\n",
            "Batch 1000 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.15 Disc: 1.34\n",
            "Batch 1100 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.39 Disc: 1.38\n",
            "Batch 1200 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.13 Disc: 1.35\n",
            "Batch 1300 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.88 Disc: 1.34\n",
            "Batch 1400 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.75 Disc: 1.34\n",
            "Batch 1500 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.95 Disc: 1.35\n",
            "Batch 1600 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.05 Disc: 1.37\n",
            "Batch 1700 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.22 Disc: 1.38\n",
            "Batch 1800 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.09 Disc: 1.34\n",
            "Batch 1900 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.01 Disc: 1.33\n",
            "Batch 2000 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.06 Disc: 1.35\n",
            "Batch 2100 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.28 Disc: 1.30\n",
            "Batch 2200 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.49 Disc: 1.36\n",
            "Batch 2300 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.23 Disc: 1.30\n",
            "Batch 2400 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.03 Disc: 1.42\n",
            "Batch 2500 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.09 Disc: 1.33\n",
            "\n",
            "Epoch 62\n",
            "Time: 796.75s\n",
            "Gen Loss: 10.2188\n",
            "Disc Loss: 1.3506\n",
            "\n",
            "Train PSNR: 24.95 dB\n",
            "Train SSIM: 0.9810\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9802\n",
            "Batch 0 | PSNR: 25.42 | SSIM: 0.982\n",
            "Gen: 9.84 Disc: 1.40\n",
            "Batch 100 | PSNR: 24.88 | SSIM: 0.981\n",
            "Gen: 9.83 Disc: 1.41\n",
            "Batch 200 | PSNR: 24.93 | SSIM: 0.981\n",
            "Gen: 9.96 Disc: 1.37\n",
            "Batch 300 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.11 Disc: 1.35\n",
            "Batch 400 | PSNR: 24.93 | SSIM: 0.981\n",
            "Gen: 10.29 Disc: 1.40\n",
            "Batch 500 | PSNR: 24.93 | SSIM: 0.981\n",
            "Gen: 10.30 Disc: 1.41\n",
            "Batch 600 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.21 Disc: 1.33\n",
            "Batch 700 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.43 Disc: 1.34\n",
            "Batch 800 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.29 Disc: 1.32\n",
            "Batch 900 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.99 Disc: 1.35\n",
            "Batch 1000 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.05 Disc: 1.41\n",
            "Batch 1100 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.85 Disc: 1.32\n",
            "Batch 1200 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.91 Disc: 1.36\n",
            "Batch 1300 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.80 Disc: 1.31\n",
            "Batch 1400 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 9.80 Disc: 1.37\n",
            "Batch 1500 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 9.93 Disc: 1.35\n",
            "Batch 1600 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.04 Disc: 1.30\n",
            "Batch 1700 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 9.93 Disc: 1.36\n",
            "Batch 1800 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.48 Disc: 1.29\n",
            "Batch 1900 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.23 Disc: 1.41\n",
            "Batch 2000 | PSNR: 24.93 | SSIM: 0.981\n",
            "Gen: 9.67 Disc: 1.37\n",
            "Batch 2100 | PSNR: 24.93 | SSIM: 0.981\n",
            "Gen: 10.95 Disc: 1.29\n",
            "Batch 2200 | PSNR: 24.93 | SSIM: 0.981\n",
            "Gen: 10.31 Disc: 1.29\n",
            "Batch 2300 | PSNR: 24.93 | SSIM: 0.981\n",
            "Gen: 10.40 Disc: 1.38\n",
            "Batch 2400 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 10.37 Disc: 1.33\n",
            "Batch 2500 | PSNR: 24.94 | SSIM: 0.981\n",
            "Gen: 9.70 Disc: 1.35\n",
            "\n",
            "Epoch 63\n",
            "Time: 800.76s\n",
            "Gen Loss: 10.2188\n",
            "Disc Loss: 1.3496\n",
            "\n",
            "Train PSNR: 24.94 dB\n",
            "Train SSIM: 0.9810\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9910\n",
            "Batch 0 | PSNR: 25.41 | SSIM: 0.982\n",
            "Gen: 9.51 Disc: 1.42\n",
            "Batch 100 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.46 Disc: 1.30\n",
            "Batch 200 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.25 Disc: 1.38\n",
            "Batch 300 | PSNR: 24.99 | SSIM: 0.981\n",
            "Gen: 9.98 Disc: 1.31\n",
            "Batch 400 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.02 Disc: 1.41\n",
            "Batch 500 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 9.99 Disc: 1.35\n",
            "Batch 600 | PSNR: 24.99 | SSIM: 0.981\n",
            "Gen: 10.14 Disc: 1.37\n",
            "Batch 700 | PSNR: 24.99 | SSIM: 0.981\n",
            "Gen: 10.63 Disc: 1.36\n",
            "Batch 800 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.16 Disc: 1.31\n",
            "Batch 900 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.25 Disc: 1.35\n",
            "Batch 1000 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.02 Disc: 1.38\n",
            "Batch 1100 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.10 Disc: 1.36\n",
            "Batch 1200 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.00 Disc: 1.31\n",
            "Batch 1300 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.99 Disc: 1.34\n",
            "Batch 1400 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.84 Disc: 1.35\n",
            "Batch 1500 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.86 Disc: 1.38\n",
            "Batch 1600 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.99 Disc: 1.36\n",
            "Batch 1700 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.38 Disc: 1.31\n",
            "Batch 1800 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.12 Disc: 1.37\n",
            "Batch 1900 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.62 Disc: 1.30\n",
            "Batch 2000 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.31 Disc: 1.39\n",
            "Batch 2100 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.34 Disc: 1.28\n",
            "Batch 2200 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.16 Disc: 1.31\n",
            "Batch 2300 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.23 Disc: 1.31\n",
            "Batch 2400 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.67 Disc: 1.38\n",
            "Batch 2500 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.77 Disc: 1.35\n",
            "\n",
            "Epoch 64\n",
            "Time: 799.56s\n",
            "Gen Loss: 10.2031\n",
            "Disc Loss: 1.3486\n",
            "\n",
            "Train PSNR: 24.95 dB\n",
            "Train SSIM: 0.9810\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9783\n",
            "Batch 0 | PSNR: 24.93 | SSIM: 0.981\n",
            "Gen: 10.05 Disc: 1.35\n",
            "Batch 100 | PSNR: 24.99 | SSIM: 0.981\n",
            "Gen: 10.45 Disc: 1.34\n",
            "Batch 200 | PSNR: 25.00 | SSIM: 0.981\n",
            "Gen: 9.95 Disc: 1.35\n",
            "Batch 300 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 9.82 Disc: 1.36\n",
            "Batch 400 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.20 Disc: 1.39\n",
            "Batch 500 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.29 Disc: 1.36\n",
            "Batch 600 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.13 Disc: 1.37\n",
            "Batch 700 | PSNR: 24.99 | SSIM: 0.981\n",
            "Gen: 10.77 Disc: 1.30\n",
            "Batch 800 | PSNR: 24.99 | SSIM: 0.981\n",
            "Gen: 10.34 Disc: 1.31\n",
            "Batch 900 | PSNR: 24.99 | SSIM: 0.981\n",
            "Gen: 9.82 Disc: 1.37\n",
            "Batch 1000 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.26 Disc: 1.33\n",
            "Batch 1100 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.40 Disc: 1.35\n",
            "Batch 1200 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.02 Disc: 1.34\n",
            "Batch 1300 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 9.90 Disc: 1.29\n",
            "Batch 1400 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 9.93 Disc: 1.34\n",
            "Batch 1500 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 9.78 Disc: 1.38\n",
            "Batch 1600 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.10 Disc: 1.35\n",
            "Batch 1700 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 9.92 Disc: 1.34\n",
            "Batch 1800 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 9.95 Disc: 1.34\n",
            "Batch 1900 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.95 Disc: 1.36\n",
            "Batch 2000 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.54 Disc: 1.38\n",
            "Batch 2100 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.00 Disc: 1.32\n",
            "Batch 2200 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.95 Disc: 1.32\n",
            "Batch 2300 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.17 Disc: 1.35\n",
            "Batch 2400 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.47 Disc: 1.35\n",
            "Batch 2500 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.72 Disc: 1.36\n",
            "\n",
            "Epoch 65\n",
            "Time: 803.54s\n",
            "Gen Loss: 10.2031\n",
            "Disc Loss: 1.3477\n",
            "\n",
            "Train PSNR: 24.96 dB\n",
            "Train SSIM: 0.9810\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9870\n",
            "Batch 0 | PSNR: 25.03 | SSIM: 0.981\n",
            "Gen: 9.91 Disc: 1.38\n",
            "Batch 100 | PSNR: 24.90 | SSIM: 0.981\n",
            "Gen: 10.03 Disc: 1.34\n",
            "Batch 200 | PSNR: 24.93 | SSIM: 0.981\n",
            "Gen: 10.16 Disc: 1.36\n",
            "Batch 300 | PSNR: 24.92 | SSIM: 0.981\n",
            "Gen: 9.98 Disc: 1.33\n",
            "Batch 400 | PSNR: 24.92 | SSIM: 0.981\n",
            "Gen: 10.55 Disc: 1.34\n",
            "Batch 500 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.10 Disc: 1.33\n",
            "Batch 600 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.40 Disc: 1.41\n",
            "Batch 700 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.29 Disc: 1.33\n",
            "Batch 800 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.44 Disc: 1.37\n",
            "Batch 900 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 9.71 Disc: 1.33\n",
            "Batch 1000 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.32 Disc: 1.36\n",
            "Batch 1100 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.39 Disc: 1.37\n",
            "Batch 1200 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.84 Disc: 1.38\n",
            "Batch 1300 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.21 Disc: 1.39\n",
            "Batch 1400 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.51 Disc: 1.37\n",
            "Batch 1500 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.60 Disc: 1.29\n",
            "Batch 1600 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.46 Disc: 1.31\n",
            "Batch 1700 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.41 Disc: 1.39\n",
            "Batch 1800 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.34 Disc: 1.33\n",
            "Batch 1900 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.92 Disc: 1.38\n",
            "Batch 2000 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.04 Disc: 1.33\n",
            "Batch 2100 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.68 Disc: 1.33\n",
            "Batch 2200 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.41 Disc: 1.33\n",
            "Batch 2300 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.96 Disc: 1.35\n",
            "Batch 2400 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.80 Disc: 1.37\n",
            "Batch 2500 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.41 Disc: 1.36\n",
            "\n",
            "Epoch 66\n",
            "Time: 800.13s\n",
            "Gen Loss: 10.1953\n",
            "Disc Loss: 1.3506\n",
            "\n",
            "Train PSNR: 24.95 dB\n",
            "Train SSIM: 0.9810\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9619\n",
            "Batch 0 | PSNR: 24.31 | SSIM: 0.978\n",
            "Gen: 10.09 Disc: 1.37\n",
            "Batch 100 | PSNR: 24.91 | SSIM: 0.981\n",
            "Gen: 10.33 Disc: 1.35\n",
            "Batch 200 | PSNR: 24.89 | SSIM: 0.981\n",
            "Gen: 10.35 Disc: 1.29\n",
            "Batch 300 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.02 Disc: 1.35\n",
            "Batch 400 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.98 Disc: 1.32\n",
            "Batch 500 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 10.51 Disc: 1.35\n",
            "Batch 600 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.79 Disc: 1.36\n",
            "Batch 700 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.26 Disc: 1.35\n",
            "Batch 800 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.32 Disc: 1.33\n",
            "Batch 900 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.95 Disc: 1.36\n",
            "Batch 1000 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.13 Disc: 1.38\n",
            "Batch 1100 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.75 Disc: 1.31\n",
            "Batch 1200 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.04 Disc: 1.40\n",
            "Batch 1300 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.38 Disc: 1.32\n",
            "Batch 1400 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.05 Disc: 1.41\n",
            "Batch 1500 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.44 Disc: 1.38\n",
            "Batch 1600 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.38 Disc: 1.34\n",
            "Batch 1700 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.51 Disc: 1.34\n",
            "Batch 1800 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.79 Disc: 1.35\n",
            "Batch 1900 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.02 Disc: 1.37\n",
            "Batch 2000 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.34 Disc: 1.31\n",
            "Batch 2100 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.25 Disc: 1.37\n",
            "Batch 2200 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.09 Disc: 1.29\n",
            "Batch 2300 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.14 Disc: 1.38\n",
            "Batch 2400 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.77 Disc: 1.33\n",
            "Batch 2500 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 9.96 Disc: 1.36\n",
            "\n",
            "Epoch 67\n",
            "Time: 809.36s\n",
            "Gen Loss: 10.1875\n",
            "Disc Loss: 1.3496\n",
            "\n",
            "Train PSNR: 24.96 dB\n",
            "Train SSIM: 0.9811\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9774\n",
            "Batch 0 | PSNR: 24.61 | SSIM: 0.980\n",
            "Gen: 10.41 Disc: 1.37\n",
            "Batch 100 | PSNR: 24.99 | SSIM: 0.981\n",
            "Gen: 10.25 Disc: 1.30\n",
            "Batch 200 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.03 Disc: 1.34\n",
            "Batch 300 | PSNR: 24.95 | SSIM: 0.981\n",
            "Gen: 9.88 Disc: 1.34\n",
            "Batch 400 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.27 Disc: 1.39\n",
            "Batch 500 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.09 Disc: 1.36\n",
            "Batch 600 | PSNR: 24.96 | SSIM: 0.981\n",
            "Gen: 10.32 Disc: 1.33\n",
            "Batch 700 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.44 Disc: 1.33\n",
            "Batch 800 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.80 Disc: 1.30\n",
            "Batch 900 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 10.12 Disc: 1.35\n",
            "Batch 1000 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 9.90 Disc: 1.42\n",
            "Batch 1100 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 9.72 Disc: 1.40\n",
            "Batch 1200 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.36 Disc: 1.39\n",
            "Batch 1300 | PSNR: 24.98 | SSIM: 0.981\n",
            "Gen: 10.38 Disc: 1.32\n",
            "Batch 1400 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 9.98 Disc: 1.31\n",
            "Batch 1500 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 9.52 Disc: 1.35\n",
            "Batch 1600 | PSNR: 24.97 | SSIM: 0.981\n",
            "Gen: 9.95 Disc: 1.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Inference Function\n",
        "# ----------------------\n",
        "def colorize_image(model, image_path, output_path, image_size=64):\n",
        "    \"\"\"\n",
        "    Colorizes a single image using the trained generator.\n",
        "\n",
        "    Args:\n",
        "        model: Trained generator model\n",
        "        image_path: Path to input grayscale/RGB image\n",
        "        output_path: Path to save colorized image\n",
        "        image_size: Size to resize image (must match model input)\n",
        "    \"\"\"\n",
        "    # Load and preprocess image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Could not load image at {image_path}\")\n",
        "\n",
        "    # Convert to RGB if needed\n",
        "    if image.ndim == 2:  # Grayscale\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "    else:  # BGR to RGB\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize and normalize\n",
        "    image = cv2.resize(image, (image_size, image_size))\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "\n",
        "    # Convert to LAB and extract L channel\n",
        "    lab = rgb2lab(image)\n",
        "    L = lab[:, :, 0:1]  # (H, W, 1)\n",
        "\n",
        "    # Add batch dimension and predict\n",
        "    L_batch = np.expand_dims(L, axis=0)  # (1, H, W, 1)\n",
        "    AB_pred = model.predict(L_batch, verbose=0)[0]  # (H, W, 2)\n",
        "\n",
        "    # Denormalize AB channels\n",
        "    AB_pred = (AB_pred * 128.0).astype(np.float32)\n",
        "\n",
        "    # Combine with L and convert to RGB\n",
        "    colorized_lab = np.concatenate([L, AB_pred], axis=-1)\n",
        "    colorized_rgb = lab2rgb(colorized_lab)\n",
        "\n",
        "    # Clip and save\n",
        "    colorized_rgb = np.clip(colorized_rgb, 0, 1)\n",
        "    plt.imsave(output_path, colorized_rgb)\n",
        "    print(f\"Colorized image saved to {output_path}\")"
      ],
      "metadata": {
        "id": "PmQiENqcR8bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training, use like this:\n",
        "colorize_image(\n",
        "    generator,\n",
        "    \"/content/Test/rose.jpeg\",  # Input path\n",
        "    \"/content/colorized_result.jpg\"     # Output path\n",
        ")"
      ],
      "metadata": {
        "id": "TfAazZuISFbG",
        "outputId": "172a98cc-4476-4f05-85db-fc702519f131",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colorized image saved to /content/colorized_result.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Parallel Video Colorization with Temporal Consistency\n",
        "# ----------------------\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "# ----------------------\n",
        "# Video Colorizer with Content Directory Temp Files\n",
        "# ----------------------\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "class VideoColorizer:\n",
        "    def __init__(self, model, temporal_alpha=0.8, blend_factor=0.7):\n",
        "        self.model = model\n",
        "        self.temporal_alpha = temporal_alpha\n",
        "        self.blend_factor = blend_factor\n",
        "        # Optical flow parameters\n",
        "        self.flow_params = {\n",
        "            'pyr_scale': 0.5,\n",
        "            'levels': 3,\n",
        "            'winsize': 15,\n",
        "            'iterations': 3,\n",
        "            'poly_n': 5,\n",
        "            'poly_sigma': 1.2,\n",
        "            'flags': cv2.OPTFLOW_FARNEBACK_GAUSSIAN\n",
        "        }\n",
        "        # Create temp directory in Colab's content directory\n",
        "        self.temp_dir = tempfile.TemporaryDirectory(\n",
        "            dir='/content',\n",
        "            prefix='colorizer_temp_'\n",
        "        )\n",
        "        os.makedirs(self.temp_dir.name, exist_ok=True)\n",
        "        os.chmod(self.temp_dir.name, 0o777)  # Ensure write permissions\n",
        "        print(f\"Created temp directory at: {self.temp_dir.name}\")\n",
        "\n",
        "    def _process_chunk(self, frames, start_idx):\n",
        "        \"\"\"Process a chunk of frames in parallel\"\"\"\n",
        "        print(f\"Processing chunk starting at {start_idx} with {len(frames)} frames\")\n",
        "\n",
        "        for local_idx, frame in enumerate(frames):\n",
        "            global_idx = start_idx + local_idx\n",
        "            save_path = os.path.join(\n",
        "                self.temp_dir.name,\n",
        "                f\"frame_{global_idx:06d}.npy\"  # Consistent naming\n",
        "            )\n",
        "\n",
        "            # Debug: Verify frame content\n",
        "            if frame is None or frame.size == 0:\n",
        "                raise ValueError(f\"Invalid frame at index {global_idx}\")\n",
        "\n",
        "            # Colorization pipeline\n",
        "            resized_rgb = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), (64, 64))\n",
        "            lab = rgb2lab(resized_rgb.astype(np.float32)/255.0)\n",
        "            L = lab[:, :, 0:1]\n",
        "            AB = self.model.predict(np.expand_dims(L, axis=0), verbose=0)[0]\n",
        "\n",
        "            # Save data with verification\n",
        "            data = {\n",
        "                'frame': frame,\n",
        "                'L': L,\n",
        "                'AB': AB,\n",
        "                'gray': cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            }\n",
        "            np.save(save_path, data)\n",
        "            print(f\"Saved frame {global_idx} to {save_path}\")\n",
        "\n",
        "        # Immediate verification of saved files\n",
        "        saved_files = [f for f in os.listdir(self.temp_dir.name)\n",
        "                      if f.startswith(f\"frame_{start_idx:06d}\")]\n",
        "        print(f\"Saved {len(saved_files)} files in this chunk\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _temporal_smooth(self, prev_data, current_data):\n",
        "        \"\"\"Apply temporal consistency between frames\"\"\"\n",
        "        if prev_data is None:\n",
        "            return current_data['AB']\n",
        "\n",
        "        # Compute optical flow at model resolution\n",
        "        target_size = (64, 64)\n",
        "        prev_gray = cv2.resize(prev_data['gray'], target_size)\n",
        "        current_gray = cv2.resize(current_data['gray'], target_size)\n",
        "\n",
        "        flow = cv2.calcOpticalFlowFarneback(\n",
        "            prev_gray, current_gray,\n",
        "            None, **self.flow_params\n",
        "        )\n",
        "\n",
        "        # Create normalized coordinate grid\n",
        "        h, w = target_size\n",
        "        x_map, y_map = np.meshgrid(np.arange(w), np.arange(h))\n",
        "        flow_map = np.stack([\n",
        "           (x_map + flow[..., 0]).astype(np.float32),\n",
        "           (y_map + flow[..., 1]).astype(np.float32)\n",
        "        ], axis=-1)\n",
        "\n",
        "        # Ensure coordinates stay within image bounds\n",
        "        flow_map[..., 0] = np.clip(flow_map[..., 0], 0, w-1)\n",
        "        flow_map[..., 1] = np.clip(flow_map[..., 1], 0, h-1)\n",
        "\n",
        "\n",
        "\n",
        "        # Warp previous AB channels\n",
        "        warped_AB = cv2.remap(\n",
        "            prev_data['AB'].astype(np.float32),  # Ensure float32 input\n",
        "            flow_map,\n",
        "            None,\n",
        "            cv2.INTER_LINEAR,\n",
        "            borderMode=cv2.BORDER_REFLECT\n",
        "        )\n",
        "\n",
        "        # Handle invalid regions (black borders from warping)\n",
        "        mask = (warped_AB == 0).all(axis=-1, keepdims=True)\n",
        "        blended_AB = np.where(mask, current_data['AB'],\n",
        "                         self.blend_factor * current_data['AB'] +\n",
        "                         (1 - self.blend_factor) * warped_AB)\n",
        "\n",
        "        smoothed_AB = self.temporal_alpha * blended_AB + \\\n",
        "                     (1 - self.temporal_alpha) * warped_AB\n",
        "        return smoothed_AB\n",
        "\n",
        "\n",
        "    def colorize_video(self, input_path, output_path, batch_size=16, workers=8):\n",
        "        # Open video once for all processing\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(f\"Couldn't open video {input_path}\")\n",
        "\n",
        "        # Get video properties from the first frame\n",
        "        ret, first_frame = cap.read()\n",
        "        if not ret:\n",
        "            cap.release()\n",
        "            raise ValueError(\"Couldn't read first frame\")\n",
        "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        print(f\"Width: {frame_width} | Height: {frame_height} | FPS: {fps}\")\n",
        "        # Rewind to beginning\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "\n",
        "        # Initialize video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        writer = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height), isColor=True)\n",
        "\n",
        "        # Process frames in a single pass\n",
        "        executor = ThreadPoolExecutor(max_workers=workers)\n",
        "        futures = []\n",
        "        chunk = []\n",
        "        frame_count = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            chunk.append(frame)\n",
        "            frame_count += 1\n",
        "            if len(chunk) == batch_size:\n",
        "                future = executor.submit(self._process_chunk, chunk.copy(), frame_count - len(chunk))\n",
        "                futures.append(future)\n",
        "                chunk = []\n",
        "\n",
        "        # Process remaining frames\n",
        "        if chunk:\n",
        "            future = executor.submit(self._process_chunk, chunk, frame_count - len(chunk))\n",
        "            futures.append(future)\n",
        "\n",
        "        # Wait for all processing to finish\n",
        "        for f in futures:\n",
        "            f.result()\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "\n",
        "        # 4. Reconstruct video with temporal smoothing\n",
        "        saved_files = sorted(\n",
        "            [f for f in os.listdir(self.temp_dir.name)\n",
        "             if f.startswith('frame_') and f.endswith('.npy')],\n",
        "            key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
        "\n",
        "        prev_data = None\n",
        "        for i, filename in enumerate(saved_files):\n",
        "            file_path = os.path.join(self.temp_dir.name, filename)\n",
        "            data = np.load(file_path, allow_pickle=True).item()\n",
        "\n",
        "            # Apply temporal smoothing\n",
        "            smoothed_AB = self._temporal_smooth(prev_data, data)\n",
        "\n",
        "            # Reconstruct frame\n",
        "            rgb_resized = cv2.resize(\n",
        "                cv2.cvtColor(data['frame'], cv2.COLOR_BGR2RGB),\n",
        "                (64, 64))\n",
        "            lab = rgb2lab(rgb_resized.astype(np.float32)/255.0)\n",
        "            final_lab = np.concatenate([lab[..., 0:1], smoothed_AB], axis=-1)\n",
        "\n",
        "            # Convert to output dimensions\n",
        "            colorized_rgb = (lab2rgb(final_lab) * 255).astype(np.uint8)\n",
        "            final_frame = cv2.resize(\n",
        "            colorized_rgb,\n",
        "            (frame_width, frame_height))\n",
        "            final_bgr = cv2.cvtColor(final_frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            writer.write(final_bgr)\n",
        "\n",
        "            prev_data = {'AB': smoothed_AB, 'gray': data['gray']}\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Processed {i+1}/{len(saved_files)} frames\")\n",
        "\n",
        "        # 5. Final cleanup\n",
        "        writer.release()\n",
        "        self.temp_dir.cleanup()\n",
        "\n",
        "        # Verify output\n",
        "        if os.path.exists(output_path):\n",
        "            print(f\"\\n✅ Success! Colorized video saved to: {output_path}\")\n",
        "            print(f\"Resolution: {frame_width}x{frame_height} | Frames: {len(saved_files)}\")\n",
        "        else:\n",
        "            print(\"\\n❌ Video creation failed - check codec compatibility\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6FYBJCluSoP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colorizer = VideoColorizer(generator, temporal_alpha=0.85)\n",
        "\n",
        "\n",
        "colorizer.colorize_video(\n",
        "    \"/content/drive/MyDrive/Colorization/Video/Input.mp4\",\n",
        "    \"/content/drive/MyDrive/Colorization/Video/Output.mp4\",\n",
        "    batch_size=32,\n",
        "    workers=8,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiFkW4nLYBbb",
        "outputId": "2b0e2f67-8508-4099-abcb-163c3a8779f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created temp directory at: /content/colorizer_temp_qa9brar1\n",
            "Width: 1280 | Height: 720 | FPS: 29.97002997002997\n",
            "Processing chunk starting at 0 with 32 frames\n",
            "Processing chunk starting at 32 with 32 frames\n",
            "Processing chunk starting at 64 with 32 frames\n",
            "Processing chunk starting at 96 with 32 frames\n",
            "Processing chunk starting at 128 with 32 frames\n",
            "Processing chunk starting at 160 with 32 frames\n",
            "Processing chunk starting at 192 with 32 frames\n",
            "Processing chunk starting at 224 with 32 frames\n",
            "Saved frame 224 to /content/colorizer_temp_qa9brar1/frame_000224.npy\n",
            "Saved frame 160 to /content/colorizer_temp_qa9brar1/frame_000160.npy\n",
            "Saved frame 0 to /content/colorizer_temp_qa9brar1/frame_000000.npy\n",
            "Saved frame 96 to /content/colorizer_temp_qa9brar1/frame_000096.npy\n",
            "Saved frame 32 to /content/colorizer_temp_qa9brar1/frame_000032.npy\n",
            "Saved frame 192 to /content/colorizer_temp_qa9brar1/frame_000192.npy\n",
            "Saved frame 64 to /content/colorizer_temp_qa9brar1/frame_000064.npy\n",
            "Saved frame 128 to /content/colorizer_temp_qa9brar1/frame_000128.npy\n",
            "Saved frame 161 to /content/colorizer_temp_qa9brar1/frame_000161.npy\n",
            "Saved frame 1 to /content/colorizer_temp_qa9brar1/frame_000001.npy\n",
            "Saved frame 225 to /content/colorizer_temp_qa9brar1/frame_000225.npy\n",
            "Saved frame 33 to /content/colorizer_temp_qa9brar1/frame_000033.npy\n",
            "Saved frame 97 to /content/colorizer_temp_qa9brar1/frame_000097.npy\n",
            "Saved frame 193 to /content/colorizer_temp_qa9brar1/frame_000193.npy\n",
            "Saved frame 65 to /content/colorizer_temp_qa9brar1/frame_000065.npy\n",
            "Saved frame 129 to /content/colorizer_temp_qa9brar1/frame_000129.npy\n",
            "Saved frame 162 to /content/colorizer_temp_qa9brar1/frame_000162.npy\n",
            "Saved frame 2 to /content/colorizer_temp_qa9brar1/frame_000002.npy\n",
            "Saved frame 226 to /content/colorizer_temp_qa9brar1/frame_000226.npy\n",
            "Saved frame 34 to /content/colorizer_temp_qa9brar1/frame_000034.npy\n",
            "Saved frame 98 to /content/colorizer_temp_qa9brar1/frame_000098.npy\n",
            "Saved frame 66 to /content/colorizer_temp_qa9brar1/frame_000066.npy\n",
            "Saved frame 194 to /content/colorizer_temp_qa9brar1/frame_000194.npy\n",
            "Saved frame 130 to /content/colorizer_temp_qa9brar1/frame_000130.npy\n",
            "Saved frame 163 to /content/colorizer_temp_qa9brar1/frame_000163.npy\n",
            "Saved frame 35 to /content/colorizer_temp_qa9brar1/frame_000035.npy\n",
            "Saved frame 227 to /content/colorizer_temp_qa9brar1/frame_000227.npy\n",
            "Saved frame 3 to /content/colorizer_temp_qa9brar1/frame_000003.npy\n",
            "Saved frame 99 to /content/colorizer_temp_qa9brar1/frame_000099.npy\n",
            "Saved frame 195 to /content/colorizer_temp_qa9brar1/frame_000195.npy\n",
            "Saved frame 67 to /content/colorizer_temp_qa9brar1/frame_000067.npy\n",
            "Saved frame 131 to /content/colorizer_temp_qa9brar1/frame_000131.npy\n",
            "Saved frame 164 to /content/colorizer_temp_qa9brar1/frame_000164.npy\n",
            "Saved frame 228 to /content/colorizer_temp_qa9brar1/frame_000228.npy\n",
            "Saved frame 36 to /content/colorizer_temp_qa9brar1/frame_000036.npy\n",
            "Saved frame 4 to /content/colorizer_temp_qa9brar1/frame_000004.npy\n",
            "Saved frame 100 to /content/colorizer_temp_qa9brar1/frame_000100.npy\n",
            "Saved frame 196 to /content/colorizer_temp_qa9brar1/frame_000196.npy\n",
            "Saved frame 132 to /content/colorizer_temp_qa9brar1/frame_000132.npy\n",
            "Saved frame 68 to /content/colorizer_temp_qa9brar1/frame_000068.npy\n",
            "Saved frame 165 to /content/colorizer_temp_qa9brar1/frame_000165.npy\n",
            "Saved frame 37 to /content/colorizer_temp_qa9brar1/frame_000037.npy\n",
            "Saved frame 229 to /content/colorizer_temp_qa9brar1/frame_000229.npy\n",
            "Saved frame 5 to /content/colorizer_temp_qa9brar1/frame_000005.npy\n",
            "Saved frame 197 to /content/colorizer_temp_qa9brar1/frame_000197.npy\n",
            "Saved frame 133 to /content/colorizer_temp_qa9brar1/frame_000133.npy\n",
            "Saved frame 101 to /content/colorizer_temp_qa9brar1/frame_000101.npy\n",
            "Saved frame 69 to /content/colorizer_temp_qa9brar1/frame_000069.npy\n",
            "Saved frame 166 to /content/colorizer_temp_qa9brar1/frame_000166.npy\n",
            "Saved frame 38 to /content/colorizer_temp_qa9brar1/frame_000038.npy\n",
            "Saved frame 230 to /content/colorizer_temp_qa9brar1/frame_000230.npy\n",
            "Saved frame 6 to /content/colorizer_temp_qa9brar1/frame_000006.npy\n",
            "Saved frame 198 to /content/colorizer_temp_qa9brar1/frame_000198.npy\n",
            "Saved frame 102 to /content/colorizer_temp_qa9brar1/frame_000102.npy\n",
            "Saved frame 134 to /content/colorizer_temp_qa9brar1/frame_000134.npy\n",
            "Saved frame 70 to /content/colorizer_temp_qa9brar1/frame_000070.npy\n",
            "Saved frame 39 to /content/colorizer_temp_qa9brar1/frame_000039.npy\n",
            "Saved frame 167 to /content/colorizer_temp_qa9brar1/frame_000167.npy\n",
            "Saved frame 231 to /content/colorizer_temp_qa9brar1/frame_000231.npy\n",
            "Saved frame 7 to /content/colorizer_temp_qa9brar1/frame_000007.npy\n",
            "Saved frame 199 to /content/colorizer_temp_qa9brar1/frame_000199.npy\n",
            "Saved frame 103 to /content/colorizer_temp_qa9brar1/frame_000103.npy\n",
            "Saved frame 135 to /content/colorizer_temp_qa9brar1/frame_000135.npy\n",
            "Saved frame 71 to /content/colorizer_temp_qa9brar1/frame_000071.npy\n",
            "Saved frame 168 to /content/colorizer_temp_qa9brar1/frame_000168.npy\n",
            "Saved frame 40 to /content/colorizer_temp_qa9brar1/frame_000040.npy\n",
            "Saved frame 232 to /content/colorizer_temp_qa9brar1/frame_000232.npy\n",
            "Saved frame 8 to /content/colorizer_temp_qa9brar1/frame_000008.npy\n",
            "Saved frame 104 to /content/colorizer_temp_qa9brar1/frame_000104.npy\n",
            "Saved frame 200 to /content/colorizer_temp_qa9brar1/frame_000200.npy\n",
            "Saved frame 136 to /content/colorizer_temp_qa9brar1/frame_000136.npy\n",
            "Saved frame 72 to /content/colorizer_temp_qa9brar1/frame_000072.npy\n",
            "Saved frame 41 to /content/colorizer_temp_qa9brar1/frame_000041.npy\n",
            "Saved frame 169 to /content/colorizer_temp_qa9brar1/frame_000169.npy\n",
            "Saved frame 9 to /content/colorizer_temp_qa9brar1/frame_000009.npy\n",
            "Saved frame 233 to /content/colorizer_temp_qa9brar1/frame_000233.npy\n",
            "Saved frame 105 to /content/colorizer_temp_qa9brar1/frame_000105.npy\n",
            "Saved frame 73 to /content/colorizer_temp_qa9brar1/frame_000073.npy\n",
            "Saved frame 201 to /content/colorizer_temp_qa9brar1/frame_000201.npy\n",
            "Saved frame 137 to /content/colorizer_temp_qa9brar1/frame_000137.npy\n",
            "Saved frame 42 to /content/colorizer_temp_qa9brar1/frame_000042.npy\n",
            "Saved frame 170 to /content/colorizer_temp_qa9brar1/frame_000170.npy\n",
            "Saved frame 10 to /content/colorizer_temp_qa9brar1/frame_000010.npy\n",
            "Saved frame 234 to /content/colorizer_temp_qa9brar1/frame_000234.npy\n",
            "Saved frame 106 to /content/colorizer_temp_qa9brar1/frame_000106.npy\n",
            "Saved frame 138 to /content/colorizer_temp_qa9brar1/frame_000138.npy\n",
            "Saved frame 202 to /content/colorizer_temp_qa9brar1/frame_000202.npy\n",
            "Saved frame 74 to /content/colorizer_temp_qa9brar1/frame_000074.npy\n",
            "Saved frame 43 to /content/colorizer_temp_qa9brar1/frame_000043.npy\n",
            "Saved frame 171 to /content/colorizer_temp_qa9brar1/frame_000171.npy\n",
            "Saved frame 11 to /content/colorizer_temp_qa9brar1/frame_000011.npy\n",
            "Saved frame 235 to /content/colorizer_temp_qa9brar1/frame_000235.npy\n",
            "Saved frame 107 to /content/colorizer_temp_qa9brar1/frame_000107.npy\n",
            "Saved frame 139 to /content/colorizer_temp_qa9brar1/frame_000139.npy\n",
            "Saved frame 203 to /content/colorizer_temp_qa9brar1/frame_000203.npy\n",
            "Saved frame 75 to /content/colorizer_temp_qa9brar1/frame_000075.npy\n",
            "Saved frame 44 to /content/colorizer_temp_qa9brar1/frame_000044.npy\n",
            "Saved frame 12 to /content/colorizer_temp_qa9brar1/frame_000012.npy\n",
            "Saved frame 172 to /content/colorizer_temp_qa9brar1/frame_000172.npy\n",
            "Saved frame 236 to /content/colorizer_temp_qa9brar1/frame_000236.npy\n",
            "Saved frame 140 to /content/colorizer_temp_qa9brar1/frame_000140.npy\n",
            "Saved frame 108 to /content/colorizer_temp_qa9brar1/frame_000108.npy\n",
            "Saved frame 204 to /content/colorizer_temp_qa9brar1/frame_000204.npy\n",
            "Saved frame 76 to /content/colorizer_temp_qa9brar1/frame_000076.npy\n",
            "Saved frame 13 to /content/colorizer_temp_qa9brar1/frame_000013.npy\n",
            "Saved frame 237 to /content/colorizer_temp_qa9brar1/frame_000237.npy\n",
            "Saved frame 45 to /content/colorizer_temp_qa9brar1/frame_000045.npy\n",
            "Saved frame 173 to /content/colorizer_temp_qa9brar1/frame_000173.npy\n",
            "Saved frame 205 to /content/colorizer_temp_qa9brar1/frame_000205.npy\n",
            "Saved frame 141 to /content/colorizer_temp_qa9brar1/frame_000141.npy\n",
            "Saved frame 109 to /content/colorizer_temp_qa9brar1/frame_000109.npy\n",
            "Saved frame 77 to /content/colorizer_temp_qa9brar1/frame_000077.npy\n",
            "Saved frame 14 to /content/colorizer_temp_qa9brar1/frame_000014.npy\n",
            "Saved frame 46 to /content/colorizer_temp_qa9brar1/frame_000046.npy\n",
            "Saved frame 238 to /content/colorizer_temp_qa9brar1/frame_000238.npy\n",
            "Saved frame 174 to /content/colorizer_temp_qa9brar1/frame_000174.npy\n",
            "Saved frame 206 to /content/colorizer_temp_qa9brar1/frame_000206.npy\n",
            "Saved frame 142 to /content/colorizer_temp_qa9brar1/frame_000142.npy\n",
            "Saved frame 78 to /content/colorizer_temp_qa9brar1/frame_000078.npy\n",
            "Saved frame 110 to /content/colorizer_temp_qa9brar1/frame_000110.npy\n",
            "Saved frame 47 to /content/colorizer_temp_qa9brar1/frame_000047.npy\n",
            "Saved frame 15 to /content/colorizer_temp_qa9brar1/frame_000015.npy\n",
            "Saved frame 239 to /content/colorizer_temp_qa9brar1/frame_000239.npy\n",
            "Saved frame 175 to /content/colorizer_temp_qa9brar1/frame_000175.npy\n",
            "Saved frame 207 to /content/colorizer_temp_qa9brar1/frame_000207.npy\n",
            "Saved frame 79 to /content/colorizer_temp_qa9brar1/frame_000079.npy\n",
            "Saved frame 111 to /content/colorizer_temp_qa9brar1/frame_000111.npy\n",
            "Saved frame 143 to /content/colorizer_temp_qa9brar1/frame_000143.npy\n",
            "Saved frame 48 to /content/colorizer_temp_qa9brar1/frame_000048.npy\n",
            "Saved frame 176 to /content/colorizer_temp_qa9brar1/frame_000176.npy\n",
            "Saved frame 240 to /content/colorizer_temp_qa9brar1/frame_000240.npy\n",
            "Saved frame 16 to /content/colorizer_temp_qa9brar1/frame_000016.npy\n",
            "Saved frame 208 to /content/colorizer_temp_qa9brar1/frame_000208.npy\n",
            "Saved frame 80 to /content/colorizer_temp_qa9brar1/frame_000080.npy\n",
            "Saved frame 112 to /content/colorizer_temp_qa9brar1/frame_000112.npy\n",
            "Saved frame 144 to /content/colorizer_temp_qa9brar1/frame_000144.npy\n",
            "Saved frame 177 to /content/colorizer_temp_qa9brar1/frame_000177.npy\n",
            "Saved frame 49 to /content/colorizer_temp_qa9brar1/frame_000049.npy\n",
            "Saved frame 17 to /content/colorizer_temp_qa9brar1/frame_000017.npy\n",
            "Saved frame 241 to /content/colorizer_temp_qa9brar1/frame_000241.npy\n",
            "Saved frame 209 to /content/colorizer_temp_qa9brar1/frame_000209.npy\n",
            "Saved frame 113 to /content/colorizer_temp_qa9brar1/frame_000113.npy\n",
            "Saved frame 81 to /content/colorizer_temp_qa9brar1/frame_000081.npy\n",
            "Saved frame 145 to /content/colorizer_temp_qa9brar1/frame_000145.npy\n",
            "Saved frame 178 to /content/colorizer_temp_qa9brar1/frame_000178.npy\n",
            "Saved frame 18 to /content/colorizer_temp_qa9brar1/frame_000018.npy\n",
            "Saved frame 50 to /content/colorizer_temp_qa9brar1/frame_000050.npy\n",
            "Saved frame 242 to /content/colorizer_temp_qa9brar1/frame_000242.npy\n",
            "Saved frame 114 to /content/colorizer_temp_qa9brar1/frame_000114.npy\n",
            "Saved frame 210 to /content/colorizer_temp_qa9brar1/frame_000210.npy\n",
            "Saved frame 82 to /content/colorizer_temp_qa9brar1/frame_000082.npy\n",
            "Saved frame 146 to /content/colorizer_temp_qa9brar1/frame_000146.npy\n",
            "Saved frame 179 to /content/colorizer_temp_qa9brar1/frame_000179.npy\n",
            "Saved frame 19 to /content/colorizer_temp_qa9brar1/frame_000019.npy\n",
            "Saved frame 51 to /content/colorizer_temp_qa9brar1/frame_000051.npy\n",
            "Saved frame 243 to /content/colorizer_temp_qa9brar1/frame_000243.npy\n",
            "Saved frame 115 to /content/colorizer_temp_qa9brar1/frame_000115.npy\n",
            "Saved frame 83 to /content/colorizer_temp_qa9brar1/frame_000083.npy\n",
            "Saved frame 211 to /content/colorizer_temp_qa9brar1/frame_000211.npy\n",
            "Saved frame 147 to /content/colorizer_temp_qa9brar1/frame_000147.npySaved frame 180 to /content/colorizer_temp_qa9brar1/frame_000180.npy\n",
            "\n",
            "Saved frame 20 to /content/colorizer_temp_qa9brar1/frame_000020.npy\n",
            "Saved frame 52 to /content/colorizer_temp_qa9brar1/frame_000052.npy\n",
            "Saved frame 244 to /content/colorizer_temp_qa9brar1/frame_000244.npy\n",
            "Saved frame 84 to /content/colorizer_temp_qa9brar1/frame_000084.npy\n",
            "Saved frame 116 to /content/colorizer_temp_qa9brar1/frame_000116.npy\n",
            "Saved frame 212 to /content/colorizer_temp_qa9brar1/frame_000212.npy\n",
            "Saved frame 181 to /content/colorizer_temp_qa9brar1/frame_000181.npy\n",
            "Saved frame 148 to /content/colorizer_temp_qa9brar1/frame_000148.npy\n",
            "Saved frame 21 to /content/colorizer_temp_qa9brar1/frame_000021.npy\n",
            "Saved frame 53 to /content/colorizer_temp_qa9brar1/frame_000053.npy\n",
            "Saved frame 117 to /content/colorizer_temp_qa9brar1/frame_000117.npy\n",
            "Saved frame 245 to /content/colorizer_temp_qa9brar1/frame_000245.npy\n",
            "Saved frame 213 to /content/colorizer_temp_qa9brar1/frame_000213.npy\n",
            "Saved frame 85 to /content/colorizer_temp_qa9brar1/frame_000085.npy\n",
            "Saved frame 182 to /content/colorizer_temp_qa9brar1/frame_000182.npy\n",
            "Saved frame 149 to /content/colorizer_temp_qa9brar1/frame_000149.npy\n",
            "Saved frame 22 to /content/colorizer_temp_qa9brar1/frame_000022.npy\n",
            "Saved frame 118 to /content/colorizer_temp_qa9brar1/frame_000118.npy\n",
            "Saved frame 54 to /content/colorizer_temp_qa9brar1/frame_000054.npy\n",
            "Saved frame 246 to /content/colorizer_temp_qa9brar1/frame_000246.npy\n",
            "Saved frame 214 to /content/colorizer_temp_qa9brar1/frame_000214.npy\n",
            "Saved frame 86 to /content/colorizer_temp_qa9brar1/frame_000086.npy\n",
            "Saved frame 183 to /content/colorizer_temp_qa9brar1/frame_000183.npy\n",
            "Saved frame 23 to /content/colorizer_temp_qa9brar1/frame_000023.npy\n",
            "Saved frame 150 to /content/colorizer_temp_qa9brar1/frame_000150.npy\n",
            "Saved frame 55 to /content/colorizer_temp_qa9brar1/frame_000055.npy\n",
            "Saved frame 119 to /content/colorizer_temp_qa9brar1/frame_000119.npy\n",
            "Saved frame 247 to /content/colorizer_temp_qa9brar1/frame_000247.npy\n",
            "Saved frame 215 to /content/colorizer_temp_qa9brar1/frame_000215.npy\n",
            "Saved frame 87 to /content/colorizer_temp_qa9brar1/frame_000087.npy\n",
            "Saved frame 184 to /content/colorizer_temp_qa9brar1/frame_000184.npySaved frame 24 to /content/colorizer_temp_qa9brar1/frame_000024.npy\n",
            "\n",
            "Saved frame 151 to /content/colorizer_temp_qa9brar1/frame_000151.npy\n",
            "Saved frame 56 to /content/colorizer_temp_qa9brar1/frame_000056.npy\n",
            "Saved frame 120 to /content/colorizer_temp_qa9brar1/frame_000120.npy\n",
            "Saved frame 248 to /content/colorizer_temp_qa9brar1/frame_000248.npy\n",
            "Saved frame 216 to /content/colorizer_temp_qa9brar1/frame_000216.npy\n",
            "Saved frame 88 to /content/colorizer_temp_qa9brar1/frame_000088.npy\n",
            "Saved frame 25 to /content/colorizer_temp_qa9brar1/frame_000025.npy\n",
            "Saved frame 185 to /content/colorizer_temp_qa9brar1/frame_000185.npy\n",
            "Saved frame 152 to /content/colorizer_temp_qa9brar1/frame_000152.npy\n",
            "Saved frame 57 to /content/colorizer_temp_qa9brar1/frame_000057.npy\n",
            "Saved frame 121 to /content/colorizer_temp_qa9brar1/frame_000121.npy\n",
            "Saved frame 217 to /content/colorizer_temp_qa9brar1/frame_000217.npy\n",
            "Saved frame 249 to /content/colorizer_temp_qa9brar1/frame_000249.npy\n",
            "Saved frame 89 to /content/colorizer_temp_qa9brar1/frame_000089.npy\n",
            "Saved frame 186 to /content/colorizer_temp_qa9brar1/frame_000186.npy\n",
            "Saved frame 26 to /content/colorizer_temp_qa9brar1/frame_000026.npy\n",
            "Saved frame 153 to /content/colorizer_temp_qa9brar1/frame_000153.npy\n",
            "Saved frame 58 to /content/colorizer_temp_qa9brar1/frame_000058.npy\n",
            "Saved frame 250 to /content/colorizer_temp_qa9brar1/frame_000250.npy\n",
            "Saved frame 122 to /content/colorizer_temp_qa9brar1/frame_000122.npy\n",
            "Saved frame 218 to /content/colorizer_temp_qa9brar1/frame_000218.npy\n",
            "Saved frame 90 to /content/colorizer_temp_qa9brar1/frame_000090.npy\n",
            "Saved frame 27 to /content/colorizer_temp_qa9brar1/frame_000027.npySaved frame 187 to /content/colorizer_temp_qa9brar1/frame_000187.npy\n",
            "\n",
            "Saved frame 154 to /content/colorizer_temp_qa9brar1/frame_000154.npy\n",
            "Saved frame 59 to /content/colorizer_temp_qa9brar1/frame_000059.npy\n",
            "Saved frame 123 to /content/colorizer_temp_qa9brar1/frame_000123.npy\n",
            "Saved frame 251 to /content/colorizer_temp_qa9brar1/frame_000251.npy\n",
            "Saved frame 219 to /content/colorizer_temp_qa9brar1/frame_000219.npy\n",
            "Saved frame 91 to /content/colorizer_temp_qa9brar1/frame_000091.npy\n",
            "Saved frame 28 to /content/colorizer_temp_qa9brar1/frame_000028.npy\n",
            "Saved frame 188 to /content/colorizer_temp_qa9brar1/frame_000188.npy\n",
            "Saved frame 155 to /content/colorizer_temp_qa9brar1/frame_000155.npy\n",
            "Saved frame 60 to /content/colorizer_temp_qa9brar1/frame_000060.npy\n",
            "Saved frame 124 to /content/colorizer_temp_qa9brar1/frame_000124.npy\n",
            "Saved frame 252 to /content/colorizer_temp_qa9brar1/frame_000252.npy\n",
            "Saved frame 220 to /content/colorizer_temp_qa9brar1/frame_000220.npy\n",
            "Saved frame 92 to /content/colorizer_temp_qa9brar1/frame_000092.npy\n",
            "Saved frame 29 to /content/colorizer_temp_qa9brar1/frame_000029.npy\n",
            "Saved frame 189 to /content/colorizer_temp_qa9brar1/frame_000189.npy\n",
            "Saved frame 125 to /content/colorizer_temp_qa9brar1/frame_000125.npy\n",
            "Saved frame 61 to /content/colorizer_temp_qa9brar1/frame_000061.npy\n",
            "Saved frame 156 to /content/colorizer_temp_qa9brar1/frame_000156.npy\n",
            "Saved frame 253 to /content/colorizer_temp_qa9brar1/frame_000253.npy\n",
            "Saved frame 221 to /content/colorizer_temp_qa9brar1/frame_000221.npy\n",
            "Saved frame 93 to /content/colorizer_temp_qa9brar1/frame_000093.npySaved frame 30 to /content/colorizer_temp_qa9brar1/frame_000030.npy\n",
            "\n",
            "Saved frame 190 to /content/colorizer_temp_qa9brar1/frame_000190.npy\n",
            "Saved frame 126 to /content/colorizer_temp_qa9brar1/frame_000126.npy\n",
            "Saved frame 62 to /content/colorizer_temp_qa9brar1/frame_000062.npy\n",
            "Saved frame 157 to /content/colorizer_temp_qa9brar1/frame_000157.npy\n",
            "Saved frame 254 to /content/colorizer_temp_qa9brar1/frame_000254.npy\n",
            "Saved frame 94 to /content/colorizer_temp_qa9brar1/frame_000094.npy\n",
            "Saved frame 222 to /content/colorizer_temp_qa9brar1/frame_000222.npy\n",
            "Saved frame 31 to /content/colorizer_temp_qa9brar1/frame_000031.npy\n",
            "Saved frame 191 to /content/colorizer_temp_qa9brar1/frame_000191.npy\n",
            "Saved 1 files in this chunk\n",
            "Processing chunk starting at 256 with 32 frames\n",
            "Saved 1 files in this chunk\n",
            "Processing chunk starting at 288 with 32 frames\n",
            "Saved frame 63 to /content/colorizer_temp_qa9brar1/frame_000063.npy\n",
            "Saved frame 127 to /content/colorizer_temp_qa9brar1/frame_000127.npy\n",
            "Saved 1 files in this chunk\n",
            "Processing chunk starting at 320 with 4 frames\n",
            "Saved frame 158 to /content/colorizer_temp_qa9brar1/frame_000158.npy\n",
            "Saved 1 files in this chunk\n",
            "Saved frame 255 to /content/colorizer_temp_qa9brar1/frame_000255.npy\n",
            "Saved 1 files in this chunk\n",
            "Saved frame 95 to /content/colorizer_temp_qa9brar1/frame_000095.npy\n",
            "Saved 1 files in this chunk\n",
            "Saved frame 223 to /content/colorizer_temp_qa9brar1/frame_000223.npy\n",
            "Saved 1 files in this chunk\n",
            "Saved frame 288 to /content/colorizer_temp_qa9brar1/frame_000288.npy\n",
            "Saved frame 256 to /content/colorizer_temp_qa9brar1/frame_000256.npy\n",
            "Saved frame 159 to /content/colorizer_temp_qa9brar1/frame_000159.npy\n",
            "Saved frame 320 to /content/colorizer_temp_qa9brar1/frame_000320.npy\n",
            "Saved 1 files in this chunk\n",
            "Saved frame 289 to /content/colorizer_temp_qa9brar1/frame_000289.npy\n",
            "Saved frame 257 to /content/colorizer_temp_qa9brar1/frame_000257.npy\n",
            "Saved frame 321 to /content/colorizer_temp_qa9brar1/frame_000321.npy\n",
            "Saved frame 290 to /content/colorizer_temp_qa9brar1/frame_000290.npy\n",
            "Saved frame 258 to /content/colorizer_temp_qa9brar1/frame_000258.npy\n",
            "Saved frame 322 to /content/colorizer_temp_qa9brar1/frame_000322.npy\n",
            "Saved frame 291 to /content/colorizer_temp_qa9brar1/frame_000291.npy\n",
            "Saved frame 259 to /content/colorizer_temp_qa9brar1/frame_000259.npy\n",
            "Saved frame 323 to /content/colorizer_temp_qa9brar1/frame_000323.npy\n",
            "Saved 1 files in this chunk\n",
            "Saved frame 292 to /content/colorizer_temp_qa9brar1/frame_000292.npy\n",
            "Saved frame 260 to /content/colorizer_temp_qa9brar1/frame_000260.npy\n",
            "Saved frame 293 to /content/colorizer_temp_qa9brar1/frame_000293.npy\n",
            "Saved frame 261 to /content/colorizer_temp_qa9brar1/frame_000261.npy\n",
            "Saved frame 294 to /content/colorizer_temp_qa9brar1/frame_000294.npy\n",
            "Saved frame 262 to /content/colorizer_temp_qa9brar1/frame_000262.npy\n",
            "Saved frame 295 to /content/colorizer_temp_qa9brar1/frame_000295.npy\n",
            "Saved frame 263 to /content/colorizer_temp_qa9brar1/frame_000263.npy\n",
            "Saved frame 296 to /content/colorizer_temp_qa9brar1/frame_000296.npy\n",
            "Saved frame 264 to /content/colorizer_temp_qa9brar1/frame_000264.npy\n",
            "Saved frame 297 to /content/colorizer_temp_qa9brar1/frame_000297.npy\n",
            "Saved frame 265 to /content/colorizer_temp_qa9brar1/frame_000265.npy\n",
            "Saved frame 298 to /content/colorizer_temp_qa9brar1/frame_000298.npy\n",
            "Saved frame 266 to /content/colorizer_temp_qa9brar1/frame_000266.npy\n",
            "Saved frame 299 to /content/colorizer_temp_qa9brar1/frame_000299.npy\n",
            "Saved frame 267 to /content/colorizer_temp_qa9brar1/frame_000267.npy\n",
            "Saved frame 300 to /content/colorizer_temp_qa9brar1/frame_000300.npy\n",
            "Saved frame 268 to /content/colorizer_temp_qa9brar1/frame_000268.npy\n",
            "Saved frame 301 to /content/colorizer_temp_qa9brar1/frame_000301.npy\n",
            "Saved frame 269 to /content/colorizer_temp_qa9brar1/frame_000269.npy\n",
            "Saved frame 302 to /content/colorizer_temp_qa9brar1/frame_000302.npy\n",
            "Saved frame 270 to /content/colorizer_temp_qa9brar1/frame_000270.npy\n",
            "Saved frame 303 to /content/colorizer_temp_qa9brar1/frame_000303.npy\n",
            "Saved frame 271 to /content/colorizer_temp_qa9brar1/frame_000271.npy\n",
            "Saved frame 304 to /content/colorizer_temp_qa9brar1/frame_000304.npy\n",
            "Saved frame 272 to /content/colorizer_temp_qa9brar1/frame_000272.npy\n",
            "Saved frame 305 to /content/colorizer_temp_qa9brar1/frame_000305.npy\n",
            "Saved frame 273 to /content/colorizer_temp_qa9brar1/frame_000273.npy\n",
            "Saved frame 306 to /content/colorizer_temp_qa9brar1/frame_000306.npy\n",
            "Saved frame 274 to /content/colorizer_temp_qa9brar1/frame_000274.npy\n",
            "Saved frame 307 to /content/colorizer_temp_qa9brar1/frame_000307.npy\n",
            "Saved frame 275 to /content/colorizer_temp_qa9brar1/frame_000275.npy\n",
            "Saved frame 308 to /content/colorizer_temp_qa9brar1/frame_000308.npy\n",
            "Saved frame 276 to /content/colorizer_temp_qa9brar1/frame_000276.npy\n",
            "Saved frame 309 to /content/colorizer_temp_qa9brar1/frame_000309.npy\n",
            "Saved frame 277 to /content/colorizer_temp_qa9brar1/frame_000277.npy\n",
            "Saved frame 310 to /content/colorizer_temp_qa9brar1/frame_000310.npy\n",
            "Saved frame 278 to /content/colorizer_temp_qa9brar1/frame_000278.npy\n",
            "Saved frame 311 to /content/colorizer_temp_qa9brar1/frame_000311.npy\n",
            "Saved frame 279 to /content/colorizer_temp_qa9brar1/frame_000279.npy\n",
            "Saved frame 312 to /content/colorizer_temp_qa9brar1/frame_000312.npy\n",
            "Saved frame 280 to /content/colorizer_temp_qa9brar1/frame_000280.npy\n",
            "Saved frame 313 to /content/colorizer_temp_qa9brar1/frame_000313.npy\n",
            "Saved frame 281 to /content/colorizer_temp_qa9brar1/frame_000281.npy\n",
            "Saved frame 314 to /content/colorizer_temp_qa9brar1/frame_000314.npy\n",
            "Saved frame 282 to /content/colorizer_temp_qa9brar1/frame_000282.npy\n",
            "Saved frame 315 to /content/colorizer_temp_qa9brar1/frame_000315.npy\n",
            "Saved frame 283 to /content/colorizer_temp_qa9brar1/frame_000283.npy\n",
            "Saved frame 316 to /content/colorizer_temp_qa9brar1/frame_000316.npy\n",
            "Saved frame 284 to /content/colorizer_temp_qa9brar1/frame_000284.npy\n",
            "Saved frame 317 to /content/colorizer_temp_qa9brar1/frame_000317.npy\n",
            "Saved frame 285 to /content/colorizer_temp_qa9brar1/frame_000285.npy\n",
            "Saved frame 318 to /content/colorizer_temp_qa9brar1/frame_000318.npy\n",
            "Saved frame 286 to /content/colorizer_temp_qa9brar1/frame_000286.npy\n",
            "Saved frame 319 to /content/colorizer_temp_qa9brar1/frame_000319.npy\n",
            "Saved 1 files in this chunk\n",
            "Saved frame 287 to /content/colorizer_temp_qa9brar1/frame_000287.npy\n",
            "Saved 1 files in this chunk\n",
            "Processed 1/324 frames\n",
            "Processed 11/324 frames\n",
            "Processed 21/324 frames\n",
            "Processed 31/324 frames\n",
            "Processed 41/324 frames\n",
            "Processed 51/324 frames\n",
            "Processed 61/324 frames\n",
            "Processed 71/324 frames\n",
            "Processed 81/324 frames\n",
            "Processed 91/324 frames\n",
            "Processed 101/324 frames\n",
            "Processed 111/324 frames\n",
            "Processed 121/324 frames\n",
            "Processed 131/324 frames\n",
            "Processed 141/324 frames\n",
            "Processed 151/324 frames\n",
            "Processed 161/324 frames\n",
            "Processed 171/324 frames\n",
            "Processed 181/324 frames\n",
            "Processed 191/324 frames\n",
            "Processed 201/324 frames\n",
            "Processed 211/324 frames\n",
            "Processed 221/324 frames\n",
            "Processed 231/324 frames\n",
            "Processed 241/324 frames\n",
            "Processed 251/324 frames\n",
            "Processed 261/324 frames\n",
            "Processed 271/324 frames\n",
            "Processed 281/324 frames\n",
            "Processed 291/324 frames\n",
            "Processed 301/324 frames\n",
            "Processed 311/324 frames\n",
            "Processed 321/324 frames\n",
            "\n",
            "✅ Success! Colorized video saved to: /content/drive/MyDrive/Colorization/Video/Output.mp4\n",
            "Resolution: 1280x720 | Frames: 324\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffprobe -v error -show_entries format=duration \\\n",
        "         -of default=noprint_wrappers=1:nokey=1 \\\n",
        "         \"/content/drive/MyDrive/Colorization/Video/Input2.mp4\""
      ],
      "metadata": {
        "id": "xgdQCtYR15a1",
        "outputId": "46c2f802-f834-4ec5-bb9b-fe23578c4943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.600000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffprobe -v error -show_entries format=duration \\\n",
        "         -of default=noprint_wrappers=1:nokey=1 \\\n",
        "         \"/content/drive/MyDrive/Colorization/Video/Output.mp4\""
      ],
      "metadata": {
        "id": "OvhPd2Bn2uPW",
        "outputId": "1fe06ece-38de-4851-90ea-3d9953bb7182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.811000\n"
          ]
        }
      ]
    }
  ]
}