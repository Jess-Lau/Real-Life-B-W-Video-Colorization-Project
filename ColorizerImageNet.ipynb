{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbx5gf/akwU0XNgeV+7rym",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jess-Lau/Real-Life-B-W-Video-Colorization-Project/blob/main/ColorizerImageNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Image Colorization GAN\n",
        "# ----------------------\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "# ------------------\n",
        "# Configuration\n",
        "# ------------------\n",
        "IMAGE_SIZE = 64\n",
        "CHANNELS = 1  # L channel input\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 64\n",
        "LAMBDA = 100\n",
        "data_dir = \"/content/ImageNet\"\n",
        "WORKDIR = \"/content/colorization\"\n",
        "CHECKPOINT_DIR = os.path.join(WORKDIR, \"checkpoints\")\n",
        "RESULTS_DIR = os.path.join(WORKDIR, \"results\")\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
        "\n",
        "# ------------------\n",
        "# ImageNet64 Data Pipeline\n",
        "# ------------------\n",
        "def unpickle(file):\n",
        "    \"\"\"Load ImageNet64x64 batch\"\"\"\n",
        "    with open(file, 'rb') as f:\n",
        "        return pickle.load(f, encoding='bytes')\n",
        "\n",
        "def load_imagenet_batch(data_dir, batch_file):\n",
        "    data = unpickle(os.path.join(data_dir, batch_file))\n",
        "    x = data[b'data'].astype(np.float32) / 255.0\n",
        "    if b'mean' in data:\n",
        "        mean = data[b'mean'].astype(np.float32) / 255.0\n",
        "        x -= mean\n",
        "    # Reshape to NHWC format\n",
        "    return x.reshape(-1, 3, IMAGE_SIZE, IMAGE_SIZE).transpose(0, 2, 3, 1)\n",
        "\n",
        "def load_dataset(data_dir, split='train'):\n",
        "    \"\"\"Load ImageNet64 dataset\"\"\"\n",
        "    if split == 'train':\n",
        "        files = [f'train_data_batch_{i}' for i in range(1, 11)]\n",
        "        # Load mean from first batch\n",
        "        first_batch = load_imagenet_batch(data_dir, 'train_data_batch_1')\n",
        "        mean = unpickle(os.path.join(data_dir, 'train_data_batch_1'))[b'mean'] / 255.0\n",
        "    else:\n",
        "        files = ['val_data']\n",
        "        mean = None\n",
        "\n",
        "    images = []\n",
        "    for file in files:\n",
        "        batch_images = load_imagenet_batch(data_dir, file)\n",
        "        if mean is not None:\n",
        "            batch_images -= mean\n",
        "        images.append(batch_images)\n",
        "\n",
        "    return np.concatenate(images, axis=0)\n",
        "\n",
        "def prepare_datasets(data_dir):\n",
        "    \"\"\"Prepare training and validation datasets\"\"\"\n",
        "    # Load RGB data\n",
        "    train_rgb = load_dataset(data_dir, 'train')\n",
        "    val_rgb = load_dataset(data_dir, 'val')\n",
        "\n",
        "    # Convert to LAB color space\n",
        "    def process_batch(rgb_batch):\n",
        "        lab_batch = []\n",
        "        for img in rgb_batch:\n",
        "            lab = rgb2lab(img)\n",
        "            L = lab[..., 0:1]          # (64, 64, 1) [0-100]\n",
        "            AB = lab[..., 1:] / 128.0  # (64, 64, 2) [-1, 1]\n",
        "            lab_batch.append((L, AB))\n",
        "        return zip(*lab_batch)\n",
        "\n",
        "    print(\"Processing training data...\")\n",
        "    train_L, train_AB = process_batch(train_rgb)\n",
        "    print(\"Processing validation data...\")\n",
        "    val_L, val_AB = process_batch(val_rgb)\n",
        "\n",
        "    # Create TensorFlow datasets\n",
        "    train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (np.array(train_L, dtype=np.float32),\n",
        "        np.array(train_AB, dtype=np.float32))\n",
        "    ).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (np.array(val_L, dtype=np.float32),\n",
        "        np.array(val_AB, dtype=np.float32))\n",
        "    ).batch(BATCH_SIZE)\n",
        "\n",
        "    return train_dataset, val_dataset\n",
        "\n",
        "# ------------------\n",
        "# Model Architectures\n",
        "# ------------------\n",
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    result = Sequential()\n",
        "    result.add(layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                            kernel_initializer=initializer, use_bias=False))\n",
        "    if apply_batchnorm:\n",
        "        result.add(layers.BatchNormalization())\n",
        "    result.add(layers.LeakyReLU(alpha=0.2))\n",
        "    return result\n",
        "\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    result = Sequential()\n",
        "    result.add(layers.Conv2DTranspose(filters, size, strides=2,\n",
        "                                     padding='same',\n",
        "                                     kernel_initializer=initializer,\n",
        "                                     use_bias=False))\n",
        "    result.add(layers.BatchNormalization())\n",
        "    if apply_dropout:\n",
        "        result.add(layers.Dropout(0.5))\n",
        "    result.add(layers.ReLU())\n",
        "    return result\n",
        "\n",
        "def build_generator():\n",
        "    inputs = layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, CHANNELS])\n",
        "\n",
        "    # Encoder (64x64 → 4x4)\n",
        "    down_stack = [\n",
        "        downsample(64, 4, apply_batchnorm=False),  # 32x32\n",
        "        downsample(128, 4),                        # 16x16\n",
        "        downsample(256, 4),                        # 8x8\n",
        "        downsample(512, 4),                        # 4x4\n",
        "    ]\n",
        "\n",
        "    # Decoder (4x4 → 64x64)\n",
        "    up_stack = [\n",
        "        upsample(512, 4, apply_dropout=True),      # 8x8\n",
        "        upsample(256, 4),                          # 16x16\n",
        "        upsample(128, 4),                          # 32x32\n",
        "        upsample(64, 4),                           # 64x64\n",
        "    ]\n",
        "\n",
        "    # Output layer\n",
        "    last = layers.Conv2D(2, 3, padding='same', activation='tanh')\n",
        "\n",
        "    # U-Net with skip connections\n",
        "    x = inputs\n",
        "    skips = []\n",
        "    for down in down_stack:\n",
        "        x = down(x)\n",
        "        skips.append(x)\n",
        "\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        x = layers.Concatenate()([x, skip])\n",
        "\n",
        "    x = last(x)\n",
        "    return Model(inputs=inputs, outputs=x)\n",
        "\n",
        "def build_discriminator():\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    inp = layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, 3], name='input_image')\n",
        "\n",
        "    x = layers.Conv2D(64, 4, strides=2, padding='same',\n",
        "                     kernel_initializer=initializer)(inp)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 4, strides=2, padding='same',\n",
        "                     kernel_initializer=initializer)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(256, 4, strides=2, padding='same',\n",
        "                     kernel_initializer=initializer)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    return Model(inputs=inp, outputs=x)\n",
        "\n",
        "# ------------------\n",
        "# Training Setup\n",
        "# ------------------\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(fake_output, generated_images, real_images):\n",
        "    gan_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "    l1_loss = tf.reduce_mean(tf.abs(real_images - generated_images))\n",
        "    return gan_loss + LAMBDA * l1_loss, gan_loss, l1_loss\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    generator_optimizer=generator_optimizer,\n",
        "    discriminator_optimizer=discriminator_optimizer,\n",
        "    generator=generator,\n",
        "    discriminator=discriminator,\n",
        "    epoch=tf.Variable(0)\n",
        ")\n",
        "\n",
        "manager = tf.train.CheckpointManager(\n",
        "    checkpoint, CHECKPOINT_DIR, max_to_keep=3)\n",
        "\n",
        "# ------------------\n",
        "# Training Loop\n",
        "# ------------------\n",
        "def generate_images(model, test_input, epoch):\n",
        "    prediction = model(test_input, training=False)\n",
        "\n",
        "    # Convert LAB to RGB\n",
        "    def to_rgb(L, AB):\n",
        "        return lab2rgb(np.concatenate([L, AB*128], axis=-1))\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Input (Grayscale)\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(to_rgb(test_input[0].numpy(), np.zeros_like(prediction[0].numpy())))\n",
        "    plt.title(\"Input\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Ground Truth\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(to_rgb(test_input[0].numpy(), test_input[1].numpy())))\n",
        "    plt.title(\"Ground Truth\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Prediction\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(to_rgb(test_input[0].numpy(), prediction[0].numpy())))\n",
        "    plt.title(\"Predicted\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, f'epoch_{epoch+1}.png'))\n",
        "    plt.close()\n",
        "\n",
        "@tf.function\n",
        "def train_step(input_l, target_ab):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_ab = generator(input_l, training=True)\n",
        "        real_images = tf.concat([input_l, target_ab], axis=-1)\n",
        "        fake_images = tf.concat([input_l, generated_ab], axis=-1)\n",
        "\n",
        "        real_output = discriminator(real_images, training=True)\n",
        "        fake_output = discriminator(fake_images, training=True)\n",
        "\n",
        "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(\n",
        "            fake_output, generated_ab, target_ab)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    # Apply gradient clipping\n",
        "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
        "                                          generator.trainable_variables)\n",
        "    generator_gradients = [tf.clip_by_norm(g, 1.0) for g in generator_gradients]\n",
        "\n",
        "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
        "                                               discriminator.trainable_variables)\n",
        "    discriminator_gradients = [tf.clip_by_norm(g, 1.0) for g in discriminator_gradients]\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
        "                                          generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
        "                                              discriminator.trainable_variables))\n",
        "\n",
        "    return gen_total_loss, disc_loss\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    start_epoch = checkpoint.epoch.numpy()\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Training\n",
        "        gen_losses = []\n",
        "        disc_losses = []\n",
        "        for batch, (input_l, target_ab) in enumerate(dataset):\n",
        "            gen_loss, disc_loss = train_step(input_l, target_ab)\n",
        "            gen_losses.append(gen_loss)\n",
        "            disc_losses.append(disc_loss)\n",
        "\n",
        "            if batch % 100 == 0:\n",
        "                print(f'Epoch {epoch+1} Batch {batch} | '\n",
        "                      f'Gen Loss: {gen_loss:.4f} | Disc Loss: {disc_loss:.4f}')\n",
        "\n",
        "        # Save checkpoint and generate samples\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            manager.save()\n",
        "            test_batch = next(iter(dataset))\n",
        "            generate_images(generator, test_batch, epoch)\n",
        "\n",
        "        # Print epoch statistics\n",
        "        epoch_time = time.time() - start_time\n",
        "        print(f'Epoch {epoch+1}/{EPOCHS} | '\n",
        "              f'Gen Loss: {np.mean(gen_losses):.4f} | '\n",
        "              f'Disc Loss: {np.mean(disc_losses):.4f} | '\n",
        "              f'Time: {epoch_time:.2f}s')\n",
        "\n",
        "        checkpoint.epoch.assign_add(1)\n",
        "\n",
        "# ------------------\n",
        "# Execution\n",
        "# ------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Initialize datasets\n",
        "    DATA_DIR = \"/path/to/imagenet64\"  # Set your dataset path\n",
        "    train_dataset, val_dataset = prepare_datasets(DATA_DIR)\n",
        "\n",
        "    # Restore checkpoints if available\n",
        "    if manager.latest_checkpoint:\n",
        "        checkpoint.restore(manager.latest_checkpoint)\n",
        "        print(f\"Restored from {manager.latest_checkpoint}\")\n",
        "\n",
        "    # Start training\n",
        "    train(train_dataset, EPOCHS)\n",
        "\n",
        "    # Final evaluation\n",
        "    test_losses = []\n",
        "    for test_input, test_target in val_dataset:\n",
        "        gen_output = generator(test_input, training=False)\n",
        "        test_losses.append(tf.reduce_mean(tf.abs(test_target - gen_output)))\n",
        "    print(f\"Final Validation MAE: {np.mean(test_losses):.4f}\")"
      ],
      "metadata": {
        "id": "RkZNWdRARk3-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}