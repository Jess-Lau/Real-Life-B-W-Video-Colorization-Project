{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "mount_file_id": "https://github.com/Jess-Lau/Real-Life-B-W-Video-Colorization-Project/blob/main/ColorizerGANV2.ipynb",
      "authorship_tag": "ABX9TyOS7fbx0HKVHJM0xlMK40U7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jess-Lau/Real-Life-B-W-Video-Colorization-Project/blob/main/ColorizerGANVXZ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Ads3J-VraLRG"
      },
      "outputs": [],
      "source": [
        "# ----------------------\n",
        "# Colorization GAN\n",
        "# ----------------------\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Configuration\n",
        "# ------------------\n",
        "IMAGE_SIZE = 64\n",
        "CHANNELS = 1\n",
        "EPOCHS = 55\n",
        "BATCH_SIZE = 256\n",
        "LAMBDA = 100\n",
        "DATA_DIR = \"/content/drive/MyDrive/ImageNet\"  # Update with your path\n",
        "WORKDIR = \"/content/drive/MyDrive/Colorization\"\n",
        "CHECKPOINT_DIR = os.path.join(WORKDIR, \"checkpoints\")\n",
        "RESULTS_DIR = os.path.join(WORKDIR, \"results\")\n",
        "\n",
        "# Enable mixed precision with proper policy\n",
        "\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "1jffqiuUahQR"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Data Pipeline\n",
        "# ------------------\n",
        "def load_mean(data_dir):\n",
        "    \"\"\"Load mean image from first training batch\"\"\"\n",
        "    with open(os.path.join(data_dir, 'train_data_batch_1'), 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "        mean = data['mean'].astype(np.float32) / 255.0\n",
        "        return mean.reshape(3, IMAGE_SIZE, IMAGE_SIZE).transpose(1, 2, 0)\n",
        "\n",
        "def data_generator(data_dir, split='train'):\n",
        "    mean = load_mean(data_dir) if split == 'train' else None\n",
        "    files = [f'train_data_batch_{i}' for i in range(1, 11)] if split == 'train' else ['val_data']\n",
        "\n",
        "    for file in files:\n",
        "        path = os.path.join(data_dir, file)\n",
        "        try:\n",
        "            with open(path, 'rb') as f:\n",
        "                data = pickle.load(f)\n",
        "                x = data['data'].astype(np.float32) / 255.0\n",
        "                x = x.reshape(-1, 3, IMAGE_SIZE, IMAGE_SIZE).transpose(0, 2, 3, 1)\n",
        "\n",
        "                if mean is not None:\n",
        "                    x -= mean\n",
        "\n",
        "                for i in range(0, x.shape[0], BATCH_SIZE):\n",
        "                    batch_rgb = x[i:i+BATCH_SIZE]\n",
        "                    batch_lab = np.array([rgb2lab(img) for img in batch_rgb])\n",
        "                    batch_lab = np.nan_to_num(batch_lab, nan=0.0, posinf=100.0, neginf=0.0)\n",
        "                    L = np.clip(batch_lab[..., 0:1], 0, 100).astype(np.float32)\n",
        "                    AB = np.clip(batch_lab[..., 1:], -128, 127).astype(np.float32) / 128.0\n",
        "                    yield L, AB\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Failed to load {path}: {str(e)}\")\n",
        "            continue  # Skip problematic files\n",
        "\n",
        "def create_dataset(data_dir, split='train'):\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        lambda: data_generator(data_dir, split),\n",
        "        output_signature=(  # ✅ Proper parentheses\n",
        "            tf.TensorSpec(shape=(None, 64, 64, 1), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(None, 64, 64, 2), dtype=tf.float32)\n",
        "        )\n",
        "    ).prefetch(tf.data.AUTOTUNE)  # ✅ .prefetch() called on dataset"
      ],
      "metadata": {
        "id": "oXsq8r77afW4"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Custom Instance Normalization (using GroupNorm)\n",
        "# ------------------\n",
        "class InstanceNormalization(layers.Layer):\n",
        "    def __init__(self, epsilon=1e-3):\n",
        "        super(InstanceNormalization, self).__init__()\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # Create variables in float32 for numerical stability\n",
        "        self.gamma = self.add_weight(\n",
        "            name='gamma',\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='ones',\n",
        "            dtype=tf.float32  # Store as float32\n",
        "        )\n",
        "        self.beta = self.add_weight(\n",
        "            name='beta',\n",
        "            shape=(input_shape[-1],),\n",
        "            initializer='zeros',\n",
        "            dtype=tf.float32  # Store as float32\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        input_dtype = inputs.dtype  # Preserve original dtype (float16)\n",
        "\n",
        "        # Compute in float32 for numerical stability\n",
        "        inputs_float32 = tf.cast(inputs, tf.float32)\n",
        "        mean, variance = tf.nn.moments(inputs_float32, axes=[1, 2], keepdims=True)\n",
        "        inv = tf.math.rsqrt(variance + self.epsilon)\n",
        "\n",
        "        # Cast parameters to match computation dtype\n",
        "        gamma = tf.cast(self.gamma, tf.float32)\n",
        "        beta = tf.cast(self.beta, tf.float32)\n",
        "\n",
        "        # Compute and cast back to original dtype\n",
        "        output = gamma * (inputs_float32 - mean) * inv + beta\n",
        "        return tf.cast(output, input_dtype)  # Return original dtype\n",
        "\n",
        "# ------------------\n",
        "# Model Architectures\n",
        "# ------------------\n",
        "def residual_block(filters):\n",
        "    \"\"\"Residual block with custom instance normalization\"\"\"\n",
        "    block = Sequential()\n",
        "    block.add(layers.Conv2D(filters, 3, padding='same'))\n",
        "    block.add(InstanceNormalization())\n",
        "    block.add(layers.ReLU())\n",
        "    block.add(layers.Conv2D(filters, 3, padding='same'))\n",
        "    block.add(InstanceNormalization())\n",
        "    return block\n",
        "\n",
        "def attention_block(skip, gate, filters):\n",
        "    \"\"\"Attention gate using core TF layers\"\"\"\n",
        "    g = layers.Conv2D(filters, 1)(gate)\n",
        "    x = layers.Conv2D(filters, 1)(skip)\n",
        "    psi = layers.Activation('relu')(layers.Add()([g, x]))\n",
        "    psi = layers.Conv2D(1, 1, activation='sigmoid')(psi)\n",
        "    return layers.Multiply()([skip, psi])\n",
        "\n",
        "def build_generator():\n",
        "    inputs = layers.Input(shape=(64, 64, 1))\n",
        "\n",
        "    # Encoder\n",
        "    d1 = layers.Conv2D(64, 4, strides=2, padding='same')(inputs)  # 32x32\n",
        "    d1 = InstanceNormalization()(d1)\n",
        "    d1 = layers.LeakyReLU(0.2)(d1)\n",
        "\n",
        "    d2 = layers.Conv2D(128, 4, strides=2, padding='same')(d1)     # 16x16\n",
        "    d2 = InstanceNormalization()(d2)\n",
        "    d2 = layers.LeakyReLU(0.2)(d2)\n",
        "\n",
        "    d3 = layers.Conv2D(256, 4, strides=2, padding='same')(d2)     # 8x8\n",
        "    d3 = InstanceNormalization()(d3)\n",
        "    d3 = layers.LeakyReLU(0.2)(d3)\n",
        "\n",
        "    d4 = layers.Conv2D(512, 4, strides=2, padding='same')(d3)     # 4x4\n",
        "    d4 = InstanceNormalization()(d4)\n",
        "    d4 = layers.LeakyReLU(0.2)(d4)\n",
        "\n",
        "    # Bottleneck with residual\n",
        "    res = residual_block(512)(d4)\n",
        "    d4 = layers.Add()([d4, res])\n",
        "\n",
        "    # Decoder with PROPER upsampling\n",
        "    # Layer 1: 4x4 → 8x8\n",
        "    u1 = layers.Conv2DTranspose(512, 4, strides=2, padding='same')(d4)\n",
        "    u1 = InstanceNormalization()(u1)\n",
        "    u1 = layers.ReLU()(u1)\n",
        "    u1 = layers.Concatenate()([u1, d3])  # Skip connection from d3 (8x8)\n",
        "\n",
        "    # Layer 2: 8x8 → 16x16\n",
        "    u2 = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(u1)\n",
        "    u2 = InstanceNormalization()(u2)\n",
        "    u2 = layers.ReLU()(u2)\n",
        "    u2 = layers.Concatenate()([u2, d2])  # Skip connection from d2 (16x16)\n",
        "\n",
        "    # Layer 3: 16x16 → 32x32\n",
        "    u3 = layers.Conv2DTranspose(128, 4, strides=2, padding='same')(u2)\n",
        "    u3 = InstanceNormalization()(u3)\n",
        "    u3 = layers.ReLU()(u3)\n",
        "    u3 = layers.Concatenate()([u3, d1])  # Skip connection from d1 (32x32)\n",
        "\n",
        "    # Layer 4: 32x32 → 64x64 (FIXED: Added final upsampling layer)\n",
        "    u4 = layers.Conv2DTranspose(64, 4, strides=2, padding='same')(u3)\n",
        "    u4 = InstanceNormalization()(u4)\n",
        "    u4 = layers.ReLU()(u4)\n",
        "\n",
        "    # Final output layer\n",
        "    output = layers.Conv2D(2, 3, padding='same',\n",
        "                          activation='tanh',\n",
        "                          dtype='float32')(u4)\n",
        "    return Model(inputs, output)\n",
        "\n",
        "def build_discriminator():\n",
        "    inputs = layers.Input(shape=(64, 64, 3))\n",
        "\n",
        "    # Layer 1: 64x64 → 32x32\n",
        "    x = layers.Conv2D(64, 4, strides=2, padding='same', dtype='float32')(inputs)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    # Layer 2: 32x32 → 16x16\n",
        "    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    # Layer 3: 16x16 → 8x8\n",
        "    x = layers.Conv2D(256, 4, strides=2, padding='same')(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    # Final layer: 8x8 → 8x8 (no striding)\n",
        "    x = layers.Conv2D(1, 4, padding='same')(x)\n",
        "    return Model(inputs, x)\n"
      ],
      "metadata": {
        "id": "6YOSJkmZadOh"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Training Setup\n",
        "# ------------------\n",
        "generator = build_generator()\n",
        "generator.summary()  # Should show output shape (None, 64, 64, 2)\n",
        "print(generator.output_shape)  # Should be (None, 64, 64, 2)\n",
        "\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5, clipnorm=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-6, beta_1=0.5, clipnorm=0.5)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    generator_optimizer=generator_optimizer,\n",
        "    discriminator_optimizer=discriminator_optimizer,\n",
        "    generator=generator,\n",
        "    discriminator=discriminator,\n",
        "    epoch=tf.Variable(0)\n",
        ")\n",
        "manager = tf.train.CheckpointManager(checkpoint, CHECKPOINT_DIR, max_to_keep=3)"
      ],
      "metadata": {
        "id": "ENkU2C05abcZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "76d217f8-b46d-47dc-c3c1-de6e340599f1"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_26\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_26\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_25            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast_106 (\u001b[38;5;33mCast\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ input_layer_25[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_95 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │          \u001b[38;5;34m1,088\u001b[0m │ cast_106[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_86 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_95[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mInstanceNormalization\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_55            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ instance_normalizatio… │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_96 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m131,200\u001b[0m │ leaky_re_lu_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_87 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m256\u001b[0m │ conv2d_96[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mInstanceNormalization\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_56            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ instance_normalizatio… │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_97 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │        \u001b[38;5;34m524,544\u001b[0m │ leaky_re_lu_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_88 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │            \u001b[38;5;34m512\u001b[0m │ conv2d_97[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mInstanceNormalization\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_57            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ instance_normalizatio… │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_98 (\u001b[38;5;33mConv2D\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m2,097,664\u001b[0m │ leaky_re_lu_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_89 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_98[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "│ (\u001b[38;5;33mInstanceNormalization\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_58            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ instance_normalizatio… │\n",
              "│ (\u001b[38;5;33mLeakyReLU\u001b[0m)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_7 (\u001b[38;5;33mSequential\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m4,721,664\u001b[0m │ leaky_re_lu_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (\u001b[38;5;33mAdd\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_58[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│                           │                        │                │ sequential_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_36       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │      \u001b[38;5;34m4,194,816\u001b[0m │ add_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_92 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │          \u001b[38;5;34m1,024\u001b[0m │ conv2d_transpose_36[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mInstanceNormalization\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_36 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m512\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ instance_normalizatio… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_27            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m768\u001b[0m)      │              \u001b[38;5;34m0\u001b[0m │ re_lu_36[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ leaky_re_lu_57[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_37       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │      \u001b[38;5;34m3,145,984\u001b[0m │ concatenate_27[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_93 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │            \u001b[38;5;34m512\u001b[0m │ conv2d_transpose_37[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mInstanceNormalization\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_37 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ instance_normalizatio… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_28            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m384\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ re_lu_37[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ leaky_re_lu_56[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_38       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m786,560\u001b[0m │ concatenate_28[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_94 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │            \u001b[38;5;34m256\u001b[0m │ conv2d_transpose_38[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mInstanceNormalization\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_38 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ instance_normalizatio… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_29            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m192\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ re_lu_38[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)             │                        │                │ leaky_re_lu_55[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_39       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m196,672\u001b[0m │ concatenate_29[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mConv2DTranspose\u001b[0m)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_95 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │            \u001b[38;5;34m128\u001b[0m │ conv2d_transpose_39[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mInstanceNormalization\u001b[0m)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_39 (\u001b[38;5;33mReLU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ instance_normalizatio… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast_107 (\u001b[38;5;33mCast\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │              \u001b[38;5;34m0\u001b[0m │ re_lu_39[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_101 (\u001b[38;5;33mConv2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m2\u001b[0m)      │          \u001b[38;5;34m1,154\u001b[0m │ cast_107[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_25            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast_106 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_25[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_95 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │ cast_106[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_86 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_95[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InstanceNormalization</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_55            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ instance_normalizatio… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">131,200</span> │ leaky_re_lu_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_87 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_96[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InstanceNormalization</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_56            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ instance_normalizatio… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_97 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ leaky_re_lu_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_88 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_97[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InstanceNormalization</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_57            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ instance_normalizatio… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_98 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │ leaky_re_lu_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_89 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_98[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InstanceNormalization</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ leaky_re_lu_58            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ instance_normalizatio… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)               │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ sequential_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,721,664</span> │ leaky_re_lu_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ add_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_58[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│                           │                        │                │ sequential_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_36       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,816</span> │ add_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_92 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_transpose_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InstanceNormalization</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ instance_normalizatio… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_27            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)      │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_36[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ leaky_re_lu_57[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_37       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,145,984</span> │ concatenate_27[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_93 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_transpose_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InstanceNormalization</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ instance_normalizatio… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_28            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_37[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ leaky_re_lu_56[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_38       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">786,560</span> │ concatenate_28[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_94 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_transpose_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InstanceNormalization</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ instance_normalizatio… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate_29            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_38[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)             │                        │                │ leaky_re_lu_55[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_transpose_39       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">196,672</span> │ concatenate_29[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2DTranspose</span>)         │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ instance_normalization_95 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv2d_transpose_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InstanceNormalization</span>)   │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ re_lu_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ instance_normalizatio… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ cast_107 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Cast</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_39[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv2d_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">1,154</span> │ cast_107[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,805,186\u001b[0m (60.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,805,186</span> (60.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m15,805,186\u001b[0m (60.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,805,186</span> (60.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 64, 64, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Training Utilities\n",
        "# ------------------\n",
        "def generate_images(model, test_input, epoch):\n",
        "    input_L = test_input[0]  # ✅ Extract L channel\n",
        "    target_AB = test_input[1]  # Ground truth AB\n",
        "\n",
        "    # Predict using only L\n",
        "    prediction = model(input_L, training=False)[0].numpy()\n",
        "    L = input_L[0].numpy()[..., 0]  # Use first sample in batch\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Input (grayscale)\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(L, cmap='gray')\n",
        "    plt.title(\"Input\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Ground truth (colorized)\n",
        "    plt.subplot(1, 3, 2)\n",
        "    true_rgb = lab2rgb(np.dstack((L, target_AB[0].numpy() * 128)))  # ✅ Use target_AB\n",
        "    plt.imshow(true_rgb)\n",
        "    plt.title(\"Ground Truth\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    # Predicted (colorized)\n",
        "    plt.subplot(1, 3, 3)\n",
        "    pred_rgb = lab2rgb(np.dstack((L, prediction * 128)))\n",
        "    plt.imshow(pred_rgb)\n",
        "    plt.title(\"Predicted\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, f'epoch_{epoch+1}.png'))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "# --- Add PSNR/SSIM Calculations ---\n",
        "# Convert LAB to RGB for metrics\n",
        "def lab_to_rgb(lab):\n",
        "    \"\"\"Convert LAB tensor to RGB tensor (0-255 range) with mixed precision support\"\"\"\n",
        "    # Ensure LAB tensor is float32 for stable calculations\n",
        "    lab = tf.cast(lab, tf.float32)\n",
        "\n",
        "    # Denormalize LAB\n",
        "    L = lab[..., 0] * 100.0          # L: [0,100]\n",
        "    ab = lab[..., 1:] * 128.0        # ab: [-128, 127]\n",
        "\n",
        "    # Convert LAB to XYZ\n",
        "    y = (L + 16.0) / 116.0\n",
        "    x = ab[..., 0] / 500.0 + y\n",
        "    z = y - ab[..., 1] / 200.0\n",
        "\n",
        "    xyz = tf.stack([x, y, z], axis=-1)\n",
        "    xyz = tf.where(xyz > 0.2068966, xyz**3, (xyz - 16.0/116.0)/7.787)\n",
        "\n",
        "    # D65 reference white (cast to float32)\n",
        "    xyz = xyz * tf.constant([95.047, 100.0, 108.883], dtype=tf.float32)\n",
        "\n",
        "    # XYZ to RGB matrix\n",
        "    rgb = tf.tensordot(xyz, tf.constant([\n",
        "        [3.2406, -1.5372, -0.4986],\n",
        "        [-0.9689, 1.8758, 0.0415],\n",
        "        [0.0557, -0.2040, 1.0570]\n",
        "    ], dtype=tf.float32), axes=1)\n",
        "\n",
        "    # Gamma correction\n",
        "    rgb = tf.where(rgb > 0.0031308,\n",
        "                    1.055 * (rgb ** (1/2.4)) - 0.055,\n",
        "                    12.92 * rgb)\n",
        "\n",
        "    # Final conversion to float16 if needed\n",
        "    return tf.cast(tf.clip_by_value(rgb * 255.0, 0.0, 255.0), tf.float32)\n",
        "\n",
        "# ------------------\n",
        "# 1. Data Validation Layer\n",
        "# ------------------\n",
        "def validate_data(L, AB):\n",
        "    \"\"\"Ensure inputs are within valid numerical ranges\"\"\"\n",
        "    # Check for NaN/Inf in inputs\n",
        "    L = tf.debugging.assert_all_finite(L, \"Invalid values in L channel\")\n",
        "    AB = tf.debugging.assert_all_finite(AB, \"Invalid values in AB channels\")\n",
        "\n",
        "    # Clip LAB values to valid ranges\n",
        "    L = tf.clip_by_value(L, 0.0, 100.0)\n",
        "    AB = tf.clip_by_value(AB, -128.0, 127.0)\n",
        "\n",
        "    return L, AB\n",
        "\n",
        "# ------------------\n",
        "# 2. Safe Loss Functions\n",
        "# ------------------\n",
        "\n",
        "def safe_generator_loss(fake_output, real_ab, gen_ab):\n",
        "    # Check input shapes\n",
        "    # For PatchGAN output (8x8 feature map)\n",
        "    tf.debugging.assert_shapes([\n",
        "        (fake_output, ('batch', 8, 8, 1)),  # Adjusted to match PatchGAN output\n",
        "        (real_ab, ('batch', 'height', 'width', 2)),\n",
        "        (gen_ab, ('batch', 'height', 'width', 2))\n",
        "    ])\n",
        "\n",
        "    # Adversarial loss with stability epsilon\n",
        "    adv_loss = tf.reduce_mean(tf.square(fake_output - 1.0 + 1e-7))\n",
        "\n",
        "    # L1 loss with clipping\n",
        "    l1_diff = tf.clip_by_value(real_ab - gen_ab, -1.0, 1.0)\n",
        "    l1_loss = tf.reduce_mean(tf.abs(l1_diff))\n",
        "\n",
        "    # Numerical checks\n",
        "    adv_loss = tf.debugging.check_numerics(adv_loss, \"Generator adv_loss NaN/Inf\")\n",
        "    l1_loss = tf.debugging.check_numerics(l1_loss, \"Generator l1_loss NaN/Inf\")\n",
        "\n",
        "    total_loss = adv_loss + LAMBDA * l1_loss\n",
        "    return tf.debugging.check_numerics(total_loss, \"Generator total_loss NaN/Inf\")\n",
        "\n",
        "def safe_discriminator_loss(real_output, fake_output):\n",
        "    # Add small epsilon to prevent log(0)\n",
        "    real_loss = tf.reduce_mean(tf.square(real_output - 1.0 + 1e-7))\n",
        "    fake_loss = tf.reduce_mean(tf.square(fake_output + 1e-7))\n",
        "\n",
        "    # Numerical checks\n",
        "    real_loss = tf.debugging.check_numerics(real_loss, \"Disc real_loss NaN/Inf\")\n",
        "    fake_loss = tf.debugging.check_numerics(fake_loss, \"Disc fake_loss NaN/Inf\")\n",
        "\n",
        "    total_loss = 0.5 * (real_loss + fake_loss)\n",
        "    return tf.debugging.check_numerics(total_loss, \"Disc total_loss NaN/Inf\")\n",
        "\n",
        "\n",
        "# ------------------\n",
        "# 4. Modified Training Step\n",
        "# ------------------\n",
        "@tf.function\n",
        "def train_step(input_L, input_AB):\n",
        "    # Cast inputs to float16 to match mixed precision policy\n",
        "    input_L = tf.cast(input_L, tf.float16)\n",
        "    input_AB = tf.cast(input_AB, tf.float16)\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        generated_AB = generator(input_L, training=True)\n",
        "\n",
        "        # Cast generator output to match discriminator input dtype\n",
        "        generated_AB = tf.cast(generated_AB, tf.float16)\n",
        "\n",
        "        # Ensure matching dtypes before concatenation\n",
        "        real_images = tf.concat([\n",
        "            tf.cast(input_L, tf.float16),\n",
        "            tf.cast(input_AB, tf.float16)\n",
        "        ], axis=-1)\n",
        "\n",
        "        fake_images = tf.concat([\n",
        "            tf.cast(input_L, tf.float16),\n",
        "            generated_AB\n",
        "        ], axis=-1)\n",
        "\n",
        "        rgb_real = lab_to_rgb(real_images)\n",
        "        rgb_fake = lab_to_rgb(fake_images)\n",
        "\n",
        "        # Discriminator outputs\n",
        "        disc_real = discriminator(real_images, training=True)\n",
        "        disc_fake = discriminator(fake_images, training=True)\n",
        "\n",
        "        # Calculate losses\n",
        "        gen_loss = safe_generator_loss(disc_fake, input_AB, generated_AB)\n",
        "        disc_loss = safe_discriminator_loss(disc_real, disc_fake)\n",
        "\n",
        "    # Calculate and clip gradients\n",
        "    gen_grads = tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    disc_grads = tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Gradient clipping and validation\n",
        "    gen_grads = [tf.clip_by_norm(g, 1.0) for g in gen_grads]\n",
        "    disc_grads = [tf.clip_by_norm(g, 1.0) for g in disc_grads]\n",
        "\n",
        "    # Check gradients before applying\n",
        "    for g in gen_grads + disc_grads:\n",
        "        tf.debugging.check_numerics(g, \"NaN/Inf in gradients\")\n",
        "\n",
        "    # Apply gradients\n",
        "    generator_optimizer.apply_gradients(zip(gen_grads, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_variables))\n",
        "\n",
        "    # Calculate metrics\n",
        "    psnr = safe_psnr(rgb_real, rgb_fake)\n",
        "    ssim = safe_ssim(rgb_real, rgb_fake)\n",
        "\n",
        "    return gen_loss, disc_loss, psnr, ssim\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zs6PxIdJaVn0"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def calculate_frame_psnr(original, colorized):\n",
        "    \"\"\"\n",
        "    Calculate PSNR for a single frame pair.\n",
        "    Args:\n",
        "        original: Ground truth frame (BGR)\n",
        "        colorized: Colorized frame (BGR)\n",
        "    Returns:\n",
        "        PSNR value in dB\n",
        "    \"\"\"\n",
        "    # Convert to YCrCb for luminance comparison (optional)\n",
        "    original_yuv = cv2.cvtColor(original, cv2.COLOR_BGR2YCrCb)\n",
        "    colorized_yuv = cv2.cvtColor(colorized, cv2.COLOR_BGR2YCrCb)\n",
        "\n",
        "    # Calculate PSNR for each channel\n",
        "    psnr_y = peak_signal_noise_ratio(original_yuv[...,0], colorized_yuv[...,0], data_range=255)\n",
        "    psnr_cr = peak_signal_noise_ratio(original_yuv[...,1], colorized_yuv[...,1], data_range=255)\n",
        "    psnr_cb = peak_signal_noise_ratio(original_yuv[...,2], colorized_yuv[...,2], data_range=255)\n",
        "\n",
        "    return np.mean([psnr_y, psnr_cr, psnr_cb])\n",
        "\n",
        "def calculate_video_psnr(original_video_path, colorized_video_path):\n",
        "    \"\"\"\n",
        "    Calculate average PSNR between two videos.\n",
        "    Returns:\n",
        "        Mean PSNR (dB), Frame-wise PSNR array\n",
        "    \"\"\"\n",
        "    cap_orig = cv2.VideoCapture(original_video_path)\n",
        "    cap_color = cv2.VideoCapture(colorized_video_path)\n",
        "\n",
        "    psnr_values = []\n",
        "\n",
        "    while True:\n",
        "        ret_orig, frame_orig = cap_orig.read()\n",
        "        ret_color, frame_color = cap_color.read()\n",
        "\n",
        "        if not ret_orig or not ret_color:\n",
        "            break\n",
        "\n",
        "        # Resize if necessary (match dimensions)\n",
        "        if frame_orig.shape != frame_color.shape:\n",
        "            frame_color = cv2.resize(frame_color, (frame_orig.shape[1], frame_orig.shape[0]))\n",
        "\n",
        "        psnr = calculate_frame_psnr(frame_orig, frame_color)\n",
        "        psnr_values.append(psnr)\n",
        "\n",
        "    cap_orig.release()\n",
        "    cap_color.release()\n",
        "\n",
        "    return np.mean(psnr_values), psnr_values"
      ],
      "metadata": {
        "id": "8xpOqmc-3Gko"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Training Loop\n",
        "# ------------------\n",
        "def train():\n",
        "    train_dataset = create_dataset(DATA_DIR, 'train')\n",
        "    val_dataset = create_dataset(DATA_DIR, 'val')\n",
        "\n",
        "    if manager.latest_checkpoint:\n",
        "        checkpoint.restore(manager.latest_checkpoint)\n",
        "        print(f\"Resumed from epoch {checkpoint.epoch.numpy()}\")\n",
        "\n",
        "    # Initialize metrics\n",
        "    psnr_metric = tf.keras.metrics.Mean(name='psnr')\n",
        "    ssim_metric = tf.keras.metrics.Mean(name='ssim')\n",
        "\n",
        "    for epoch in range(checkpoint.epoch.numpy(), EPOCHS):\n",
        "        start = time.time()\n",
        "        gen_losses, disc_losses = [], []\n",
        "        # Reset metrics each epoch (CORRECTED METHOD NAME)\n",
        "        psnr_metric.reset_state()\n",
        "        ssim_metric.reset_state()\n",
        "\n",
        "        # Training phase\n",
        "        for batch, (L, AB) in enumerate(train_dataset):\n",
        "            gen_loss, disc_loss, psnr, ssim = train_step(L, AB)\n",
        "            gen_losses.append(gen_loss)\n",
        "            disc_losses.append(disc_loss)\n",
        "\n",
        "            # Update metrics\n",
        "            psnr_metric.update_state(psnr)\n",
        "            ssim_metric.update_state(ssim)\n",
        "\n",
        "\n",
        "            # Existing logging\n",
        "            if batch % 100 == 0:\n",
        "                gen_loss_val = gen_loss.numpy().item()\n",
        "                disc_loss_val = disc_loss.numpy().item()\n",
        "                print(f\"Batch {batch} | PSNR: {psnr_metric.result():.2f} | SSIM: {ssim_metric.result():.3f}\")\n",
        "                print(f\"Gen: {gen_loss_val:.2f} Disc: {disc_loss_val:.2f}\")\n",
        "\n",
        "\n",
        "        # In your training loop after the epoch's training phase:\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            manager.save()\n",
        "            test_batch = next(iter(val_dataset))\n",
        "            generate_images(generator, test_batch, epoch)\n",
        "\n",
        "        # Validation phase\n",
        "        val_psnr = []\n",
        "        val_ssim = []\n",
        "        for val_L, val_AB in val_dataset.take(10):\n",
        "           val_gen_AB = generator(val_L, training=False)\n",
        "\n",
        "        # Convert to float32 before concatenation\n",
        "           val_real_lab = tf.concat([\n",
        "               tf.cast(val_L, tf.float32),\n",
        "               tf.cast(val_AB, tf.float32)\n",
        "           ], axis=-1)\n",
        "           val_real_rgb = lab_to_rgb(val_real_lab)\n",
        "\n",
        "           val_fake_lab = tf.concat([\n",
        "               tf.cast(val_L, tf.float32),\n",
        "               tf.cast(val_gen_AB, tf.float32)\n",
        "           ], axis=-1)\n",
        "           val_fake_rgb = lab_to_rgb(val_fake_lab)\n",
        "\n",
        "        # Calculate metrics\n",
        "        batch_psnr = tf.reduce_mean(tf.image.psnr(val_real_rgb, val_fake_rgb, max_val=255))\n",
        "        batch_ssim = tf.reduce_mean(tf.image.ssim(val_real_rgb, val_fake_rgb, max_val=255))\n",
        "\n",
        "        val_psnr.append(batch_psnr.numpy())\n",
        "        val_ssim.append(batch_ssim.numpy())\n",
        "\n",
        "        # Epoch summary\n",
        "        print(f\"\\nEpoch {epoch+1}\")\n",
        "        print(f\"Time: {time.time()-start:.2f}s\")\n",
        "        print(f\"Gen Loss: {np.mean(gen_losses):.4f}\")\n",
        "        print(f\"Disc Loss: {np.mean(disc_losses):.4f}\\n\")\n",
        "        print(f\"Train PSNR: {psnr_metric.result():.2f} dB\")\n",
        "        print(f\"Train SSIM: {ssim_metric.result():.4f}\")\n",
        "        print(f\"Val PSNR: {np.mean(val_psnr):.2f} dB\")\n",
        "        print(f\"Val SSIM: {np.mean(val_ssim):.4f}\")\n",
        "\n",
        "        checkpoint.epoch.assign_add(1)\n"
      ],
      "metadata": {
        "id": "BOasui2daTd5"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
        "tf.keras.mixed_precision.set_global_policy(policy)\n"
      ],
      "metadata": {
        "id": "O41o85s9o6FA"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train()"
      ],
      "metadata": {
        "id": "LvKNoJXlaRZl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6b9d86-0e85-42f9-f511-3250b4eb79ad"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resumed from epoch 49\n",
            "Batch 0 | PSNR: 10.78 | SSIM: 0.598\n",
            "Gen: 9.03 Disc: 0.25\n",
            "Batch 100 | PSNR: 9.74 | SSIM: 0.573\n",
            "Gen: 9.73 Disc: 0.25\n",
            "Batch 200 | PSNR: 10.12 | SSIM: 0.579\n",
            "Gen: 9.57 Disc: 0.25\n",
            "Batch 300 | PSNR: 10.03 | SSIM: 0.578\n",
            "Gen: 10.38 Disc: 0.25\n",
            "Batch 400 | PSNR: 10.08 | SSIM: 0.581\n",
            "Gen: 10.70 Disc: 0.25\n",
            "Batch 500 | PSNR: 9.99 | SSIM: 0.579\n",
            "Gen: 9.55 Disc: 0.25\n",
            "Batch 600 | PSNR: 10.06 | SSIM: 0.580\n",
            "Gen: 9.27 Disc: 0.25\n",
            "Batch 700 | PSNR: 10.15 | SSIM: 0.582\n",
            "Gen: 9.21 Disc: 0.25\n",
            "Batch 800 | PSNR: 10.21 | SSIM: 0.583\n",
            "Gen: 10.38 Disc: 0.25\n",
            "Batch 900 | PSNR: 10.24 | SSIM: 0.585\n",
            "Gen: 9.68 Disc: 0.25\n",
            "Batch 1000 | PSNR: 10.23 | SSIM: 0.585\n",
            "Gen: 11.65 Disc: 0.25\n",
            "Batch 1100 | PSNR: 10.09 | SSIM: 0.579\n",
            "Gen: 13.61 Disc: 0.25\n",
            "Batch 1200 | PSNR: 10.08 | SSIM: 0.579\n",
            "Gen: 9.30 Disc: 0.25\n",
            "Batch 1300 | PSNR: 10.13 | SSIM: 0.581\n",
            "Gen: 9.26 Disc: 0.25\n",
            "Batch 1400 | PSNR: 10.18 | SSIM: 0.582\n",
            "Gen: 9.93 Disc: 0.25\n",
            "Batch 1500 | PSNR: 10.22 | SSIM: 0.584\n",
            "Gen: 9.27 Disc: 0.25\n",
            "Batch 1600 | PSNR: 10.27 | SSIM: 0.585\n",
            "Gen: 9.71 Disc: 0.25\n",
            "Batch 1700 | PSNR: 10.25 | SSIM: 0.584\n",
            "Gen: 14.67 Disc: 0.25\n",
            "Batch 1800 | PSNR: 10.24 | SSIM: 0.584\n",
            "Gen: 9.59 Disc: 0.25\n",
            "Batch 1900 | PSNR: 10.22 | SSIM: 0.584\n",
            "Gen: 9.75 Disc: 0.25\n",
            "Batch 2000 | PSNR: 10.24 | SSIM: 0.584\n",
            "Gen: 14.77 Disc: 0.25\n",
            "Batch 2100 | PSNR: 10.15 | SSIM: 0.583\n",
            "Gen: 13.30 Disc: 0.25\n",
            "Batch 2200 | PSNR: 10.15 | SSIM: 0.583\n",
            "Gen: 9.91 Disc: 0.25\n",
            "Batch 2300 | PSNR: 10.19 | SSIM: 0.585\n",
            "Gen: 9.59 Disc: 0.25\n",
            "Batch 2400 | PSNR: 10.21 | SSIM: 0.585\n",
            "Gen: 9.62 Disc: 0.25\n",
            "Batch 2500 | PSNR: 10.25 | SSIM: 0.586\n",
            "Gen: 9.59 Disc: 0.25\n",
            "Batch 2600 | PSNR: 10.25 | SSIM: 0.587\n",
            "Gen: 9.55 Disc: 0.25\n",
            "Batch 2700 | PSNR: 10.22 | SSIM: 0.586\n",
            "Gen: 14.42 Disc: 0.25\n",
            "Batch 2800 | PSNR: 10.22 | SSIM: 0.586\n",
            "Gen: 9.47 Disc: 0.25\n",
            "Batch 2900 | PSNR: 10.24 | SSIM: 0.587\n",
            "Gen: 9.56 Disc: 0.25\n",
            "Batch 3000 | PSNR: 10.26 | SSIM: 0.588\n",
            "Gen: 8.96 Disc: 0.25\n",
            "Batch 3100 | PSNR: 10.26 | SSIM: 0.588\n",
            "Gen: 9.09 Disc: 0.25\n",
            "Batch 3200 | PSNR: 10.27 | SSIM: 0.588\n",
            "Gen: 11.80 Disc: 0.25\n",
            "Batch 3300 | PSNR: 10.25 | SSIM: 0.588\n",
            "Gen: 10.10 Disc: 0.25\n",
            "Batch 3400 | PSNR: 10.23 | SSIM: 0.587\n",
            "Gen: 10.49 Disc: 0.25\n",
            "Batch 3500 | PSNR: 10.23 | SSIM: 0.588\n",
            "Gen: 9.52 Disc: 0.25\n",
            "Batch 3600 | PSNR: 10.22 | SSIM: 0.587\n",
            "Gen: 15.89 Disc: 0.25\n",
            "Batch 3700 | PSNR: 10.18 | SSIM: 0.586\n",
            "Gen: 12.67 Disc: 0.25\n",
            "Batch 3800 | PSNR: 10.17 | SSIM: 0.586\n",
            "Gen: 9.29 Disc: 0.25\n",
            "Batch 3900 | PSNR: 10.19 | SSIM: 0.586\n",
            "Gen: 9.19 Disc: 0.25\n",
            "Batch 4000 | PSNR: 10.21 | SSIM: 0.587\n",
            "Gen: 9.66 Disc: 0.25\n",
            "Batch 4100 | PSNR: 10.22 | SSIM: 0.587\n",
            "Gen: 14.22 Disc: 0.25\n",
            "Batch 4200 | PSNR: 10.19 | SSIM: 0.586\n",
            "Gen: 15.22 Disc: 0.25\n",
            "Batch 4300 | PSNR: 10.18 | SSIM: 0.586\n",
            "Gen: 9.47 Disc: 0.25\n",
            "Batch 4400 | PSNR: 10.16 | SSIM: 0.586\n",
            "Gen: 10.08 Disc: 0.25\n",
            "Batch 4500 | PSNR: 10.17 | SSIM: 0.586\n",
            "Gen: 9.83 Disc: 0.25\n",
            "Batch 4600 | PSNR: 10.16 | SSIM: 0.586\n",
            "Gen: 9.22 Disc: 0.25\n",
            "Batch 4700 | PSNR: 10.15 | SSIM: 0.586\n",
            "Gen: 9.83 Disc: 0.25\n",
            "Batch 4800 | PSNR: 10.14 | SSIM: 0.586\n",
            "Gen: 22.00 Disc: 0.25\n",
            "Batch 4900 | PSNR: 10.13 | SSIM: 0.586\n",
            "Gen: 9.77 Disc: 0.25\n",
            "Batch 5000 | PSNR: 10.13 | SSIM: 0.586\n",
            "Gen: 9.24 Disc: 0.25\n",
            "\n",
            "Epoch 50\n",
            "Time: 982.22s\n",
            "Gen Loss: 10.8359\n",
            "Disc Loss: 0.2510\n",
            "\n",
            "Train PSNR: 10.13 dB\n",
            "Train SSIM: 0.5862\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9919\n",
            "Batch 0 | PSNR: 10.91 | SSIM: 0.608\n",
            "Gen: 8.77 Disc: 0.25\n",
            "Batch 100 | PSNR: 10.44 | SSIM: 0.603\n",
            "Gen: 9.29 Disc: 0.25\n",
            "Batch 200 | PSNR: 10.74 | SSIM: 0.608\n",
            "Gen: 9.22 Disc: 0.25\n",
            "Batch 300 | PSNR: 10.52 | SSIM: 0.602\n",
            "Gen: 10.77 Disc: 0.25\n",
            "Batch 400 | PSNR: 10.11 | SSIM: 0.593\n",
            "Gen: 12.20 Disc: 0.25\n",
            "Batch 500 | PSNR: 10.21 | SSIM: 0.594\n",
            "Gen: 10.07 Disc: 0.25\n",
            "Batch 600 | PSNR: 10.27 | SSIM: 0.594\n",
            "Gen: 8.91 Disc: 0.25\n",
            "Batch 700 | PSNR: 10.37 | SSIM: 0.596\n",
            "Gen: 9.02 Disc: 0.25\n",
            "Batch 800 | PSNR: 10.44 | SSIM: 0.597\n",
            "Gen: 9.20 Disc: 0.25\n",
            "Batch 900 | PSNR: 10.52 | SSIM: 0.599\n",
            "Gen: 9.58 Disc: 0.25\n",
            "Batch 1000 | PSNR: 10.54 | SSIM: 0.599\n",
            "Gen: 14.54 Disc: 0.25\n",
            "Batch 1100 | PSNR: 10.32 | SSIM: 0.590\n",
            "Gen: 14.67 Disc: 0.25\n",
            "Batch 1200 | PSNR: 10.24 | SSIM: 0.587\n",
            "Gen: 11.65 Disc: 0.25\n",
            "Batch 1300 | PSNR: 10.23 | SSIM: 0.586\n",
            "Gen: 10.83 Disc: 0.25\n",
            "Batch 1400 | PSNR: 10.25 | SSIM: 0.585\n",
            "Gen: 11.39 Disc: 0.25\n",
            "Batch 1500 | PSNR: 10.27 | SSIM: 0.585\n",
            "Gen: 10.73 Disc: 0.25\n",
            "Batch 1600 | PSNR: 10.28 | SSIM: 0.585\n",
            "Gen: 11.38 Disc: 0.25\n",
            "Batch 1700 | PSNR: 10.28 | SSIM: 0.585\n",
            "Gen: 12.50 Disc: 0.25\n",
            "Batch 1800 | PSNR: 10.26 | SSIM: 0.585\n",
            "Gen: 12.12 Disc: 0.25\n",
            "Batch 1900 | PSNR: 10.25 | SSIM: 0.584\n",
            "Gen: 12.27 Disc: 0.25\n",
            "Batch 2000 | PSNR: 10.26 | SSIM: 0.584\n",
            "Gen: 11.23 Disc: 0.25\n",
            "Batch 2100 | PSNR: 10.27 | SSIM: 0.584\n",
            "Gen: 11.03 Disc: 0.25\n",
            "Batch 2200 | PSNR: 10.28 | SSIM: 0.584\n",
            "Gen: 11.19 Disc: 0.25\n",
            "Batch 2300 | PSNR: 10.29 | SSIM: 0.584\n",
            "Gen: 11.25 Disc: 0.25\n",
            "Batch 2400 | PSNR: 10.30 | SSIM: 0.584\n",
            "Gen: 11.44 Disc: 0.25\n",
            "Batch 2500 | PSNR: 10.30 | SSIM: 0.584\n",
            "Gen: 12.03 Disc: 0.25\n",
            "Batch 2600 | PSNR: 10.26 | SSIM: 0.583\n",
            "Gen: 12.12 Disc: 0.25\n",
            "Batch 2700 | PSNR: 10.24 | SSIM: 0.582\n",
            "Gen: 12.59 Disc: 0.25\n",
            "Batch 2800 | PSNR: 10.20 | SSIM: 0.581\n",
            "Gen: 13.83 Disc: 0.25\n",
            "Batch 2900 | PSNR: 10.18 | SSIM: 0.581\n",
            "Gen: 14.48 Disc: 0.25\n",
            "Batch 3000 | PSNR: 10.16 | SSIM: 0.580\n",
            "Gen: 14.29 Disc: 0.25\n",
            "Batch 3100 | PSNR: 10.13 | SSIM: 0.579\n",
            "Gen: 14.29 Disc: 0.25\n",
            "Batch 3200 | PSNR: 10.11 | SSIM: 0.577\n",
            "Gen: 14.22 Disc: 0.25\n",
            "Batch 3300 | PSNR: 10.09 | SSIM: 0.576\n",
            "Gen: 14.79 Disc: 0.25\n",
            "Batch 3400 | PSNR: 10.07 | SSIM: 0.575\n",
            "Gen: 15.04 Disc: 0.25\n",
            "Batch 3500 | PSNR: 10.05 | SSIM: 0.574\n",
            "Gen: 15.34 Disc: 0.25\n",
            "Batch 3600 | PSNR: 10.03 | SSIM: 0.572\n",
            "Gen: 15.91 Disc: 0.25\n",
            "Batch 3700 | PSNR: 10.00 | SSIM: 0.571\n",
            "Gen: 15.11 Disc: 0.25\n",
            "Batch 3800 | PSNR: 9.98 | SSIM: 0.570\n",
            "Gen: 15.09 Disc: 0.25\n",
            "Batch 3900 | PSNR: 9.97 | SSIM: 0.569\n",
            "Gen: 14.70 Disc: 0.25\n",
            "Batch 4000 | PSNR: 9.95 | SSIM: 0.567\n",
            "Gen: 21.72 Disc: 0.25\n",
            "Batch 4100 | PSNR: 9.92 | SSIM: 0.566\n",
            "Gen: 14.73 Disc: 0.25\n",
            "Batch 4200 | PSNR: 9.90 | SSIM: 0.565\n",
            "Gen: 15.32 Disc: 0.25\n",
            "Batch 4300 | PSNR: 9.89 | SSIM: 0.564\n",
            "Gen: 14.45 Disc: 0.25\n",
            "Batch 4400 | PSNR: 9.87 | SSIM: 0.563\n",
            "Gen: 14.96 Disc: 0.25\n",
            "Batch 4500 | PSNR: 9.86 | SSIM: 0.563\n",
            "Gen: 13.89 Disc: 0.25\n",
            "Batch 4600 | PSNR: 9.86 | SSIM: 0.562\n",
            "Gen: 13.98 Disc: 0.25\n",
            "Batch 4700 | PSNR: 9.86 | SSIM: 0.562\n",
            "Gen: 14.48 Disc: 0.25\n",
            "Batch 4800 | PSNR: 9.86 | SSIM: 0.561\n",
            "Gen: 14.14 Disc: 0.25\n",
            "Batch 4900 | PSNR: 9.86 | SSIM: 0.561\n",
            "Gen: 13.85 Disc: 0.25\n",
            "Batch 5000 | PSNR: 9.86 | SSIM: 0.560\n",
            "Gen: 13.77 Disc: 0.25\n",
            "\n",
            "Epoch 51\n",
            "Time: 940.05s\n",
            "Gen Loss: 12.8516\n",
            "Disc Loss: 0.2512\n",
            "\n",
            "Train PSNR: 9.86 dB\n",
            "Train SSIM: 0.5604\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9866\n",
            "Batch 0 | PSNR: 10.04 | SSIM: 0.544\n",
            "Gen: 13.31 Disc: 0.25\n",
            "Batch 100 | PSNR: 9.88 | SSIM: 0.544\n",
            "Gen: 13.62 Disc: 0.25\n",
            "Batch 200 | PSNR: 9.86 | SSIM: 0.544\n",
            "Gen: 14.20 Disc: 0.25\n",
            "Batch 300 | PSNR: 9.61 | SSIM: 0.538\n",
            "Gen: 17.38 Disc: 0.25\n",
            "Batch 400 | PSNR: 9.58 | SSIM: 0.539\n",
            "Gen: 14.55 Disc: 0.25\n",
            "Batch 500 | PSNR: 9.50 | SSIM: 0.539\n",
            "Gen: 14.47 Disc: 0.25\n",
            "Batch 600 | PSNR: 9.47 | SSIM: 0.541\n",
            "Gen: 14.63 Disc: 0.25\n",
            "Batch 700 | PSNR: 9.50 | SSIM: 0.543\n",
            "Gen: 14.54 Disc: 0.25\n",
            "Batch 800 | PSNR: 9.56 | SSIM: 0.544\n",
            "Gen: 14.33 Disc: 0.25\n",
            "Batch 900 | PSNR: 9.62 | SSIM: 0.545\n",
            "Gen: 14.68 Disc: 0.25\n",
            "Batch 1000 | PSNR: 9.66 | SSIM: 0.545\n",
            "Gen: 15.04 Disc: 0.25\n",
            "Batch 1100 | PSNR: 9.69 | SSIM: 0.546\n",
            "Gen: 14.85 Disc: 0.25\n",
            "Batch 1200 | PSNR: 9.72 | SSIM: 0.546\n",
            "Gen: 14.68 Disc: 0.25\n",
            "Batch 1300 | PSNR: 9.76 | SSIM: 0.547\n",
            "Gen: 14.46 Disc: 0.25\n",
            "Batch 1400 | PSNR: 9.79 | SSIM: 0.548\n",
            "Gen: 14.75 Disc: 0.25\n",
            "Batch 1500 | PSNR: 9.74 | SSIM: 0.547\n",
            "Gen: 15.54 Disc: 0.25\n",
            "Batch 1600 | PSNR: 9.74 | SSIM: 0.548\n",
            "Gen: 15.05 Disc: 0.25\n",
            "Batch 1700 | PSNR: 9.68 | SSIM: 0.546\n",
            "Gen: 17.42 Disc: 0.25\n",
            "Batch 1800 | PSNR: 9.67 | SSIM: 0.546\n",
            "Gen: 15.77 Disc: 0.25\n",
            "Batch 1900 | PSNR: 9.69 | SSIM: 0.547\n",
            "Gen: 15.25 Disc: 0.25\n",
            "Batch 2000 | PSNR: 9.65 | SSIM: 0.547\n",
            "Gen: 17.95 Disc: 0.25\n",
            "Batch 2100 | PSNR: 9.66 | SSIM: 0.547\n",
            "Gen: 14.05 Disc: 0.25\n",
            "Batch 2200 | PSNR: 9.67 | SSIM: 0.548\n",
            "Gen: 17.52 Disc: 0.25\n",
            "Batch 2300 | PSNR: 9.66 | SSIM: 0.548\n",
            "Gen: 13.53 Disc: 0.25\n",
            "Batch 2400 | PSNR: 9.67 | SSIM: 0.549\n",
            "Gen: 13.24 Disc: 0.25\n",
            "Batch 2500 | PSNR: 9.70 | SSIM: 0.549\n",
            "Gen: 12.84 Disc: 0.25\n",
            "Batch 2600 | PSNR: 9.70 | SSIM: 0.550\n",
            "Gen: 12.61 Disc: 0.25\n",
            "Batch 2700 | PSNR: 9.73 | SSIM: 0.551\n",
            "Gen: 14.20 Disc: 0.25\n",
            "Batch 2800 | PSNR: 9.74 | SSIM: 0.551\n",
            "Gen: 12.40 Disc: 0.25\n",
            "Batch 2900 | PSNR: 9.74 | SSIM: 0.552\n",
            "Gen: 12.41 Disc: 0.25\n",
            "Batch 3000 | PSNR: 9.76 | SSIM: 0.552\n",
            "Gen: 14.37 Disc: 0.25\n",
            "Batch 3100 | PSNR: 9.72 | SSIM: 0.552\n",
            "Gen: 22.92 Disc: 0.25\n",
            "Batch 3200 | PSNR: 9.71 | SSIM: 0.552\n",
            "Gen: 11.95 Disc: 0.25\n",
            "Batch 3300 | PSNR: 9.73 | SSIM: 0.552\n",
            "Gen: 13.86 Disc: 0.25\n",
            "Batch 3400 | PSNR: 9.75 | SSIM: 0.553\n",
            "Gen: 12.29 Disc: 0.25\n",
            "Batch 3500 | PSNR: 9.77 | SSIM: 0.554\n",
            "Gen: 11.34 Disc: 0.25\n",
            "Batch 3600 | PSNR: 9.79 | SSIM: 0.555\n",
            "Gen: 11.92 Disc: 0.25\n",
            "Batch 3700 | PSNR: 9.81 | SSIM: 0.555\n",
            "Gen: 12.74 Disc: 0.25\n",
            "Batch 3800 | PSNR: 9.83 | SSIM: 0.556\n",
            "Gen: 11.23 Disc: 0.25\n",
            "Batch 3900 | PSNR: 9.84 | SSIM: 0.557\n",
            "Gen: 12.37 Disc: 0.25\n",
            "Batch 4000 | PSNR: 9.85 | SSIM: 0.557\n",
            "Gen: 11.38 Disc: 0.25\n",
            "Batch 4100 | PSNR: 9.86 | SSIM: 0.558\n",
            "Gen: 10.92 Disc: 0.25\n",
            "Batch 4200 | PSNR: 9.88 | SSIM: 0.559\n",
            "Gen: 11.01 Disc: 0.25\n",
            "Batch 4300 | PSNR: 9.87 | SSIM: 0.559\n",
            "Gen: 11.65 Disc: 0.25\n",
            "Batch 4400 | PSNR: 9.88 | SSIM: 0.560\n",
            "Gen: 13.74 Disc: 0.25\n",
            "Batch 4500 | PSNR: 9.84 | SSIM: 0.558\n",
            "Gen: 24.16 Disc: 0.25\n",
            "Batch 4600 | PSNR: 9.82 | SSIM: 0.559\n",
            "Gen: 10.83 Disc: 0.25\n",
            "Batch 4700 | PSNR: 9.84 | SSIM: 0.559\n",
            "Gen: 11.05 Disc: 0.25\n",
            "Batch 4800 | PSNR: 9.86 | SSIM: 0.560\n",
            "Gen: 10.96 Disc: 0.25\n",
            "Batch 4900 | PSNR: 9.88 | SSIM: 0.560\n",
            "Gen: 10.80 Disc: 0.25\n",
            "Batch 5000 | PSNR: 9.90 | SSIM: 0.561\n",
            "Gen: 10.91 Disc: 0.25\n",
            "\n",
            "Epoch 52\n",
            "Time: 955.08s\n",
            "Gen Loss: 13.8984\n",
            "Disc Loss: 0.2510\n",
            "\n",
            "Train PSNR: 9.90 dB\n",
            "Train SSIM: 0.5609\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9953\n",
            "Batch 0 | PSNR: 10.65 | SSIM: 0.590\n",
            "Gen: 10.81 Disc: 0.25\n",
            "Batch 100 | PSNR: 9.81 | SSIM: 0.583\n",
            "Gen: 10.94 Disc: 0.25\n",
            "Batch 200 | PSNR: 10.20 | SSIM: 0.583\n",
            "Gen: 12.01 Disc: 0.25\n",
            "Batch 300 | PSNR: 10.33 | SSIM: 0.586\n",
            "Gen: 10.39 Disc: 0.25\n",
            "Batch 400 | PSNR: 10.32 | SSIM: 0.587\n",
            "Gen: 10.42 Disc: 0.25\n",
            "Batch 500 | PSNR: 10.44 | SSIM: 0.589\n",
            "Gen: 11.05 Disc: 0.25\n",
            "Batch 600 | PSNR: 10.14 | SSIM: 0.581\n",
            "Gen: 31.09 Disc: 0.25\n",
            "Batch 700 | PSNR: 9.79 | SSIM: 0.571\n",
            "Gen: 14.68 Disc: 0.25\n",
            "Batch 800 | PSNR: 9.88 | SSIM: 0.573\n",
            "Gen: 10.59 Disc: 0.25\n",
            "Batch 900 | PSNR: 9.98 | SSIM: 0.574\n",
            "Gen: 10.63 Disc: 0.25\n",
            "Batch 1000 | PSNR: 10.09 | SSIM: 0.576\n",
            "Gen: 10.67 Disc: 0.25\n",
            "Batch 1100 | PSNR: 9.98 | SSIM: 0.574\n",
            "Gen: 10.83 Disc: 0.25\n",
            "Batch 1200 | PSNR: 10.02 | SSIM: 0.575\n",
            "Gen: 10.52 Disc: 0.25\n",
            "Batch 1300 | PSNR: 10.01 | SSIM: 0.575\n",
            "Gen: 10.34 Disc: 0.25\n",
            "Batch 1400 | PSNR: 10.06 | SSIM: 0.577\n",
            "Gen: 14.34 Disc: 0.25\n",
            "Batch 1500 | PSNR: 10.06 | SSIM: 0.578\n",
            "Gen: 10.30 Disc: 0.25\n",
            "Batch 1600 | PSNR: 10.12 | SSIM: 0.579\n",
            "Gen: 10.47 Disc: 0.25\n",
            "Batch 1700 | PSNR: 10.09 | SSIM: 0.578\n",
            "Gen: 28.98 Disc: 0.25\n",
            "Batch 1800 | PSNR: 10.03 | SSIM: 0.576\n",
            "Gen: 10.48 Disc: 0.25\n",
            "Batch 1900 | PSNR: 10.07 | SSIM: 0.576\n",
            "Gen: 10.55 Disc: 0.25\n",
            "Batch 2000 | PSNR: 10.11 | SSIM: 0.577\n",
            "Gen: 10.38 Disc: 0.25\n",
            "Batch 2100 | PSNR: 10.15 | SSIM: 0.578\n",
            "Gen: 10.05 Disc: 0.25\n",
            "Batch 2200 | PSNR: 10.19 | SSIM: 0.579\n",
            "Gen: 10.29 Disc: 0.25\n",
            "Batch 2300 | PSNR: 10.21 | SSIM: 0.580\n",
            "Gen: 11.52 Disc: 0.25\n",
            "Batch 2400 | PSNR: 10.23 | SSIM: 0.581\n",
            "Gen: 10.38 Disc: 0.25\n",
            "Batch 2500 | PSNR: 10.23 | SSIM: 0.581\n",
            "Gen: 10.33 Disc: 0.25\n",
            "Batch 2600 | PSNR: 10.26 | SSIM: 0.582\n",
            "Gen: 10.20 Disc: 0.25\n",
            "Batch 2700 | PSNR: 10.25 | SSIM: 0.582\n",
            "Gen: 10.16 Disc: 0.25\n",
            "Batch 2800 | PSNR: 10.24 | SSIM: 0.582\n",
            "Gen: 11.68 Disc: 0.25\n",
            "Batch 2900 | PSNR: 10.20 | SSIM: 0.580\n",
            "Gen: 13.76 Disc: 0.25\n",
            "Batch 3000 | PSNR: 10.22 | SSIM: 0.581\n",
            "Gen: 9.52 Disc: 0.25\n",
            "Batch 3100 | PSNR: 10.24 | SSIM: 0.582\n",
            "Gen: 9.47 Disc: 0.25\n",
            "Batch 3200 | PSNR: 10.27 | SSIM: 0.583\n",
            "Gen: 10.86 Disc: 0.25\n",
            "Batch 3300 | PSNR: 10.28 | SSIM: 0.583\n",
            "Gen: 9.66 Disc: 0.25\n",
            "Batch 3400 | PSNR: 10.30 | SSIM: 0.584\n",
            "Gen: 13.30 Disc: 0.25\n",
            "Batch 3500 | PSNR: 10.26 | SSIM: 0.583\n",
            "Gen: 16.27 Disc: 0.25\n",
            "Batch 3600 | PSNR: 10.26 | SSIM: 0.583\n",
            "Gen: 9.88 Disc: 0.25\n",
            "Batch 3700 | PSNR: 10.28 | SSIM: 0.584\n",
            "Gen: 10.10 Disc: 0.25\n",
            "Batch 3800 | PSNR: 10.29 | SSIM: 0.584\n",
            "Gen: 9.91 Disc: 0.25\n",
            "Batch 3900 | PSNR: 10.30 | SSIM: 0.585\n",
            "Gen: 9.84 Disc: 0.25\n",
            "Batch 4000 | PSNR: 10.32 | SSIM: 0.585\n",
            "Gen: 10.05 Disc: 0.25\n",
            "Batch 4100 | PSNR: 10.28 | SSIM: 0.584\n",
            "Gen: 10.36 Disc: 0.25\n",
            "Batch 4200 | PSNR: 10.26 | SSIM: 0.584\n",
            "Gen: 12.84 Disc: 0.25\n",
            "Batch 4300 | PSNR: 10.24 | SSIM: 0.584\n",
            "Gen: 9.87 Disc: 0.25\n",
            "Batch 4400 | PSNR: 10.26 | SSIM: 0.584\n",
            "Gen: 9.86 Disc: 0.25\n",
            "Batch 4500 | PSNR: 10.27 | SSIM: 0.585\n",
            "Gen: 9.66 Disc: 0.25\n",
            "Batch 4600 | PSNR: 10.27 | SSIM: 0.586\n",
            "Gen: 8.82 Disc: 0.25\n",
            "Batch 4700 | PSNR: 10.29 | SSIM: 0.586\n",
            "Gen: 9.27 Disc: 0.25\n",
            "Batch 4800 | PSNR: 10.30 | SSIM: 0.586\n",
            "Gen: 9.89 Disc: 0.25\n",
            "Batch 4900 | PSNR: 10.26 | SSIM: 0.585\n",
            "Gen: 27.66 Disc: 0.25\n",
            "Batch 5000 | PSNR: 10.22 | SSIM: 0.584\n",
            "Gen: 9.55 Disc: 0.25\n",
            "\n",
            "Epoch 53\n",
            "Time: 953.42s\n",
            "Gen Loss: 11.6406\n",
            "Disc Loss: 0.2512\n",
            "\n",
            "Train PSNR: 10.22 dB\n",
            "Train SSIM: 0.5843\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9947\n",
            "Batch 0 | PSNR: 10.38 | SSIM: 0.592\n",
            "Gen: 9.29 Disc: 0.25\n",
            "Batch 100 | PSNR: 10.73 | SSIM: 0.607\n",
            "Gen: 9.47 Disc: 0.25\n",
            "Batch 200 | PSNR: 10.90 | SSIM: 0.611\n",
            "Gen: 9.22 Disc: 0.25\n",
            "Batch 300 | PSNR: 10.82 | SSIM: 0.610\n",
            "Gen: 10.59 Disc: 0.25\n",
            "Batch 400 | PSNR: 10.56 | SSIM: 0.607\n",
            "Gen: 9.20 Disc: 0.25\n",
            "Batch 500 | PSNR: 10.55 | SSIM: 0.606\n",
            "Gen: 10.55 Disc: 0.25\n",
            "Batch 600 | PSNR: 10.54 | SSIM: 0.606\n",
            "Gen: 8.97 Disc: 0.25\n",
            "Batch 700 | PSNR: 10.46 | SSIM: 0.603\n",
            "Gen: 16.72 Disc: 0.25\n",
            "Batch 800 | PSNR: 10.39 | SSIM: 0.600\n",
            "Gen: 9.52 Disc: 0.25\n",
            "Batch 900 | PSNR: 10.44 | SSIM: 0.601\n",
            "Gen: 9.41 Disc: 0.25\n",
            "Batch 1000 | PSNR: 10.48 | SSIM: 0.602\n",
            "Gen: 9.64 Disc: 0.25\n",
            "Batch 1100 | PSNR: 10.41 | SSIM: 0.601\n",
            "Gen: 9.93 Disc: 0.25\n",
            "Batch 1200 | PSNR: 10.41 | SSIM: 0.601\n",
            "Gen: 9.26 Disc: 0.25\n",
            "Batch 1300 | PSNR: 10.39 | SSIM: 0.600\n",
            "Gen: 9.54 Disc: 0.25\n",
            "Batch 1400 | PSNR: 10.38 | SSIM: 0.600\n",
            "Gen: 10.66 Disc: 0.25\n",
            "Batch 1500 | PSNR: 10.36 | SSIM: 0.600\n",
            "Gen: 9.69 Disc: 0.25\n",
            "Batch 1600 | PSNR: 10.24 | SSIM: 0.595\n",
            "Gen: 15.80 Disc: 0.25\n",
            "Batch 1700 | PSNR: 10.23 | SSIM: 0.595\n",
            "Gen: 9.65 Disc: 0.25\n",
            "Batch 1800 | PSNR: 10.26 | SSIM: 0.596\n",
            "Gen: 9.08 Disc: 0.25\n",
            "Batch 1900 | PSNR: 10.29 | SSIM: 0.596\n",
            "Gen: 9.90 Disc: 0.25\n",
            "Batch 2000 | PSNR: 10.31 | SSIM: 0.597\n",
            "Gen: 9.62 Disc: 0.25\n",
            "Batch 2100 | PSNR: 10.33 | SSIM: 0.597\n",
            "Gen: 9.61 Disc: 0.25\n",
            "Batch 2200 | PSNR: 10.31 | SSIM: 0.597\n",
            "Gen: 10.95 Disc: 0.25\n",
            "Batch 2300 | PSNR: 10.21 | SSIM: 0.593\n",
            "Gen: 24.23 Disc: 0.25\n",
            "Batch 2400 | PSNR: 10.10 | SSIM: 0.589\n",
            "Gen: 14.66 Disc: 0.25\n",
            "Batch 2500 | PSNR: 10.10 | SSIM: 0.589\n",
            "Gen: 10.55 Disc: 0.25\n",
            "Batch 2600 | PSNR: 10.12 | SSIM: 0.590\n",
            "Gen: 9.95 Disc: 0.25\n",
            "Batch 2700 | PSNR: 10.13 | SSIM: 0.590\n",
            "Gen: 10.16 Disc: 0.25\n",
            "Batch 2800 | PSNR: 10.14 | SSIM: 0.591\n",
            "Gen: 9.87 Disc: 0.25\n",
            "Batch 2900 | PSNR: 10.15 | SSIM: 0.592\n",
            "Gen: 9.62 Disc: 0.25\n",
            "Batch 3000 | PSNR: 10.18 | SSIM: 0.592\n",
            "Gen: 10.46 Disc: 0.25\n",
            "Batch 3100 | PSNR: 10.14 | SSIM: 0.591\n",
            "Gen: 10.74 Disc: 0.25\n",
            "Batch 3200 | PSNR: 10.16 | SSIM: 0.592\n",
            "Gen: 9.30 Disc: 0.25\n",
            "Batch 3300 | PSNR: 10.17 | SSIM: 0.592\n",
            "Gen: 9.61 Disc: 0.25\n",
            "Batch 3400 | PSNR: 10.18 | SSIM: 0.592\n",
            "Gen: 10.95 Disc: 0.25\n",
            "Batch 3500 | PSNR: 10.20 | SSIM: 0.593\n",
            "Gen: 10.13 Disc: 0.25\n",
            "Batch 3600 | PSNR: 10.21 | SSIM: 0.593\n",
            "Gen: 10.17 Disc: 0.25\n",
            "Batch 3700 | PSNR: 10.21 | SSIM: 0.593\n",
            "Gen: 9.22 Disc: 0.25\n",
            "Batch 3800 | PSNR: 10.20 | SSIM: 0.593\n",
            "Gen: 10.05 Disc: 0.25\n",
            "Batch 3900 | PSNR: 10.20 | SSIM: 0.593\n",
            "Gen: 10.13 Disc: 0.25\n",
            "Batch 4000 | PSNR: 10.20 | SSIM: 0.593\n",
            "Gen: 10.07 Disc: 0.25\n",
            "Batch 4100 | PSNR: 10.19 | SSIM: 0.593\n",
            "Gen: 9.12 Disc: 0.25\n",
            "Batch 4200 | PSNR: 10.20 | SSIM: 0.594\n",
            "Gen: 10.33 Disc: 0.25\n",
            "Batch 4300 | PSNR: 10.15 | SSIM: 0.592\n",
            "Gen: 19.05 Disc: 0.25\n",
            "Batch 4400 | PSNR: 10.14 | SSIM: 0.592\n",
            "Gen: 10.36 Disc: 0.25\n",
            "Batch 4500 | PSNR: 10.14 | SSIM: 0.592\n",
            "Gen: 9.27 Disc: 0.25\n",
            "Batch 4600 | PSNR: 10.15 | SSIM: 0.592\n",
            "Gen: 8.88 Disc: 0.25\n",
            "Batch 4700 | PSNR: 10.16 | SSIM: 0.593\n",
            "Gen: 9.36 Disc: 0.25\n",
            "Batch 4800 | PSNR: 10.17 | SSIM: 0.593\n",
            "Gen: 9.55 Disc: 0.25\n",
            "Batch 4900 | PSNR: 10.15 | SSIM: 0.592\n",
            "Gen: 37.16 Disc: 0.25\n",
            "Batch 5000 | PSNR: 10.10 | SSIM: 0.590\n",
            "Gen: 24.48 Disc: 0.25\n",
            "\n",
            "Epoch 54\n",
            "Time: 953.18s\n",
            "Gen Loss: 11.1797\n",
            "Disc Loss: 0.2512\n",
            "\n",
            "Train PSNR: 10.09 dB\n",
            "Train SSIM: 0.5901\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9899\n",
            "Batch 0 | PSNR: 6.92 | SSIM: 0.462\n",
            "Gen: 17.42 Disc: 0.25\n",
            "Batch 100 | PSNR: 8.68 | SSIM: 0.536\n",
            "Gen: 10.80 Disc: 0.25\n",
            "Batch 200 | PSNR: 9.60 | SSIM: 0.568\n",
            "Gen: 10.10 Disc: 0.25\n",
            "Batch 300 | PSNR: 9.92 | SSIM: 0.581\n",
            "Gen: 9.95 Disc: 0.25\n",
            "Batch 400 | PSNR: 9.98 | SSIM: 0.587\n",
            "Gen: 9.55 Disc: 0.25\n",
            "Batch 500 | PSNR: 10.07 | SSIM: 0.591\n",
            "Gen: 9.22 Disc: 0.25\n",
            "Batch 600 | PSNR: 10.16 | SSIM: 0.593\n",
            "Gen: 9.07 Disc: 0.25\n",
            "Batch 700 | PSNR: 10.23 | SSIM: 0.595\n",
            "Gen: 9.16 Disc: 0.25\n",
            "Batch 800 | PSNR: 10.29 | SSIM: 0.597\n",
            "Gen: 9.73 Disc: 0.25\n",
            "Batch 900 | PSNR: 10.30 | SSIM: 0.598\n",
            "Gen: 10.45 Disc: 0.25\n",
            "Batch 1000 | PSNR: 10.27 | SSIM: 0.596\n",
            "Gen: 12.14 Disc: 0.25\n",
            "Batch 1100 | PSNR: 10.27 | SSIM: 0.596\n",
            "Gen: 9.78 Disc: 0.25\n",
            "Batch 1200 | PSNR: 10.26 | SSIM: 0.596\n",
            "Gen: 9.34 Disc: 0.25\n",
            "Batch 1300 | PSNR: 10.26 | SSIM: 0.596\n",
            "Gen: 9.84 Disc: 0.25\n",
            "Batch 1400 | PSNR: 10.28 | SSIM: 0.597\n",
            "Gen: 9.74 Disc: 0.25\n",
            "Batch 1500 | PSNR: 10.29 | SSIM: 0.597\n",
            "Gen: 9.08 Disc: 0.25\n",
            "Batch 1600 | PSNR: 10.32 | SSIM: 0.598\n",
            "Gen: 9.43 Disc: 0.25\n",
            "Batch 1700 | PSNR: 10.31 | SSIM: 0.598\n",
            "Gen: 9.86 Disc: 0.25\n",
            "Batch 1800 | PSNR: 10.28 | SSIM: 0.597\n",
            "Gen: 23.83 Disc: 0.25\n",
            "Batch 1900 | PSNR: 10.23 | SSIM: 0.595\n",
            "Gen: 10.77 Disc: 0.25\n",
            "Batch 2000 | PSNR: 10.24 | SSIM: 0.595\n",
            "Gen: 9.88 Disc: 0.25\n",
            "Batch 2100 | PSNR: 10.25 | SSIM: 0.595\n",
            "Gen: 10.88 Disc: 0.25\n",
            "Batch 2200 | PSNR: 10.17 | SSIM: 0.592\n",
            "Gen: 19.02 Disc: 0.25\n",
            "Batch 2300 | PSNR: 10.11 | SSIM: 0.591\n",
            "Gen: 10.46 Disc: 0.25\n",
            "Batch 2400 | PSNR: 10.10 | SSIM: 0.591\n",
            "Gen: 10.02 Disc: 0.25\n",
            "Batch 2500 | PSNR: 10.11 | SSIM: 0.591\n",
            "Gen: 9.69 Disc: 0.25\n",
            "Batch 2600 | PSNR: 10.11 | SSIM: 0.592\n",
            "Gen: 9.49 Disc: 0.25\n",
            "Batch 2700 | PSNR: 10.12 | SSIM: 0.592\n",
            "Gen: 9.33 Disc: 0.25\n",
            "Batch 2800 | PSNR: 10.13 | SSIM: 0.592\n",
            "Gen: 9.47 Disc: 0.25\n",
            "Batch 2900 | PSNR: 10.14 | SSIM: 0.593\n",
            "Gen: 9.58 Disc: 0.25\n",
            "Batch 3000 | PSNR: 10.15 | SSIM: 0.593\n",
            "Gen: 12.37 Disc: 0.25\n",
            "Batch 3100 | PSNR: 10.07 | SSIM: 0.590\n",
            "Gen: 15.02 Disc: 0.25\n",
            "Batch 3200 | PSNR: 10.07 | SSIM: 0.590\n",
            "Gen: 9.38 Disc: 0.25\n",
            "Batch 3300 | PSNR: 10.08 | SSIM: 0.590\n",
            "Gen: 9.58 Disc: 0.25\n",
            "Batch 3400 | PSNR: 10.10 | SSIM: 0.590\n",
            "Gen: 10.09 Disc: 0.25\n",
            "Batch 3500 | PSNR: 10.11 | SSIM: 0.591\n",
            "Gen: 9.33 Disc: 0.25\n",
            "Batch 3600 | PSNR: 10.13 | SSIM: 0.591\n",
            "Gen: 9.91 Disc: 0.25\n",
            "Batch 3700 | PSNR: 10.13 | SSIM: 0.591\n",
            "Gen: 11.03 Disc: 0.25\n",
            "Batch 3800 | PSNR: 10.13 | SSIM: 0.592\n",
            "Gen: 9.52 Disc: 0.25\n",
            "Batch 3900 | PSNR: 10.12 | SSIM: 0.591\n",
            "Gen: 17.33 Disc: 0.25\n",
            "Batch 4000 | PSNR: 10.09 | SSIM: 0.590\n",
            "Gen: 10.35 Disc: 0.25\n",
            "Batch 4100 | PSNR: 10.07 | SSIM: 0.590\n",
            "Gen: 26.14 Disc: 0.25\n",
            "Batch 4200 | PSNR: 10.02 | SSIM: 0.588\n",
            "Gen: 17.30 Disc: 0.25\n",
            "Batch 4300 | PSNR: 10.00 | SSIM: 0.587\n",
            "Gen: 10.96 Disc: 0.25\n",
            "Batch 4400 | PSNR: 10.02 | SSIM: 0.587\n",
            "Gen: 10.45 Disc: 0.25\n",
            "Batch 4500 | PSNR: 10.01 | SSIM: 0.588\n",
            "Gen: 9.58 Disc: 0.25\n",
            "Batch 4600 | PSNR: 10.02 | SSIM: 0.588\n",
            "Gen: 8.90 Disc: 0.25\n",
            "Batch 4700 | PSNR: 10.03 | SSIM: 0.589\n",
            "Gen: 9.41 Disc: 0.25\n",
            "Batch 4800 | PSNR: 10.04 | SSIM: 0.589\n",
            "Gen: 9.29 Disc: 0.25\n",
            "Batch 4900 | PSNR: 10.05 | SSIM: 0.589\n",
            "Gen: 9.29 Disc: 0.25\n",
            "Batch 5000 | PSNR: 10.06 | SSIM: 0.589\n",
            "Gen: 9.61 Disc: 0.25\n",
            "\n",
            "Epoch 55\n",
            "Time: 940.39s\n",
            "Gen Loss: 10.7812\n",
            "Disc Loss: 0.2512\n",
            "\n",
            "Train PSNR: 10.06 dB\n",
            "Train SSIM: 0.5894\n",
            "Val PSNR: inf dB\n",
            "Val SSIM: 0.9952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Inference Function\n",
        "# ----------------------\n",
        "def colorize_image(model, image_path, output_path, image_size=64):\n",
        "    \"\"\"\n",
        "    Colorizes a single image using the trained generator.\n",
        "\n",
        "    Args:\n",
        "        model: Trained generator model\n",
        "        image_path: Path to input grayscale/RGB image\n",
        "        output_path: Path to save colorized image\n",
        "        image_size: Size to resize image (must match model input)\n",
        "    \"\"\"\n",
        "    # Load and preprocess image\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        raise FileNotFoundError(f\"Could not load image at {image_path}\")\n",
        "\n",
        "    # Convert to RGB if needed\n",
        "    if image.ndim == 2:  # Grayscale\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "    else:  # BGR to RGB\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize and normalize\n",
        "    image = cv2.resize(image, (image_size, image_size))\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "\n",
        "    # Convert to LAB and extract L channel\n",
        "    lab = rgb2lab(image)\n",
        "    L = lab[:, :, 0:1]  # (H, W, 1)\n",
        "\n",
        "    # Add batch dimension and predict\n",
        "    L_batch = np.expand_dims(L, axis=0)  # (1, H, W, 1)\n",
        "    AB_pred = model.predict(L_batch, verbose=0)[0]  # (H, W, 2)\n",
        "\n",
        "    # Denormalize AB channels\n",
        "    AB_pred = (AB_pred * 128.0).astype(np.float32)\n",
        "\n",
        "    # Combine with L and convert to RGB\n",
        "    colorized_lab = np.concatenate([L, AB_pred], axis=-1)\n",
        "    colorized_rgb = lab2rgb(colorized_lab)\n",
        "\n",
        "    # Clip and save\n",
        "    colorized_rgb = np.clip(colorized_rgb, 0, 1)\n",
        "    plt.imsave(output_path, colorized_rgb)\n",
        "    print(f\"Colorized image saved to {output_path}\")"
      ],
      "metadata": {
        "id": "PmQiENqcR8bz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# After training, use like this:\n",
        "colorize_image(\n",
        "    generator,\n",
        "    \"/content/Test/rose.jpeg\",  # Input path\n",
        "    \"/content/colorized_result.jpg\"     # Output path\n",
        ")\n",
        "\n",
        "calculate_frame_psnr(\"/content/Test/rose.jpeg\",\"/content/colorized_result.jpg\")"
      ],
      "metadata": {
        "id": "TfAazZuISFbG",
        "outputId": "172a98cc-4476-4f05-85db-fc702519f131",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colorized image saved to /content/colorized_result.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------\n",
        "# Parallel Video Colorization with Temporal Consistency\n",
        "# ----------------------\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "# ----------------------\n",
        "# Video Colorizer with Content Directory Temp Files\n",
        "# ----------------------\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import tempfile\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n",
        "class VideoColorizer:\n",
        "    def __init__(self, model, temporal_alpha=0.8, blend_factor=0.7):\n",
        "        self.model = model\n",
        "        self.temporal_alpha = temporal_alpha\n",
        "        self.blend_factor = blend_factor\n",
        "        # Optical flow parameters\n",
        "        self.flow_params = {\n",
        "            'pyr_scale': 0.5,\n",
        "            'levels': 3,\n",
        "            'winsize': 15,\n",
        "            'iterations': 3,\n",
        "            'poly_n': 5,\n",
        "            'poly_sigma': 1.2,\n",
        "            'flags': cv2.OPTFLOW_FARNEBACK_GAUSSIAN\n",
        "        }\n",
        "        # Create temp directory in Colab's content directory\n",
        "        self.temp_dir = tempfile.TemporaryDirectory(\n",
        "            dir='/content',\n",
        "            prefix='colorizer_temp_'\n",
        "        )\n",
        "        os.makedirs(self.temp_dir.name, exist_ok=True)\n",
        "        os.chmod(self.temp_dir.name, 0o777)  # Ensure write permissions\n",
        "        print(f\"Created temp directory at: {self.temp_dir.name}\")\n",
        "\n",
        "    def _process_chunk(self, frames, start_idx):\n",
        "        \"\"\"Process a chunk of frames in parallel\"\"\"\n",
        "        print(f\"Processing chunk starting at {start_idx} with {len(frames)} frames\")\n",
        "\n",
        "        for local_idx, frame in enumerate(frames):\n",
        "            global_idx = start_idx + local_idx\n",
        "            save_path = os.path.join(\n",
        "                self.temp_dir.name,\n",
        "                f\"frame_{global_idx:06d}.npy\"  # Consistent naming\n",
        "            )\n",
        "\n",
        "            # Debug: Verify frame content\n",
        "            if frame is None or frame.size == 0:\n",
        "                raise ValueError(f\"Invalid frame at index {global_idx}\")\n",
        "\n",
        "            # Colorization pipeline\n",
        "            resized_rgb = cv2.resize(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB), (64, 64))\n",
        "            lab = rgb2lab(resized_rgb.astype(np.float32)/255.0)\n",
        "            L = lab[:, :, 0:1]\n",
        "            AB = self.model.predict(np.expand_dims(L, axis=0), verbose=0)[0]\n",
        "\n",
        "            # Save data with verification\n",
        "            data = {\n",
        "                'frame': frame,\n",
        "                'L': L,\n",
        "                'AB': AB,\n",
        "                'gray': cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "            }\n",
        "            np.save(save_path, data)\n",
        "            print(f\"Saved frame {global_idx} to {save_path}\")\n",
        "\n",
        "        # Immediate verification of saved files\n",
        "        saved_files = [f for f in os.listdir(self.temp_dir.name)\n",
        "                      if f.startswith(f\"frame_{start_idx:06d}\")]\n",
        "        print(f\"Saved {len(saved_files)} files in this chunk\")\n",
        "\n",
        "        return True\n",
        "\n",
        "    def _temporal_smooth(self, prev_data, current_data):\n",
        "        \"\"\"Apply temporal consistency between frames\"\"\"\n",
        "        if prev_data is None:\n",
        "            return current_data['AB']\n",
        "\n",
        "        # Compute optical flow at model resolution\n",
        "        target_size = (64, 64)\n",
        "        prev_gray = cv2.resize(prev_data['gray'], target_size)\n",
        "        current_gray = cv2.resize(current_data['gray'], target_size)\n",
        "\n",
        "        flow = cv2.calcOpticalFlowFarneback(\n",
        "            prev_gray, current_gray,\n",
        "            None, **self.flow_params\n",
        "        )\n",
        "\n",
        "        # Create normalized coordinate grid\n",
        "        h, w = target_size\n",
        "        x_map, y_map = np.meshgrid(np.arange(w), np.arange(h))\n",
        "        flow_map = np.stack([\n",
        "           (x_map + flow[..., 0]).astype(np.float32),\n",
        "           (y_map + flow[..., 1]).astype(np.float32)\n",
        "        ], axis=-1)\n",
        "\n",
        "        # Ensure coordinates stay within image bounds\n",
        "        flow_map[..., 0] = np.clip(flow_map[..., 0], 0, w-1)\n",
        "        flow_map[..., 1] = np.clip(flow_map[..., 1], 0, h-1)\n",
        "\n",
        "\n",
        "\n",
        "        # Warp previous AB channels\n",
        "        warped_AB = cv2.remap(\n",
        "            prev_data['AB'].astype(np.float32),  # Ensure float32 input\n",
        "            flow_map,\n",
        "            None,\n",
        "            cv2.INTER_LINEAR,\n",
        "            borderMode=cv2.BORDER_REFLECT\n",
        "        )\n",
        "\n",
        "        # Handle invalid regions (black borders from warping)\n",
        "        mask = (warped_AB == 0).all(axis=-1, keepdims=True)\n",
        "        blended_AB = np.where(mask, current_data['AB'],\n",
        "                         self.blend_factor * current_data['AB'] +\n",
        "                         (1 - self.blend_factor) * warped_AB)\n",
        "\n",
        "        smoothed_AB = self.temporal_alpha * blended_AB + \\\n",
        "                     (1 - self.temporal_alpha) * warped_AB\n",
        "        return smoothed_AB\n",
        "\n",
        "\n",
        "    def colorize_video(self, input_path, output_path, batch_size=16, workers=8):\n",
        "        # Open video once for all processing\n",
        "        cap = cv2.VideoCapture(input_path)\n",
        "        if not cap.isOpened():\n",
        "            raise ValueError(f\"Couldn't open video {input_path}\")\n",
        "\n",
        "        # Get video properties from the first frame\n",
        "        ret, first_frame = cap.read()\n",
        "        if not ret:\n",
        "            cap.release()\n",
        "            raise ValueError(\"Couldn't read first frame\")\n",
        "        frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "        print(f\"Width: {frame_width} | Height: {frame_height} | FPS: {fps}\")\n",
        "        # Rewind to beginning\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "\n",
        "        # Initialize video writer\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "        writer = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height), isColor=True)\n",
        "\n",
        "        # Process frames in a single pass\n",
        "        executor = ThreadPoolExecutor(max_workers=workers)\n",
        "        futures = []\n",
        "        chunk = []\n",
        "        frame_count = 0\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "            chunk.append(frame)\n",
        "            frame_count += 1\n",
        "            if len(chunk) == batch_size:\n",
        "                future = executor.submit(self._process_chunk, chunk.copy(), frame_count - len(chunk))\n",
        "                futures.append(future)\n",
        "                chunk = []\n",
        "\n",
        "        # Process remaining frames\n",
        "        if chunk:\n",
        "            future = executor.submit(self._process_chunk, chunk, frame_count - len(chunk))\n",
        "            futures.append(future)\n",
        "\n",
        "        # Wait for all processing to finish\n",
        "        for f in futures:\n",
        "            f.result()\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "\n",
        "        # 4. Reconstruct video with temporal smoothing\n",
        "        saved_files = sorted(\n",
        "            [f for f in os.listdir(self.temp_dir.name)\n",
        "             if f.startswith('frame_') and f.endswith('.npy')],\n",
        "            key=lambda x: int(x.split('_')[1].split('.')[0]))\n",
        "\n",
        "        prev_data = None\n",
        "        for i, filename in enumerate(saved_files):\n",
        "            file_path = os.path.join(self.temp_dir.name, filename)\n",
        "            data = np.load(file_path, allow_pickle=True).item()\n",
        "\n",
        "            # Apply temporal smoothing\n",
        "            smoothed_AB = self._temporal_smooth(prev_data, data)\n",
        "\n",
        "            # Reconstruct frame\n",
        "            rgb_resized = cv2.resize(\n",
        "                cv2.cvtColor(data['frame'], cv2.COLOR_BGR2RGB),\n",
        "                (64, 64))\n",
        "            lab = rgb2lab(rgb_resized.astype(np.float32)/255.0)\n",
        "            final_lab = np.concatenate([lab[..., 0:1], smoothed_AB], axis=-1)\n",
        "\n",
        "            # Convert to output dimensions\n",
        "            colorized_rgb = (lab2rgb(final_lab) * 255).astype(np.uint8)\n",
        "            final_frame = cv2.resize(\n",
        "            colorized_rgb,\n",
        "            (frame_width, frame_height))\n",
        "            final_bgr = cv2.cvtColor(final_frame, cv2.COLOR_RGB2BGR)\n",
        "\n",
        "            writer.write(final_bgr)\n",
        "\n",
        "            prev_data = {'AB': smoothed_AB, 'gray': data['gray']}\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print(f\"Processed {i+1}/{len(saved_files)} frames\")\n",
        "\n",
        "        # 5. Final cleanup\n",
        "        writer.release()\n",
        "        self.temp_dir.cleanup()\n",
        "\n",
        "        # Verify output\n",
        "        if os.path.exists(output_path):\n",
        "            print(f\"\\n✅ Success! Colorized video saved to: {output_path}\")\n",
        "            print(f\"Resolution: {frame_width}x{frame_height} | Frames: {len(saved_files)}\")\n",
        "        else:\n",
        "            print(\"\\n❌ Video creation failed - check codec compatibility\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6FYBJCluSoP8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "colorizer = VideoColorizer(generator, temporal_alpha=0.85)\n",
        "\n",
        "\n",
        "colorizer.colorize_video(\n",
        "    \"/content/drive/MyDrive/Colorization/Video/Input.mp4\",\n",
        "    \"/content/drive/MyDrive/Colorization/Video/Output.mp4\",\n",
        "    batch_size=32,\n",
        "    workers=8,\n",
        ")"
      ],
      "metadata": {
        "id": "LiFkW4nLYBbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_video_psnr(\"/content/drive/MyDrive/Colorization/Video/Input.mp4\",\n",
        "    \"/content/drive/MyDrive/Colorization/Video/Output.mp4\")"
      ],
      "metadata": {
        "id": "Le04nktcDS_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffprobe -v error -show_entries format=duration \\\n",
        "         -of default=noprint_wrappers=1:nokey=1 \\\n",
        "         \"/content/drive/MyDrive/Colorization/Video/Input2.mp4\""
      ],
      "metadata": {
        "id": "xgdQCtYR15a1",
        "outputId": "46c2f802-f834-4ec5-bb9b-fe23578c4943",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.600000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ffprobe -v error -show_entries format=duration \\\n",
        "         -of default=noprint_wrappers=1:nokey=1 \\\n",
        "         \"/content/drive/MyDrive/Colorization/Video/Output.mp4\""
      ],
      "metadata": {
        "id": "OvhPd2Bn2uPW",
        "outputId": "1fe06ece-38de-4851-90ea-3d9953bb7182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.811000\n"
          ]
        }
      ]
    }
  ]
}