{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMcGPpwMYD+yuWHkVQw7cE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jess-Lau/Real-Life-B-W-Video-Colorization-Project/blob/main/ImageColorizerGANV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ads3J-VraLRG"
      },
      "outputs": [],
      "source": [
        "# ----------------------\n",
        "# Image Colorization GAN\n",
        "# ----------------------\n",
        "import os\n",
        "import time\n",
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model, Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.color import rgb2lab, lab2rgb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Configuration\n",
        "# ------------------\n",
        "IMAGE_SIZE = 64\n",
        "CHANNELS = 1\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 32\n",
        "LAMBDA = 100\n",
        "DATA_DIR = \"/content/drive/MyDrive/ImageNet\"  # Update with your path\n",
        "WORKDIR = \"/content/colorization\"\n",
        "CHECKPOINT_DIR = os.path.join(WORKDIR, \"checkpoints\")\n",
        "RESULTS_DIR = os.path.join(WORKDIR, \"results\")\n",
        "\n",
        "# Enable mixed precision\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Create directories\n",
        "os.makedirs(WORKDIR, exist_ok=True)\n",
        "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(RESULTS_DIR, exist_ok=True)"
      ],
      "metadata": {
        "id": "1jffqiuUahQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Data Pipeline\n",
        "# ------------------\n",
        "def load_mean(data_dir):\n",
        "    \"\"\"Load mean image from first training batch\"\"\"\n",
        "    with open(os.path.join(data_dir, 'train_data_batch_1'), 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "        mean = data['mean'].astype(np.float32) / 255.0\n",
        "        return mean.reshape(3, IMAGE_SIZE, IMAGE_SIZE).transpose(1, 2, 0)\n",
        "\n",
        "def data_generator(data_dir, split='train'):\n",
        "    \"\"\"Memory-efficient data generator\"\"\"\n",
        "    mean = load_mean(data_dir) if split == 'train' else None\n",
        "    files = [f'train_data_batch_{i}' for i in range(1, 11)] if split == 'train' else ['val_data']\n",
        "\n",
        "    for file in files:\n",
        "        path = os.path.join(data_dir, file)\n",
        "        with open(path, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            x = data['data'].astype(np.float32) / 255.0\n",
        "            x = x.reshape(-1, 3, IMAGE_SIZE, IMAGE_SIZE).transpose(0, 2, 3, 1)\n",
        "\n",
        "            if mean is not None:\n",
        "                x -= mean\n",
        "\n",
        "            for i in range(0, x.shape[0], BATCH_SIZE):\n",
        "                batch_rgb = x[i:i+BATCH_SIZE]\n",
        "                batch_lab = np.array([rgb2lab(img) for img in batch_rgb])\n",
        "                L = batch_lab[..., 0:1].astype(np.float32)  # (B,64,64,1)\n",
        "                AB = (batch_lab[..., 1:] / 128.0).astype(np.float32)  # (B,64,64,2)\n",
        "                yield L, AB\n",
        "\n",
        "def create_dataset(data_dir, split='train'):\n",
        "    \"\"\"Create TF Dataset\"\"\"\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        lambda: data_generator(data_dir, split),\n",
        "        output_signature=(\n",
        "            tf.TensorSpec(shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 1), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 2), dtype=tf.float32)\n",
        "    ).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "oXsq8r77afW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Model Architectures\n",
        "# ------------------\n",
        "def downsample(filters, size, apply_batchnorm=True):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv2D(filters, size, strides=2, padding='same',\n",
        "                          kernel_initializer=initializer, use_bias=False))\n",
        "    if apply_batchnorm:\n",
        "        model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU(0.2))\n",
        "    return model\n",
        "\n",
        "def upsample(filters, size, apply_dropout=False):\n",
        "    initializer = tf.random_normal_initializer(0., 0.02)\n",
        "    model = Sequential()\n",
        "    model.add(layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
        "                                    kernel_initializer=initializer, use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    if apply_dropout:\n",
        "        model.add(layers.Dropout(0.5))\n",
        "    model.add(layers.ReLU())\n",
        "    return model\n",
        "\n",
        "def build_generator():\n",
        "    inputs = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNELS))\n",
        "\n",
        "    # Encoder\n",
        "    d1 = downsample(64, 4, False)(inputs)    # 32x32\n",
        "    d2 = downsample(128, 4)(d1)              # 16x16\n",
        "    d3 = downsample(256, 4)(d2)              # 8x8\n",
        "    d4 = downsample(512, 4)(d3)              # 4x4\n",
        "\n",
        "    # Decoder\n",
        "    u1 = upsample(512, 4, True)(d4)          # 8x8\n",
        "    u1 = layers.Concatenate()([u1, d3])\n",
        "    u2 = upsample(256, 4)(u1)                # 16x16\n",
        "    u2 = layers.Concatenate()([u2, d2])\n",
        "    u3 = upsample(128, 4)(u2)                # 32x32\n",
        "    u3 = layers.Concatenate()([u3, d1])\n",
        "    u4 = upsample(64, 4)(u3)                 # 64x64\n",
        "\n",
        "    output = layers.Conv2D(2, 3, padding='same', activation='tanh')(u4)\n",
        "    return Model(inputs, output)\n",
        "\n",
        "def build_discriminator():\n",
        "    inputs = layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "\n",
        "    x = layers.Conv2D(64, 4, strides=2, padding='same')(inputs)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 4, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Conv2D(256, 4, strides=2, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1, activation='sigmoid')(x)\n",
        "    return Model(inputs, x)"
      ],
      "metadata": {
        "id": "6YOSJkmZadOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Training Setup\n",
        "# ------------------\n",
        "generator = build_generator()\n",
        "discriminator = build_discriminator()\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "    generator_optimizer=generator_optimizer,\n",
        "    discriminator_optimizer=discriminator_optimizer,\n",
        "    generator=generator,\n",
        "    discriminator=discriminator,\n",
        "    epoch=tf.Variable(0)\n",
        ")\n",
        "manager = tf.train.CheckpointManager(checkpoint, CHECKPOINT_DIR, max_to_keep=3)"
      ],
      "metadata": {
        "id": "ENkU2C05abcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Training Utilities\n",
        "# ------------------\n",
        "def generate_images(model, test_input, epoch):\n",
        "    prediction = model(test_input, training=False)[0].numpy()\n",
        "    L = test_input[0].numpy()[..., 0]\n",
        "\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(L, cmap='gray')\n",
        "    plt.title(\"Input\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 2)\n",
        "    true_rgb = lab2rgb(np.dstack((L, test_input[1].numpy()[0] * 128)))\n",
        "    plt.imshow(true_rgb)\n",
        "    plt.title(\"Ground Truth\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 3, 3)\n",
        "    pred_rgb = lab2rgb(np.dstack((L, prediction * 128)))\n",
        "    plt.imshow(pred_rgb)\n",
        "    plt.title(\"Predicted\")\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, f'epoch_{epoch+1}.png'))\n",
        "    plt.close()\n",
        "\n",
        "@tf.function\n",
        "def train_step(input_L, input_AB):\n",
        "    # Cast to mixed precision\n",
        "    input_L = tf.cast(input_L, tf.float16)\n",
        "    input_AB = tf.cast(input_AB, tf.float16)\n",
        "\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        generated_AB = generator(input_L, training=True)\n",
        "\n",
        "        # Create concatenated images\n",
        "        real_images = tf.concat([input_L, input_AB], axis=-1)\n",
        "        fake_images = tf.concat([input_L, generated_AB], axis=-1)\n",
        "\n",
        "        # Discriminator outputs\n",
        "        disc_real = discriminator(real_images, training=True)\n",
        "        disc_fake = discriminator(fake_images, training=True)\n",
        "\n",
        "        # Loss calculations\n",
        "        gen_loss = tf.keras.losses.binary_crossentropy(\n",
        "            tf.ones_like(disc_fake), disc_fake) + LAMBDA * tf.reduce_mean(tf.abs(input_AB - generated_AB))\n",
        "        disc_loss = tf.keras.losses.binary_crossentropy(\n",
        "            tf.ones_like(disc_real), disc_real) + tf.keras.losses.binary_crossentropy(\n",
        "            tf.zeros_like(disc_fake), disc_fake)\n",
        "\n",
        "    # Apply gradient clipping\n",
        "    gen_grads = tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gen_grads = [tf.clip_by_norm(g, 1.0) for g in gen_grads]\n",
        "    generator_optimizer.apply_gradients(zip(gen_grads, generator.trainable_variables))\n",
        "\n",
        "    disc_grads = tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    disc_grads = [tf.clip_by_norm(g, 1.0) for g in disc_grads]\n",
        "    discriminator_optimizer.apply_gradients(zip(disc_grads, discriminator.trainable_variables))\n",
        "\n",
        "    return tf.reduce_mean(gen_loss), tf.reduce_mean(disc_loss)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zs6PxIdJaVn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------------\n",
        "# Training Loop\n",
        "# ------------------\n",
        "def train():\n",
        "    train_dataset = create_dataset(DATA_DIR, 'train')\n",
        "    val_dataset = create_dataset(DATA_DIR, 'val')\n",
        "\n",
        "    if manager.latest_checkpoint:\n",
        "        checkpoint.restore(manager.latest_checkpoint)\n",
        "        print(f\"Resumed from epoch {checkpoint.epoch.numpy()}\")\n",
        "\n",
        "    for epoch in range(checkpoint.epoch.numpy(), EPOCHS):\n",
        "        start = time.time()\n",
        "        gen_losses, disc_losses = [], []\n",
        "\n",
        "        for batch, (L, AB) in enumerate(train_dataset):\n",
        "            gen_loss, disc_loss = train_step(L, AB)\n",
        "            gen_losses.append(gen_loss)\n",
        "            disc_losses.append(disc_loss)\n",
        "\n",
        "            if batch % 100 == 0:\n",
        "                gen_loss_val = gen_loss.numpy().item()\n",
        "                disc_loss_val = disc_loss.numpy().item()\n",
        "                print(f\"Epoch {epoch+1} Batch {batch} | Gen: {gen_loss_val:.2f} Disc: {disc_loss_val:.2f}\")\n",
        "                tf.keras.backend.clear_session()\n",
        "\n",
        "        if (epoch + 1) % 5 == 0:\n",
        "            manager.save()\n",
        "            test_batch = next(iter(val_dataset))\n",
        "            generate_images(generator, test_batch, epoch)\n",
        "\n",
        "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "        print(f\"Time: {time.time()-start:.2f}s\")\n",
        "        print(f\"Gen Loss: {np.mean(gen_losses):.4f}\")\n",
        "        print(f\"Disc Loss: {np.mean(disc_losses):.4f}\\n\")\n",
        "        checkpoint.epoch.assign_add(1)"
      ],
      "metadata": {
        "id": "BOasui2daTd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    train()"
      ],
      "metadata": {
        "id": "LvKNoJXlaRZl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}